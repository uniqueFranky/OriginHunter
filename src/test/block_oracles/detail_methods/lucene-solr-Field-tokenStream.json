{
  "origin": "codeshovel",
  "repositoryName": "lucene-solr",
  "repositoryPath": "/Users/franky/Documents/Homework/毕业设计/testcase/lucene-solr/.git",
  "startCommitName": "38bf976cd4b9e324c21664bd7ae3d554df803705",
  "sourceFileName": "Field.java",
  "functionName": "tokenStream",
  "functionId": "tokenStream___analyzer-Analyzer__reuse-TokenStream",
  "sourceFilePath": "lucene/core/src/java/org/apache/lucene/document/Field.java",
  "functionAnnotation": "@Override",
  "functionDoc": "",
  "functionStartLine": 472,
  "functionEndLine": 509,
  "numCommitsSeen": 117,
  "timeTaken": 9513,
  "changeHistory": [
    "105c7eae87896762cbcb295c73c8e8b1fd8f71f8",
    "75dd5e9f9e13c72890f1e5b1695f8281fe990d94",
    "7da175b0b6b4185ee6b5df852e59b93d9a9a1c86",
    "249d0d25fec0c8d3aeaa8991b22c96317b6db86a",
    "6bf44e94399e474ba3285d442ce6406cdadc1d9e",
    "bc41d58cd37ab38c1a088ea67197bd3c338ac53f",
    "8f9f8a3252c73428e67bc5d390e58d1370e060ba",
    "1613f1882c00f28f12570e4f75f913a663e1e2c0",
    "43974d668667ba1b1dacf26a18a22c7fea909539",
    "18117c0b04620e0e4bb7403fca5d05d35665de08",
    "f092795fe94ba727f7368b63d8eb1ecd39749fc4",
    "e2f54df3ca7639f143b195f75adbc5ee97187b92",
    "8f88aa64978a61125adafff544c8e5084d497fb5",
    "2afa06672fe204f468a72d7c85b23158345d5597",
    "518fc20d1cf385650202ff9a3b35136ed9d646e5",
    "e53aee7739be1c04bd1673a55b4956efb63c337f",
    "fd16190940d7495e985f44ce7504562c8bbc91e6",
    "854c9ac45223b64acf3e7e4c0a77383a9441268f",
    "eb0ab3d392a42c1835f79bcd7f5404bcc50c8e4c",
    "9de01b56ebf252ffefe05e606e330a1787b94c9d",
    "67c13bd2fe57d73a824f163f9c73018fa51a1a65",
    "5d4502ad0a3249fec5fcc1e28ce7074f67e8a027",
    "ffb3cbee57e1b075dac827bcc46bc95483c603e0",
    "4dad0ba89f1d663939999be9005433dd629955f1",
    "400639f54e54ba2cf90b2436652450ded25861f7",
    "778d96752fa94636a2136ea2b4d58a3fcbe283ec",
    "efb74380fda0da18650dbc66372a7bb1cd41dcf6",
    "edfce675a575bf83baecb52ca58c6e307d50eaad"
  ],
  "changeHistoryShort": {
    "105c7eae87896762cbcb295c73c8e8b1fd8f71f8": "Ybodychange",
    "75dd5e9f9e13c72890f1e5b1695f8281fe990d94": "Yexceptionschange",
    "7da175b0b6b4185ee6b5df852e59b93d9a9a1c86": "Ybodychange",
    "249d0d25fec0c8d3aeaa8991b22c96317b6db86a": "Ybodychange",
    "6bf44e94399e474ba3285d442ce6406cdadc1d9e": "Ybodychange",
    "bc41d58cd37ab38c1a088ea67197bd3c338ac53f": "Ybodychange",
    "8f9f8a3252c73428e67bc5d390e58d1370e060ba": "Ybodychange",
    "1613f1882c00f28f12570e4f75f913a663e1e2c0": "Ymultichange(Yparameterchange,Ybodychange)",
    "43974d668667ba1b1dacf26a18a22c7fea909539": "Ybodychange",
    "18117c0b04620e0e4bb7403fca5d05d35665de08": "Ybodychange",
    "f092795fe94ba727f7368b63d8eb1ecd39749fc4": "Ybodychange",
    "e2f54df3ca7639f143b195f75adbc5ee97187b92": "Yannotationchange",
    "8f88aa64978a61125adafff544c8e5084d497fb5": "Ybodychange",
    "2afa06672fe204f468a72d7c85b23158345d5597": "Ydocchange",
    "518fc20d1cf385650202ff9a3b35136ed9d646e5": "Ybodychange",
    "e53aee7739be1c04bd1673a55b4956efb63c337f": "Ybodychange",
    "fd16190940d7495e985f44ce7504562c8bbc91e6": "Ybodychange",
    "854c9ac45223b64acf3e7e4c0a77383a9441268f": "Ybodychange",
    "eb0ab3d392a42c1835f79bcd7f5404bcc50c8e4c": "Yfilerename",
    "9de01b56ebf252ffefe05e606e330a1787b94c9d": "Ybodychange",
    "67c13bd2fe57d73a824f163f9c73018fa51a1a65": "Ybodychange",
    "5d4502ad0a3249fec5fcc1e28ce7074f67e8a027": "Ymultichange(Ymovefromfile,Yexceptionschange,Ybodychange,Ydocchange,Yrename,Yparameterchange)",
    "ffb3cbee57e1b075dac827bcc46bc95483c603e0": "Ybodychange",
    "4dad0ba89f1d663939999be9005433dd629955f1": "Ybodychange",
    "400639f54e54ba2cf90b2436652450ded25861f7": "Ybodychange",
    "778d96752fa94636a2136ea2b4d58a3fcbe283ec": "Yfilerename",
    "efb74380fda0da18650dbc66372a7bb1cd41dcf6": "Ybodychange",
    "edfce675a575bf83baecb52ca58c6e307d50eaad": "Yintroduced"
  },
  "changeHistoryDetails": {
    "105c7eae87896762cbcb295c73c8e8b1fd8f71f8": {
      "type": "Ybodychange",
      "commitMessage": "LUCENE-7413: move legacy numeric support to backwards module\n",
      "commitDate": "2016/8/17 下午9:28",
      "commitName": "105c7eae87896762cbcb295c73c8e8b1fd8f71f8",
      "commitAuthor": "Robert Muir",
      "commitDateOld": "2016/8/2 下午5:10",
      "commitNameOld": "d9df295bb73e011b72425d62ce609a14e4644aa4",
      "commitAuthorOld": "Mike McCandless",
      "daysBetweenCommits": 15.18,
      "commitsBetweenForRepo": 59,
      "commitsBetweenForFile": 1,
      "actualSource": "@Override\npublic TokenStream tokenStream(Analyzer analyzer, TokenStream reuse) {\n    if (fieldType().indexOptions() \u003d\u003d IndexOptions.NONE) {\n        return null;\n    }\n    if (!fieldType().tokenized()) {\n        if (stringValue() !\u003d null) {\n            if (!(reuse instanceof StringTokenStream)) {\n                reuse \u003d new StringTokenStream();\n            }\n            ((StringTokenStream) reuse).setValue(stringValue());\n            return reuse;\n        } else if (binaryValue() !\u003d null) {\n            if (!(reuse instanceof BinaryTokenStream)) {\n                reuse \u003d new BinaryTokenStream();\n            }\n            ((BinaryTokenStream) reuse).setValue(binaryValue());\n            return reuse;\n        } else {\n            throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n        }\n    }\n    if (tokenStream !\u003d null) {\n        return tokenStream;\n    } else if (readerValue() !\u003d null) {\n        return analyzer.tokenStream(name(), readerValue());\n    } else if (stringValue() !\u003d null) {\n        return analyzer.tokenStream(name(), stringValue());\n    }\n    throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value; got \" + this);\n}",
      "path": "lucene/core/src/java/org/apache/lucene/document/Field.java",
      "functionStartLine": 504,
      "functionName": "tokenStream",
      "functionAnnotation": "@Override",
      "functionDoc": "",
      "diff": "@@ -1,56 +1,31 @@\n @Override\n public TokenStream tokenStream(Analyzer analyzer, TokenStream reuse) {\n     if (fieldType().indexOptions() \u003d\u003d IndexOptions.NONE) {\n         return null;\n     }\n-    final FieldType.LegacyNumericType numericType \u003d fieldType().numericType();\n-    if (numericType !\u003d null) {\n-        if (!(reuse instanceof LegacyNumericTokenStream \u0026\u0026 ((LegacyNumericTokenStream) reuse).getPrecisionStep() \u003d\u003d type.numericPrecisionStep())) {\n-            reuse \u003d new LegacyNumericTokenStream(type.numericPrecisionStep());\n-        }\n-        final LegacyNumericTokenStream nts \u003d (LegacyNumericTokenStream) reuse;\n-        final Number val \u003d (Number) fieldsData;\n-        switch(numericType) {\n-            case INT:\n-                nts.setIntValue(val.intValue());\n-                break;\n-            case LONG:\n-                nts.setLongValue(val.longValue());\n-                break;\n-            case FLOAT:\n-                nts.setFloatValue(val.floatValue());\n-                break;\n-            case DOUBLE:\n-                nts.setDoubleValue(val.doubleValue());\n-                break;\n-            default:\n-                throw new AssertionError(\"Should never get here\");\n-        }\n-        return reuse;\n-    }\n     if (!fieldType().tokenized()) {\n         if (stringValue() !\u003d null) {\n             if (!(reuse instanceof StringTokenStream)) {\n                 reuse \u003d new StringTokenStream();\n             }\n             ((StringTokenStream) reuse).setValue(stringValue());\n             return reuse;\n         } else if (binaryValue() !\u003d null) {\n             if (!(reuse instanceof BinaryTokenStream)) {\n                 reuse \u003d new BinaryTokenStream();\n             }\n             ((BinaryTokenStream) reuse).setValue(binaryValue());\n             return reuse;\n         } else {\n             throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n         }\n     }\n     if (tokenStream !\u003d null) {\n         return tokenStream;\n     } else if (readerValue() !\u003d null) {\n         return analyzer.tokenStream(name(), readerValue());\n     } else if (stringValue() !\u003d null) {\n         return analyzer.tokenStream(name(), stringValue());\n     }\n     throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value; got \" + this);\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "75dd5e9f9e13c72890f1e5b1695f8281fe990d94": {
      "type": "Yexceptionschange",
      "commitMessage": "LUCENE-6988: IndexableField.tokenStream() no longer throws IOException\n",
      "commitDate": "2016/1/25 下午6:04",
      "commitName": "75dd5e9f9e13c72890f1e5b1695f8281fe990d94",
      "commitAuthor": "Alan Woodward",
      "commitDateOld": "2016/1/18 上午3:54",
      "commitNameOld": "24c46305bd8f335c3d0e501a33dd3da82732c49e",
      "commitAuthorOld": "Michael McCandless",
      "daysBetweenCommits": 7.59,
      "commitsBetweenForRepo": 69,
      "commitsBetweenForFile": 1,
      "actualSource": "@Override\npublic TokenStream tokenStream(Analyzer analyzer, TokenStream reuse) {\n    if (fieldType().indexOptions() \u003d\u003d IndexOptions.NONE) {\n        return null;\n    }\n    final FieldType.LegacyNumericType numericType \u003d fieldType().numericType();\n    if (numericType !\u003d null) {\n        if (!(reuse instanceof LegacyNumericTokenStream \u0026\u0026 ((LegacyNumericTokenStream) reuse).getPrecisionStep() \u003d\u003d type.numericPrecisionStep())) {\n            reuse \u003d new LegacyNumericTokenStream(type.numericPrecisionStep());\n        }\n        final LegacyNumericTokenStream nts \u003d (LegacyNumericTokenStream) reuse;\n        final Number val \u003d (Number) fieldsData;\n        switch(numericType) {\n            case INT:\n                nts.setIntValue(val.intValue());\n                break;\n            case LONG:\n                nts.setLongValue(val.longValue());\n                break;\n            case FLOAT:\n                nts.setFloatValue(val.floatValue());\n                break;\n            case DOUBLE:\n                nts.setDoubleValue(val.doubleValue());\n                break;\n            default:\n                throw new AssertionError(\"Should never get here\");\n        }\n        return reuse;\n    }\n    if (!fieldType().tokenized()) {\n        if (stringValue() !\u003d null) {\n            if (!(reuse instanceof StringTokenStream)) {\n                reuse \u003d new StringTokenStream();\n            }\n            ((StringTokenStream) reuse).setValue(stringValue());\n            return reuse;\n        } else if (binaryValue() !\u003d null) {\n            if (!(reuse instanceof BinaryTokenStream)) {\n                reuse \u003d new BinaryTokenStream();\n            }\n            ((BinaryTokenStream) reuse).setValue(binaryValue());\n            return reuse;\n        } else {\n            throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n        }\n    }\n    if (tokenStream !\u003d null) {\n        return tokenStream;\n    } else if (readerValue() !\u003d null) {\n        return analyzer.tokenStream(name(), readerValue());\n    } else if (stringValue() !\u003d null) {\n        return analyzer.tokenStream(name(), stringValue());\n    }\n    throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value; got \" + this);\n}",
      "path": "lucene/core/src/java/org/apache/lucene/document/Field.java",
      "functionStartLine": 499,
      "functionName": "tokenStream",
      "functionAnnotation": "@Override",
      "functionDoc": "",
      "diff": "@@ -1,56 +1,56 @@\n @Override\n-public TokenStream tokenStream(Analyzer analyzer, TokenStream reuse) throws IOException {\n+public TokenStream tokenStream(Analyzer analyzer, TokenStream reuse) {\n     if (fieldType().indexOptions() \u003d\u003d IndexOptions.NONE) {\n         return null;\n     }\n     final FieldType.LegacyNumericType numericType \u003d fieldType().numericType();\n     if (numericType !\u003d null) {\n         if (!(reuse instanceof LegacyNumericTokenStream \u0026\u0026 ((LegacyNumericTokenStream) reuse).getPrecisionStep() \u003d\u003d type.numericPrecisionStep())) {\n             reuse \u003d new LegacyNumericTokenStream(type.numericPrecisionStep());\n         }\n         final LegacyNumericTokenStream nts \u003d (LegacyNumericTokenStream) reuse;\n         final Number val \u003d (Number) fieldsData;\n         switch(numericType) {\n             case INT:\n                 nts.setIntValue(val.intValue());\n                 break;\n             case LONG:\n                 nts.setLongValue(val.longValue());\n                 break;\n             case FLOAT:\n                 nts.setFloatValue(val.floatValue());\n                 break;\n             case DOUBLE:\n                 nts.setDoubleValue(val.doubleValue());\n                 break;\n             default:\n                 throw new AssertionError(\"Should never get here\");\n         }\n         return reuse;\n     }\n     if (!fieldType().tokenized()) {\n         if (stringValue() !\u003d null) {\n             if (!(reuse instanceof StringTokenStream)) {\n                 reuse \u003d new StringTokenStream();\n             }\n             ((StringTokenStream) reuse).setValue(stringValue());\n             return reuse;\n         } else if (binaryValue() !\u003d null) {\n             if (!(reuse instanceof BinaryTokenStream)) {\n                 reuse \u003d new BinaryTokenStream();\n             }\n             ((BinaryTokenStream) reuse).setValue(binaryValue());\n             return reuse;\n         } else {\n             throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n         }\n     }\n     if (tokenStream !\u003d null) {\n         return tokenStream;\n     } else if (readerValue() !\u003d null) {\n         return analyzer.tokenStream(name(), readerValue());\n     } else if (stringValue() !\u003d null) {\n         return analyzer.tokenStream(name(), stringValue());\n     }\n     throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value; got \" + this);\n }\n\\ No newline at end of file\n",
      "extendedDetails": {
        "oldValue": "[IOException]",
        "newValue": "[]"
      }
    },
    "7da175b0b6b4185ee6b5df852e59b93d9a9a1c86": {
      "type": "Ybodychange",
      "commitMessage": "LUCENE-6917: rename/deprecate numeric classes in favor of dimensional values\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1719562 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "2015/12/12 上午5:13",
      "commitName": "7da175b0b6b4185ee6b5df852e59b93d9a9a1c86",
      "commitAuthor": "Michael McCandless",
      "commitDateOld": "2015/7/2 下午10:09",
      "commitNameOld": "1816ed194556a8199c0338272d1c894036aa163f",
      "commitAuthorOld": "Uwe Schindler",
      "daysBetweenCommits": 162.29,
      "commitsBetweenForRepo": 875,
      "commitsBetweenForFile": 1,
      "actualSource": "@Override\npublic TokenStream tokenStream(Analyzer analyzer, TokenStream reuse) throws IOException {\n    if (fieldType().indexOptions() \u003d\u003d IndexOptions.NONE) {\n        return null;\n    }\n    final FieldType.LegacyNumericType numericType \u003d fieldType().numericType();\n    if (numericType !\u003d null) {\n        if (!(reuse instanceof LegacyNumericTokenStream \u0026\u0026 ((LegacyNumericTokenStream) reuse).getPrecisionStep() \u003d\u003d type.numericPrecisionStep())) {\n            reuse \u003d new LegacyNumericTokenStream(type.numericPrecisionStep());\n        }\n        final LegacyNumericTokenStream nts \u003d (LegacyNumericTokenStream) reuse;\n        final Number val \u003d (Number) fieldsData;\n        switch(numericType) {\n            case INT:\n                nts.setIntValue(val.intValue());\n                break;\n            case LONG:\n                nts.setLongValue(val.longValue());\n                break;\n            case FLOAT:\n                nts.setFloatValue(val.floatValue());\n                break;\n            case DOUBLE:\n                nts.setDoubleValue(val.doubleValue());\n                break;\n            default:\n                throw new AssertionError(\"Should never get here\");\n        }\n        return reuse;\n    }\n    if (!fieldType().tokenized()) {\n        if (stringValue() !\u003d null) {\n            if (!(reuse instanceof StringTokenStream)) {\n                reuse \u003d new StringTokenStream();\n            }\n            ((StringTokenStream) reuse).setValue(stringValue());\n            return reuse;\n        } else if (binaryValue() !\u003d null) {\n            if (!(reuse instanceof BinaryTokenStream)) {\n                reuse \u003d new BinaryTokenStream();\n            }\n            ((BinaryTokenStream) reuse).setValue(binaryValue());\n            return reuse;\n        } else {\n            throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n        }\n    }\n    if (tokenStream !\u003d null) {\n        return tokenStream;\n    } else if (readerValue() !\u003d null) {\n        return analyzer.tokenStream(name(), readerValue());\n    } else if (stringValue() !\u003d null) {\n        return analyzer.tokenStream(name(), stringValue());\n    }\n    throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value; got \" + this);\n}",
      "path": "lucene/core/src/java/org/apache/lucene/document/Field.java",
      "functionStartLine": 500,
      "functionName": "tokenStream",
      "functionAnnotation": "@Override",
      "functionDoc": "",
      "diff": "@@ -1,56 +1,56 @@\n @Override\n public TokenStream tokenStream(Analyzer analyzer, TokenStream reuse) throws IOException {\n     if (fieldType().indexOptions() \u003d\u003d IndexOptions.NONE) {\n         return null;\n     }\n-    final NumericType numericType \u003d fieldType().numericType();\n+    final FieldType.LegacyNumericType numericType \u003d fieldType().numericType();\n     if (numericType !\u003d null) {\n-        if (!(reuse instanceof NumericTokenStream \u0026\u0026 ((NumericTokenStream) reuse).getPrecisionStep() \u003d\u003d type.numericPrecisionStep())) {\n-            reuse \u003d new NumericTokenStream(type.numericPrecisionStep());\n+        if (!(reuse instanceof LegacyNumericTokenStream \u0026\u0026 ((LegacyNumericTokenStream) reuse).getPrecisionStep() \u003d\u003d type.numericPrecisionStep())) {\n+            reuse \u003d new LegacyNumericTokenStream(type.numericPrecisionStep());\n         }\n-        final NumericTokenStream nts \u003d (NumericTokenStream) reuse;\n+        final LegacyNumericTokenStream nts \u003d (LegacyNumericTokenStream) reuse;\n         final Number val \u003d (Number) fieldsData;\n         switch(numericType) {\n             case INT:\n                 nts.setIntValue(val.intValue());\n                 break;\n             case LONG:\n                 nts.setLongValue(val.longValue());\n                 break;\n             case FLOAT:\n                 nts.setFloatValue(val.floatValue());\n                 break;\n             case DOUBLE:\n                 nts.setDoubleValue(val.doubleValue());\n                 break;\n             default:\n                 throw new AssertionError(\"Should never get here\");\n         }\n         return reuse;\n     }\n     if (!fieldType().tokenized()) {\n         if (stringValue() !\u003d null) {\n             if (!(reuse instanceof StringTokenStream)) {\n                 reuse \u003d new StringTokenStream();\n             }\n             ((StringTokenStream) reuse).setValue(stringValue());\n             return reuse;\n         } else if (binaryValue() !\u003d null) {\n             if (!(reuse instanceof BinaryTokenStream)) {\n                 reuse \u003d new BinaryTokenStream();\n             }\n             ((BinaryTokenStream) reuse).setValue(binaryValue());\n             return reuse;\n         } else {\n             throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n         }\n     }\n     if (tokenStream !\u003d null) {\n         return tokenStream;\n     } else if (readerValue() !\u003d null) {\n         return analyzer.tokenStream(name(), readerValue());\n     } else if (stringValue() !\u003d null) {\n         return analyzer.tokenStream(name(), stringValue());\n     }\n     throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value; got \" + this);\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "249d0d25fec0c8d3aeaa8991b22c96317b6db86a": {
      "type": "Ybodychange",
      "commitMessage": "LUCENE-5989: allow passing BytesRef to StringField to make it easier to index arbitrary binary tokens\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1672781 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "2015/4/11 上午6:24",
      "commitName": "249d0d25fec0c8d3aeaa8991b22c96317b6db86a",
      "commitAuthor": "Michael McCandless",
      "commitDateOld": "2015/2/7 下午6:10",
      "commitNameOld": "376256316b016f4971bfa86517c750fae42158c7",
      "commitAuthorOld": "Robert Muir",
      "daysBetweenCommits": 62.51,
      "commitsBetweenForRepo": 511,
      "commitsBetweenForFile": 1,
      "actualSource": "@Override\npublic TokenStream tokenStream(Analyzer analyzer, TokenStream reuse) throws IOException {\n    if (fieldType().indexOptions() \u003d\u003d IndexOptions.NONE) {\n        return null;\n    }\n    final NumericType numericType \u003d fieldType().numericType();\n    if (numericType !\u003d null) {\n        if (!(reuse instanceof NumericTokenStream \u0026\u0026 ((NumericTokenStream) reuse).getPrecisionStep() \u003d\u003d type.numericPrecisionStep())) {\n            reuse \u003d new NumericTokenStream(type.numericPrecisionStep());\n        }\n        final NumericTokenStream nts \u003d (NumericTokenStream) reuse;\n        final Number val \u003d (Number) fieldsData;\n        switch(numericType) {\n            case INT:\n                nts.setIntValue(val.intValue());\n                break;\n            case LONG:\n                nts.setLongValue(val.longValue());\n                break;\n            case FLOAT:\n                nts.setFloatValue(val.floatValue());\n                break;\n            case DOUBLE:\n                nts.setDoubleValue(val.doubleValue());\n                break;\n            default:\n                throw new AssertionError(\"Should never get here\");\n        }\n        return reuse;\n    }\n    if (!fieldType().tokenized()) {\n        if (stringValue() !\u003d null) {\n            if (!(reuse instanceof StringTokenStream)) {\n                reuse \u003d new StringTokenStream();\n            }\n            ((StringTokenStream) reuse).setValue(stringValue());\n            return reuse;\n        } else if (binaryValue() !\u003d null) {\n            if (!(reuse instanceof BinaryTokenStream)) {\n                reuse \u003d new BinaryTokenStream();\n            }\n            ((BinaryTokenStream) reuse).setValue(binaryValue());\n            return reuse;\n        } else {\n            throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n        }\n    }\n    if (tokenStream !\u003d null) {\n        return tokenStream;\n    } else if (readerValue() !\u003d null) {\n        return analyzer.tokenStream(name(), readerValue());\n    } else if (stringValue() !\u003d null) {\n        return analyzer.tokenStream(name(), stringValue());\n    }\n    throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value; got \" + this);\n}",
      "path": "lucene/core/src/java/org/apache/lucene/document/Field.java",
      "functionStartLine": 504,
      "functionName": "tokenStream",
      "functionAnnotation": "@Override",
      "functionDoc": "",
      "diff": "@@ -1,49 +1,56 @@\n @Override\n public TokenStream tokenStream(Analyzer analyzer, TokenStream reuse) throws IOException {\n     if (fieldType().indexOptions() \u003d\u003d IndexOptions.NONE) {\n         return null;\n     }\n     final NumericType numericType \u003d fieldType().numericType();\n     if (numericType !\u003d null) {\n         if (!(reuse instanceof NumericTokenStream \u0026\u0026 ((NumericTokenStream) reuse).getPrecisionStep() \u003d\u003d type.numericPrecisionStep())) {\n             reuse \u003d new NumericTokenStream(type.numericPrecisionStep());\n         }\n         final NumericTokenStream nts \u003d (NumericTokenStream) reuse;\n         final Number val \u003d (Number) fieldsData;\n         switch(numericType) {\n             case INT:\n                 nts.setIntValue(val.intValue());\n                 break;\n             case LONG:\n                 nts.setLongValue(val.longValue());\n                 break;\n             case FLOAT:\n                 nts.setFloatValue(val.floatValue());\n                 break;\n             case DOUBLE:\n                 nts.setDoubleValue(val.doubleValue());\n                 break;\n             default:\n                 throw new AssertionError(\"Should never get here\");\n         }\n         return reuse;\n     }\n     if (!fieldType().tokenized()) {\n-        if (stringValue() \u003d\u003d null) {\n+        if (stringValue() !\u003d null) {\n+            if (!(reuse instanceof StringTokenStream)) {\n+                reuse \u003d new StringTokenStream();\n+            }\n+            ((StringTokenStream) reuse).setValue(stringValue());\n+            return reuse;\n+        } else if (binaryValue() !\u003d null) {\n+            if (!(reuse instanceof BinaryTokenStream)) {\n+                reuse \u003d new BinaryTokenStream();\n+            }\n+            ((BinaryTokenStream) reuse).setValue(binaryValue());\n+            return reuse;\n+        } else {\n             throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n         }\n-        if (!(reuse instanceof StringTokenStream)) {\n-            reuse \u003d new StringTokenStream();\n-        }\n-        ((StringTokenStream) reuse).setValue(stringValue());\n-        return reuse;\n     }\n     if (tokenStream !\u003d null) {\n         return tokenStream;\n     } else if (readerValue() !\u003d null) {\n         return analyzer.tokenStream(name(), readerValue());\n     } else if (stringValue() !\u003d null) {\n         return analyzer.tokenStream(name(), stringValue());\n     }\n     throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value; got \" + this);\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "6bf44e94399e474ba3285d442ce6406cdadc1d9e": {
      "type": "Ybodychange",
      "commitMessage": "LUCENE-6039: NO -\u003e NONE\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1635861 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "2014/11/1 上午4:48",
      "commitName": "6bf44e94399e474ba3285d442ce6406cdadc1d9e",
      "commitAuthor": "Michael McCandless",
      "commitDateOld": "2014/10/31 下午11:10",
      "commitNameOld": "bc41d58cd37ab38c1a088ea67197bd3c338ac53f",
      "commitAuthorOld": "Michael McCandless",
      "daysBetweenCommits": 0.23,
      "commitsBetweenForRepo": 5,
      "commitsBetweenForFile": 1,
      "actualSource": "@Override\npublic TokenStream tokenStream(Analyzer analyzer, TokenStream reuse) throws IOException {\n    if (fieldType().indexOptions() \u003d\u003d IndexOptions.NONE) {\n        return null;\n    }\n    final NumericType numericType \u003d fieldType().numericType();\n    if (numericType !\u003d null) {\n        if (!(reuse instanceof NumericTokenStream \u0026\u0026 ((NumericTokenStream) reuse).getPrecisionStep() \u003d\u003d type.numericPrecisionStep())) {\n            reuse \u003d new NumericTokenStream(type.numericPrecisionStep());\n        }\n        final NumericTokenStream nts \u003d (NumericTokenStream) reuse;\n        final Number val \u003d (Number) fieldsData;\n        switch(numericType) {\n            case INT:\n                nts.setIntValue(val.intValue());\n                break;\n            case LONG:\n                nts.setLongValue(val.longValue());\n                break;\n            case FLOAT:\n                nts.setFloatValue(val.floatValue());\n                break;\n            case DOUBLE:\n                nts.setDoubleValue(val.doubleValue());\n                break;\n            default:\n                throw new AssertionError(\"Should never get here\");\n        }\n        return reuse;\n    }\n    if (!fieldType().tokenized()) {\n        if (stringValue() \u003d\u003d null) {\n            throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n        }\n        if (!(reuse instanceof StringTokenStream)) {\n            reuse \u003d new StringTokenStream();\n        }\n        ((StringTokenStream) reuse).setValue(stringValue());\n        return reuse;\n    }\n    if (tokenStream !\u003d null) {\n        return tokenStream;\n    } else if (readerValue() !\u003d null) {\n        return analyzer.tokenStream(name(), readerValue());\n    } else if (stringValue() !\u003d null) {\n        return analyzer.tokenStream(name(), stringValue());\n    }\n    throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value; got \" + this);\n}",
      "path": "lucene/core/src/java/org/apache/lucene/document/Field.java",
      "functionStartLine": 505,
      "functionName": "tokenStream",
      "functionAnnotation": "@Override",
      "functionDoc": "",
      "diff": "@@ -1,49 +1,49 @@\n @Override\n public TokenStream tokenStream(Analyzer analyzer, TokenStream reuse) throws IOException {\n-    if (fieldType().indexOptions() \u003d\u003d IndexOptions.NO) {\n+    if (fieldType().indexOptions() \u003d\u003d IndexOptions.NONE) {\n         return null;\n     }\n     final NumericType numericType \u003d fieldType().numericType();\n     if (numericType !\u003d null) {\n         if (!(reuse instanceof NumericTokenStream \u0026\u0026 ((NumericTokenStream) reuse).getPrecisionStep() \u003d\u003d type.numericPrecisionStep())) {\n             reuse \u003d new NumericTokenStream(type.numericPrecisionStep());\n         }\n         final NumericTokenStream nts \u003d (NumericTokenStream) reuse;\n         final Number val \u003d (Number) fieldsData;\n         switch(numericType) {\n             case INT:\n                 nts.setIntValue(val.intValue());\n                 break;\n             case LONG:\n                 nts.setLongValue(val.longValue());\n                 break;\n             case FLOAT:\n                 nts.setFloatValue(val.floatValue());\n                 break;\n             case DOUBLE:\n                 nts.setDoubleValue(val.doubleValue());\n                 break;\n             default:\n                 throw new AssertionError(\"Should never get here\");\n         }\n         return reuse;\n     }\n     if (!fieldType().tokenized()) {\n         if (stringValue() \u003d\u003d null) {\n             throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n         }\n         if (!(reuse instanceof StringTokenStream)) {\n             reuse \u003d new StringTokenStream();\n         }\n         ((StringTokenStream) reuse).setValue(stringValue());\n         return reuse;\n     }\n     if (tokenStream !\u003d null) {\n         return tokenStream;\n     } else if (readerValue() !\u003d null) {\n         return analyzer.tokenStream(name(), readerValue());\n     } else if (stringValue() !\u003d null) {\n         return analyzer.tokenStream(name(), stringValue());\n     }\n     throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value; got \" + this);\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "bc41d58cd37ab38c1a088ea67197bd3c338ac53f": {
      "type": "Ybodychange",
      "commitMessage": "LUCENE-6039: cutover to IndexOptions.NO/DocValuesType.NO instead of null\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1635790 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "2014/10/31 下午11:10",
      "commitName": "bc41d58cd37ab38c1a088ea67197bd3c338ac53f",
      "commitAuthor": "Michael McCandless",
      "commitDateOld": "2014/10/21 下午3:32",
      "commitNameOld": "8f9f8a3252c73428e67bc5d390e58d1370e060ba",
      "commitAuthorOld": "Michael McCandless",
      "daysBetweenCommits": 10.32,
      "commitsBetweenForRepo": 79,
      "commitsBetweenForFile": 1,
      "actualSource": "@Override\npublic TokenStream tokenStream(Analyzer analyzer, TokenStream reuse) throws IOException {\n    if (fieldType().indexOptions() \u003d\u003d IndexOptions.NO) {\n        return null;\n    }\n    final NumericType numericType \u003d fieldType().numericType();\n    if (numericType !\u003d null) {\n        if (!(reuse instanceof NumericTokenStream \u0026\u0026 ((NumericTokenStream) reuse).getPrecisionStep() \u003d\u003d type.numericPrecisionStep())) {\n            reuse \u003d new NumericTokenStream(type.numericPrecisionStep());\n        }\n        final NumericTokenStream nts \u003d (NumericTokenStream) reuse;\n        final Number val \u003d (Number) fieldsData;\n        switch(numericType) {\n            case INT:\n                nts.setIntValue(val.intValue());\n                break;\n            case LONG:\n                nts.setLongValue(val.longValue());\n                break;\n            case FLOAT:\n                nts.setFloatValue(val.floatValue());\n                break;\n            case DOUBLE:\n                nts.setDoubleValue(val.doubleValue());\n                break;\n            default:\n                throw new AssertionError(\"Should never get here\");\n        }\n        return reuse;\n    }\n    if (!fieldType().tokenized()) {\n        if (stringValue() \u003d\u003d null) {\n            throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n        }\n        if (!(reuse instanceof StringTokenStream)) {\n            reuse \u003d new StringTokenStream();\n        }\n        ((StringTokenStream) reuse).setValue(stringValue());\n        return reuse;\n    }\n    if (tokenStream !\u003d null) {\n        return tokenStream;\n    } else if (readerValue() !\u003d null) {\n        return analyzer.tokenStream(name(), readerValue());\n    } else if (stringValue() !\u003d null) {\n        return analyzer.tokenStream(name(), stringValue());\n    }\n    throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value; got \" + this);\n}",
      "path": "lucene/core/src/java/org/apache/lucene/document/Field.java",
      "functionStartLine": 505,
      "functionName": "tokenStream",
      "functionAnnotation": "@Override",
      "functionDoc": "",
      "diff": "@@ -1,49 +1,49 @@\n @Override\n public TokenStream tokenStream(Analyzer analyzer, TokenStream reuse) throws IOException {\n-    if (fieldType().indexOptions() \u003d\u003d null) {\n+    if (fieldType().indexOptions() \u003d\u003d IndexOptions.NO) {\n         return null;\n     }\n     final NumericType numericType \u003d fieldType().numericType();\n     if (numericType !\u003d null) {\n         if (!(reuse instanceof NumericTokenStream \u0026\u0026 ((NumericTokenStream) reuse).getPrecisionStep() \u003d\u003d type.numericPrecisionStep())) {\n             reuse \u003d new NumericTokenStream(type.numericPrecisionStep());\n         }\n         final NumericTokenStream nts \u003d (NumericTokenStream) reuse;\n         final Number val \u003d (Number) fieldsData;\n         switch(numericType) {\n             case INT:\n                 nts.setIntValue(val.intValue());\n                 break;\n             case LONG:\n                 nts.setLongValue(val.longValue());\n                 break;\n             case FLOAT:\n                 nts.setFloatValue(val.floatValue());\n                 break;\n             case DOUBLE:\n                 nts.setDoubleValue(val.doubleValue());\n                 break;\n             default:\n                 throw new AssertionError(\"Should never get here\");\n         }\n         return reuse;\n     }\n     if (!fieldType().tokenized()) {\n         if (stringValue() \u003d\u003d null) {\n             throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n         }\n         if (!(reuse instanceof StringTokenStream)) {\n             reuse \u003d new StringTokenStream();\n         }\n         ((StringTokenStream) reuse).setValue(stringValue());\n         return reuse;\n     }\n     if (tokenStream !\u003d null) {\n         return tokenStream;\n     } else if (readerValue() !\u003d null) {\n         return analyzer.tokenStream(name(), readerValue());\n     } else if (stringValue() !\u003d null) {\n         return analyzer.tokenStream(name(), stringValue());\n     }\n     throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value; got \" + this);\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "8f9f8a3252c73428e67bc5d390e58d1370e060ba": {
      "type": "Ybodychange",
      "commitMessage": "LUCENE-6013: remove IndexableFieldType.indexed and FieldInfo.indexed (it\u0027s redundant with IndexOptions !\u003d null)\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1633296 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "2014/10/21 下午3:32",
      "commitName": "8f9f8a3252c73428e67bc5d390e58d1370e060ba",
      "commitAuthor": "Michael McCandless",
      "commitDateOld": "2014/5/10 上午12:36",
      "commitNameOld": "e12039a377c4639f30aad8b31fb39964754d6084",
      "commitAuthorOld": "Robert Muir",
      "daysBetweenCommits": 164.62,
      "commitsBetweenForRepo": 1136,
      "commitsBetweenForFile": 1,
      "actualSource": "@Override\npublic TokenStream tokenStream(Analyzer analyzer, TokenStream reuse) throws IOException {\n    if (fieldType().indexOptions() \u003d\u003d null) {\n        return null;\n    }\n    final NumericType numericType \u003d fieldType().numericType();\n    if (numericType !\u003d null) {\n        if (!(reuse instanceof NumericTokenStream \u0026\u0026 ((NumericTokenStream) reuse).getPrecisionStep() \u003d\u003d type.numericPrecisionStep())) {\n            reuse \u003d new NumericTokenStream(type.numericPrecisionStep());\n        }\n        final NumericTokenStream nts \u003d (NumericTokenStream) reuse;\n        final Number val \u003d (Number) fieldsData;\n        switch(numericType) {\n            case INT:\n                nts.setIntValue(val.intValue());\n                break;\n            case LONG:\n                nts.setLongValue(val.longValue());\n                break;\n            case FLOAT:\n                nts.setFloatValue(val.floatValue());\n                break;\n            case DOUBLE:\n                nts.setDoubleValue(val.doubleValue());\n                break;\n            default:\n                throw new AssertionError(\"Should never get here\");\n        }\n        return reuse;\n    }\n    if (!fieldType().tokenized()) {\n        if (stringValue() \u003d\u003d null) {\n            throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n        }\n        if (!(reuse instanceof StringTokenStream)) {\n            reuse \u003d new StringTokenStream();\n        }\n        ((StringTokenStream) reuse).setValue(stringValue());\n        return reuse;\n    }\n    if (tokenStream !\u003d null) {\n        return tokenStream;\n    } else if (readerValue() !\u003d null) {\n        return analyzer.tokenStream(name(), readerValue());\n    } else if (stringValue() !\u003d null) {\n        return analyzer.tokenStream(name(), stringValue());\n    }\n    throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value; got \" + this);\n}",
      "path": "lucene/core/src/java/org/apache/lucene/document/Field.java",
      "functionStartLine": 504,
      "functionName": "tokenStream",
      "functionAnnotation": "@Override",
      "functionDoc": "",
      "diff": "@@ -1,49 +1,49 @@\n @Override\n public TokenStream tokenStream(Analyzer analyzer, TokenStream reuse) throws IOException {\n-    if (!fieldType().indexed()) {\n+    if (fieldType().indexOptions() \u003d\u003d null) {\n         return null;\n     }\n     final NumericType numericType \u003d fieldType().numericType();\n     if (numericType !\u003d null) {\n         if (!(reuse instanceof NumericTokenStream \u0026\u0026 ((NumericTokenStream) reuse).getPrecisionStep() \u003d\u003d type.numericPrecisionStep())) {\n             reuse \u003d new NumericTokenStream(type.numericPrecisionStep());\n         }\n         final NumericTokenStream nts \u003d (NumericTokenStream) reuse;\n         final Number val \u003d (Number) fieldsData;\n         switch(numericType) {\n             case INT:\n                 nts.setIntValue(val.intValue());\n                 break;\n             case LONG:\n                 nts.setLongValue(val.longValue());\n                 break;\n             case FLOAT:\n                 nts.setFloatValue(val.floatValue());\n                 break;\n             case DOUBLE:\n                 nts.setDoubleValue(val.doubleValue());\n                 break;\n             default:\n                 throw new AssertionError(\"Should never get here\");\n         }\n         return reuse;\n     }\n     if (!fieldType().tokenized()) {\n         if (stringValue() \u003d\u003d null) {\n             throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n         }\n         if (!(reuse instanceof StringTokenStream)) {\n             reuse \u003d new StringTokenStream();\n         }\n         ((StringTokenStream) reuse).setValue(stringValue());\n         return reuse;\n     }\n     if (tokenStream !\u003d null) {\n         return tokenStream;\n     } else if (readerValue() !\u003d null) {\n         return analyzer.tokenStream(name(), readerValue());\n     } else if (stringValue() !\u003d null) {\n         return analyzer.tokenStream(name(), stringValue());\n     }\n     throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value; got \" + this);\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "1613f1882c00f28f12570e4f75f913a663e1e2c0": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "LUCENE-5634: Reuse TokenStream instances for string and numeric Fields\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1591992 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "2014/5/3 上午2:07",
      "commitName": "1613f1882c00f28f12570e4f75f913a663e1e2c0",
      "commitAuthor": "Robert Muir",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "LUCENE-5634: Reuse TokenStream instances for string and numeric Fields\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1591992 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "2014/5/3 上午2:07",
          "commitName": "1613f1882c00f28f12570e4f75f913a663e1e2c0",
          "commitAuthor": "Robert Muir",
          "commitDateOld": "2014/4/30 上午1:18",
          "commitNameOld": "f5de5d01e8108653b2d6e2dcb0f7e9af7389937a",
          "commitAuthorOld": "",
          "daysBetweenCommits": 3.03,
          "commitsBetweenForRepo": 36,
          "commitsBetweenForFile": 1,
          "actualSource": "@Override\npublic TokenStream tokenStream(Analyzer analyzer, TokenStream reuse) throws IOException {\n    if (!fieldType().indexed()) {\n        return null;\n    }\n    final NumericType numericType \u003d fieldType().numericType();\n    if (numericType !\u003d null) {\n        if (!(reuse instanceof NumericTokenStream \u0026\u0026 ((NumericTokenStream) reuse).getPrecisionStep() \u003d\u003d type.numericPrecisionStep())) {\n            reuse \u003d new NumericTokenStream(type.numericPrecisionStep());\n        }\n        final NumericTokenStream nts \u003d (NumericTokenStream) reuse;\n        final Number val \u003d (Number) fieldsData;\n        switch(numericType) {\n            case INT:\n                nts.setIntValue(val.intValue());\n                break;\n            case LONG:\n                nts.setLongValue(val.longValue());\n                break;\n            case FLOAT:\n                nts.setFloatValue(val.floatValue());\n                break;\n            case DOUBLE:\n                nts.setDoubleValue(val.doubleValue());\n                break;\n            default:\n                throw new AssertionError(\"Should never get here\");\n        }\n        return reuse;\n    }\n    if (!fieldType().tokenized()) {\n        if (stringValue() \u003d\u003d null) {\n            throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n        }\n        if (!(reuse instanceof StringTokenStream)) {\n            reuse \u003d new StringTokenStream();\n        }\n        ((StringTokenStream) reuse).setValue(stringValue());\n        return reuse;\n    }\n    if (tokenStream !\u003d null) {\n        return tokenStream;\n    } else if (readerValue() !\u003d null) {\n        return analyzer.tokenStream(name(), readerValue());\n    } else if (stringValue() !\u003d null) {\n        return analyzer.tokenStream(name(), stringValue());\n    }\n    throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value; got \" + this);\n}",
          "path": "lucene/core/src/java/org/apache/lucene/document/Field.java",
          "functionStartLine": 495,
          "functionName": "tokenStream",
          "functionAnnotation": "@Override",
          "functionDoc": "",
          "diff": "@@ -1,49 +1,49 @@\n @Override\n-public TokenStream tokenStream(Analyzer analyzer) throws IOException {\n+public TokenStream tokenStream(Analyzer analyzer, TokenStream reuse) throws IOException {\n     if (!fieldType().indexed()) {\n         return null;\n     }\n     final NumericType numericType \u003d fieldType().numericType();\n     if (numericType !\u003d null) {\n-        if (!(internalTokenStream instanceof NumericTokenStream)) {\n-            internalTokenStream \u003d new NumericTokenStream(type.numericPrecisionStep());\n+        if (!(reuse instanceof NumericTokenStream \u0026\u0026 ((NumericTokenStream) reuse).getPrecisionStep() \u003d\u003d type.numericPrecisionStep())) {\n+            reuse \u003d new NumericTokenStream(type.numericPrecisionStep());\n         }\n-        final NumericTokenStream nts \u003d (NumericTokenStream) internalTokenStream;\n+        final NumericTokenStream nts \u003d (NumericTokenStream) reuse;\n         final Number val \u003d (Number) fieldsData;\n         switch(numericType) {\n             case INT:\n                 nts.setIntValue(val.intValue());\n                 break;\n             case LONG:\n                 nts.setLongValue(val.longValue());\n                 break;\n             case FLOAT:\n                 nts.setFloatValue(val.floatValue());\n                 break;\n             case DOUBLE:\n                 nts.setDoubleValue(val.doubleValue());\n                 break;\n             default:\n                 throw new AssertionError(\"Should never get here\");\n         }\n-        return internalTokenStream;\n+        return reuse;\n     }\n     if (!fieldType().tokenized()) {\n         if (stringValue() \u003d\u003d null) {\n             throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n         }\n-        if (!(internalTokenStream instanceof StringTokenStream)) {\n-            internalTokenStream \u003d new StringTokenStream();\n+        if (!(reuse instanceof StringTokenStream)) {\n+            reuse \u003d new StringTokenStream();\n         }\n-        ((StringTokenStream) internalTokenStream).setValue(stringValue());\n-        return internalTokenStream;\n+        ((StringTokenStream) reuse).setValue(stringValue());\n+        return reuse;\n     }\n     if (tokenStream !\u003d null) {\n         return tokenStream;\n     } else if (readerValue() !\u003d null) {\n         return analyzer.tokenStream(name(), readerValue());\n     } else if (stringValue() !\u003d null) {\n         return analyzer.tokenStream(name(), stringValue());\n     }\n     throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value; got \" + this);\n }\n\\ No newline at end of file\n",
          "extendedDetails": {
            "oldValue": "[analyzer-Analyzer]",
            "newValue": "[analyzer-Analyzer, reuse-TokenStream]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "LUCENE-5634: Reuse TokenStream instances for string and numeric Fields\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1591992 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "2014/5/3 上午2:07",
          "commitName": "1613f1882c00f28f12570e4f75f913a663e1e2c0",
          "commitAuthor": "Robert Muir",
          "commitDateOld": "2014/4/30 上午1:18",
          "commitNameOld": "f5de5d01e8108653b2d6e2dcb0f7e9af7389937a",
          "commitAuthorOld": "",
          "daysBetweenCommits": 3.03,
          "commitsBetweenForRepo": 36,
          "commitsBetweenForFile": 1,
          "actualSource": "@Override\npublic TokenStream tokenStream(Analyzer analyzer, TokenStream reuse) throws IOException {\n    if (!fieldType().indexed()) {\n        return null;\n    }\n    final NumericType numericType \u003d fieldType().numericType();\n    if (numericType !\u003d null) {\n        if (!(reuse instanceof NumericTokenStream \u0026\u0026 ((NumericTokenStream) reuse).getPrecisionStep() \u003d\u003d type.numericPrecisionStep())) {\n            reuse \u003d new NumericTokenStream(type.numericPrecisionStep());\n        }\n        final NumericTokenStream nts \u003d (NumericTokenStream) reuse;\n        final Number val \u003d (Number) fieldsData;\n        switch(numericType) {\n            case INT:\n                nts.setIntValue(val.intValue());\n                break;\n            case LONG:\n                nts.setLongValue(val.longValue());\n                break;\n            case FLOAT:\n                nts.setFloatValue(val.floatValue());\n                break;\n            case DOUBLE:\n                nts.setDoubleValue(val.doubleValue());\n                break;\n            default:\n                throw new AssertionError(\"Should never get here\");\n        }\n        return reuse;\n    }\n    if (!fieldType().tokenized()) {\n        if (stringValue() \u003d\u003d null) {\n            throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n        }\n        if (!(reuse instanceof StringTokenStream)) {\n            reuse \u003d new StringTokenStream();\n        }\n        ((StringTokenStream) reuse).setValue(stringValue());\n        return reuse;\n    }\n    if (tokenStream !\u003d null) {\n        return tokenStream;\n    } else if (readerValue() !\u003d null) {\n        return analyzer.tokenStream(name(), readerValue());\n    } else if (stringValue() !\u003d null) {\n        return analyzer.tokenStream(name(), stringValue());\n    }\n    throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value; got \" + this);\n}",
          "path": "lucene/core/src/java/org/apache/lucene/document/Field.java",
          "functionStartLine": 495,
          "functionName": "tokenStream",
          "functionAnnotation": "@Override",
          "functionDoc": "",
          "diff": "@@ -1,49 +1,49 @@\n @Override\n-public TokenStream tokenStream(Analyzer analyzer) throws IOException {\n+public TokenStream tokenStream(Analyzer analyzer, TokenStream reuse) throws IOException {\n     if (!fieldType().indexed()) {\n         return null;\n     }\n     final NumericType numericType \u003d fieldType().numericType();\n     if (numericType !\u003d null) {\n-        if (!(internalTokenStream instanceof NumericTokenStream)) {\n-            internalTokenStream \u003d new NumericTokenStream(type.numericPrecisionStep());\n+        if (!(reuse instanceof NumericTokenStream \u0026\u0026 ((NumericTokenStream) reuse).getPrecisionStep() \u003d\u003d type.numericPrecisionStep())) {\n+            reuse \u003d new NumericTokenStream(type.numericPrecisionStep());\n         }\n-        final NumericTokenStream nts \u003d (NumericTokenStream) internalTokenStream;\n+        final NumericTokenStream nts \u003d (NumericTokenStream) reuse;\n         final Number val \u003d (Number) fieldsData;\n         switch(numericType) {\n             case INT:\n                 nts.setIntValue(val.intValue());\n                 break;\n             case LONG:\n                 nts.setLongValue(val.longValue());\n                 break;\n             case FLOAT:\n                 nts.setFloatValue(val.floatValue());\n                 break;\n             case DOUBLE:\n                 nts.setDoubleValue(val.doubleValue());\n                 break;\n             default:\n                 throw new AssertionError(\"Should never get here\");\n         }\n-        return internalTokenStream;\n+        return reuse;\n     }\n     if (!fieldType().tokenized()) {\n         if (stringValue() \u003d\u003d null) {\n             throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n         }\n-        if (!(internalTokenStream instanceof StringTokenStream)) {\n-            internalTokenStream \u003d new StringTokenStream();\n+        if (!(reuse instanceof StringTokenStream)) {\n+            reuse \u003d new StringTokenStream();\n         }\n-        ((StringTokenStream) internalTokenStream).setValue(stringValue());\n-        return internalTokenStream;\n+        ((StringTokenStream) reuse).setValue(stringValue());\n+        return reuse;\n     }\n     if (tokenStream !\u003d null) {\n         return tokenStream;\n     } else if (readerValue() !\u003d null) {\n         return analyzer.tokenStream(name(), readerValue());\n     } else if (stringValue() !\u003d null) {\n         return analyzer.tokenStream(name(), stringValue());\n     }\n     throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value; got \" + this);\n }\n\\ No newline at end of file\n",
          "extendedDetails": {}
        }
      ]
    },
    "43974d668667ba1b1dacf26a18a22c7fea909539": {
      "type": "Ybodychange",
      "commitMessage": "LUCENE-5339: javadocs\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/branches/lucene5339@1554710 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "2014/1/2 上午8:23",
      "commitName": "43974d668667ba1b1dacf26a18a22c7fea909539",
      "commitAuthor": "Michael McCandless",
      "commitDateOld": "2013/11/18 下午10:53",
      "commitNameOld": "18117c0b04620e0e4bb7403fca5d05d35665de08",
      "commitAuthorOld": "Michael McCandless",
      "daysBetweenCommits": 44.4,
      "commitsBetweenForRepo": 225,
      "commitsBetweenForFile": 1,
      "actualSource": "@Override\npublic TokenStream tokenStream(Analyzer analyzer) throws IOException {\n    if (!fieldType().indexed()) {\n        return null;\n    }\n    final NumericType numericType \u003d fieldType().numericType();\n    if (numericType !\u003d null) {\n        if (!(internalTokenStream instanceof NumericTokenStream)) {\n            internalTokenStream \u003d new NumericTokenStream(type.numericPrecisionStep());\n        }\n        final NumericTokenStream nts \u003d (NumericTokenStream) internalTokenStream;\n        final Number val \u003d (Number) fieldsData;\n        switch(numericType) {\n            case INT:\n                nts.setIntValue(val.intValue());\n                break;\n            case LONG:\n                nts.setLongValue(val.longValue());\n                break;\n            case FLOAT:\n                nts.setFloatValue(val.floatValue());\n                break;\n            case DOUBLE:\n                nts.setDoubleValue(val.doubleValue());\n                break;\n            default:\n                throw new AssertionError(\"Should never get here\");\n        }\n        return internalTokenStream;\n    }\n    if (!fieldType().tokenized()) {\n        if (stringValue() \u003d\u003d null) {\n            throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n        }\n        if (!(internalTokenStream instanceof StringTokenStream)) {\n            internalTokenStream \u003d new StringTokenStream();\n        }\n        ((StringTokenStream) internalTokenStream).setValue(stringValue());\n        return internalTokenStream;\n    }\n    if (tokenStream !\u003d null) {\n        return tokenStream;\n    } else if (readerValue() !\u003d null) {\n        return analyzer.tokenStream(name(), readerValue());\n    } else if (stringValue() !\u003d null) {\n        return analyzer.tokenStream(name(), stringValue());\n    }\n    throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value; got \" + this);\n}",
      "path": "lucene/core/src/java/org/apache/lucene/document/Field.java",
      "functionStartLine": 502,
      "functionName": "tokenStream",
      "functionAnnotation": "@Override",
      "functionDoc": "",
      "diff": "@@ -1,49 +1,49 @@\n @Override\n public TokenStream tokenStream(Analyzer analyzer) throws IOException {\n     if (!fieldType().indexed()) {\n         return null;\n     }\n     final NumericType numericType \u003d fieldType().numericType();\n     if (numericType !\u003d null) {\n         if (!(internalTokenStream instanceof NumericTokenStream)) {\n             internalTokenStream \u003d new NumericTokenStream(type.numericPrecisionStep());\n         }\n         final NumericTokenStream nts \u003d (NumericTokenStream) internalTokenStream;\n         final Number val \u003d (Number) fieldsData;\n         switch(numericType) {\n             case INT:\n                 nts.setIntValue(val.intValue());\n                 break;\n             case LONG:\n                 nts.setLongValue(val.longValue());\n                 break;\n             case FLOAT:\n                 nts.setFloatValue(val.floatValue());\n                 break;\n             case DOUBLE:\n                 nts.setDoubleValue(val.doubleValue());\n                 break;\n             default:\n                 throw new AssertionError(\"Should never get here\");\n         }\n         return internalTokenStream;\n     }\n     if (!fieldType().tokenized()) {\n         if (stringValue() \u003d\u003d null) {\n             throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n         }\n         if (!(internalTokenStream instanceof StringTokenStream)) {\n             internalTokenStream \u003d new StringTokenStream();\n         }\n         ((StringTokenStream) internalTokenStream).setValue(stringValue());\n         return internalTokenStream;\n     }\n     if (tokenStream !\u003d null) {\n         return tokenStream;\n     } else if (readerValue() !\u003d null) {\n         return analyzer.tokenStream(name(), readerValue());\n     } else if (stringValue() !\u003d null) {\n         return analyzer.tokenStream(name(), stringValue());\n     }\n-    throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value; this\u003d\" + this);\n+    throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value; got \" + this);\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "18117c0b04620e0e4bb7403fca5d05d35665de08": {
      "type": "Ybodychange",
      "commitMessage": "LUCENE-5339: assocations\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/branches/lucene5339@1543047 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "2013/11/18 下午10:53",
      "commitName": "18117c0b04620e0e4bb7403fca5d05d35665de08",
      "commitAuthor": "Michael McCandless",
      "commitDateOld": "2013/7/9 上午1:55",
      "commitNameOld": "f092795fe94ba727f7368b63d8eb1ecd39749fc4",
      "commitAuthorOld": "Uwe Schindler",
      "daysBetweenCommits": 132.87,
      "commitsBetweenForRepo": 835,
      "commitsBetweenForFile": 1,
      "actualSource": "@Override\npublic TokenStream tokenStream(Analyzer analyzer) throws IOException {\n    if (!fieldType().indexed()) {\n        return null;\n    }\n    final NumericType numericType \u003d fieldType().numericType();\n    if (numericType !\u003d null) {\n        if (!(internalTokenStream instanceof NumericTokenStream)) {\n            internalTokenStream \u003d new NumericTokenStream(type.numericPrecisionStep());\n        }\n        final NumericTokenStream nts \u003d (NumericTokenStream) internalTokenStream;\n        final Number val \u003d (Number) fieldsData;\n        switch(numericType) {\n            case INT:\n                nts.setIntValue(val.intValue());\n                break;\n            case LONG:\n                nts.setLongValue(val.longValue());\n                break;\n            case FLOAT:\n                nts.setFloatValue(val.floatValue());\n                break;\n            case DOUBLE:\n                nts.setDoubleValue(val.doubleValue());\n                break;\n            default:\n                throw new AssertionError(\"Should never get here\");\n        }\n        return internalTokenStream;\n    }\n    if (!fieldType().tokenized()) {\n        if (stringValue() \u003d\u003d null) {\n            throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n        }\n        if (!(internalTokenStream instanceof StringTokenStream)) {\n            internalTokenStream \u003d new StringTokenStream();\n        }\n        ((StringTokenStream) internalTokenStream).setValue(stringValue());\n        return internalTokenStream;\n    }\n    if (tokenStream !\u003d null) {\n        return tokenStream;\n    } else if (readerValue() !\u003d null) {\n        return analyzer.tokenStream(name(), readerValue());\n    } else if (stringValue() !\u003d null) {\n        return analyzer.tokenStream(name(), stringValue());\n    }\n    throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value; this\u003d\" + this);\n}",
      "path": "lucene/core/src/java/org/apache/lucene/document/Field.java",
      "functionStartLine": 502,
      "functionName": "tokenStream",
      "functionAnnotation": "@Override",
      "functionDoc": "",
      "diff": "@@ -1,49 +1,49 @@\n @Override\n public TokenStream tokenStream(Analyzer analyzer) throws IOException {\n     if (!fieldType().indexed()) {\n         return null;\n     }\n     final NumericType numericType \u003d fieldType().numericType();\n     if (numericType !\u003d null) {\n         if (!(internalTokenStream instanceof NumericTokenStream)) {\n             internalTokenStream \u003d new NumericTokenStream(type.numericPrecisionStep());\n         }\n         final NumericTokenStream nts \u003d (NumericTokenStream) internalTokenStream;\n         final Number val \u003d (Number) fieldsData;\n         switch(numericType) {\n             case INT:\n                 nts.setIntValue(val.intValue());\n                 break;\n             case LONG:\n                 nts.setLongValue(val.longValue());\n                 break;\n             case FLOAT:\n                 nts.setFloatValue(val.floatValue());\n                 break;\n             case DOUBLE:\n                 nts.setDoubleValue(val.doubleValue());\n                 break;\n             default:\n                 throw new AssertionError(\"Should never get here\");\n         }\n         return internalTokenStream;\n     }\n     if (!fieldType().tokenized()) {\n         if (stringValue() \u003d\u003d null) {\n             throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n         }\n         if (!(internalTokenStream instanceof StringTokenStream)) {\n             internalTokenStream \u003d new StringTokenStream();\n         }\n         ((StringTokenStream) internalTokenStream).setValue(stringValue());\n         return internalTokenStream;\n     }\n     if (tokenStream !\u003d null) {\n         return tokenStream;\n     } else if (readerValue() !\u003d null) {\n         return analyzer.tokenStream(name(), readerValue());\n     } else if (stringValue() !\u003d null) {\n         return analyzer.tokenStream(name(), stringValue());\n     }\n-    throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value\");\n+    throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value; this\u003d\" + this);\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "f092795fe94ba727f7368b63d8eb1ecd39749fc4": {
      "type": "Ybodychange",
      "commitMessage": "LUCENE-5097: Analyzer now has an additional tokenStream(String fieldName, String text) method, so wrapping by StringReader for common use is no longer needed. This method uses an internal reuseable reader, which was previously only used by the Field class.\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1500862 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "2013/7/9 上午1:55",
      "commitName": "f092795fe94ba727f7368b63d8eb1ecd39749fc4",
      "commitAuthor": "Uwe Schindler",
      "commitDateOld": "2013/1/22 下午2:36",
      "commitNameOld": "06bf9a0857e997e7c5251ca8546556d1cdadf80f",
      "commitAuthorOld": "Robert Muir",
      "daysBetweenCommits": 167.47,
      "commitsBetweenForRepo": 1345,
      "commitsBetweenForFile": 1,
      "actualSource": "@Override\npublic TokenStream tokenStream(Analyzer analyzer) throws IOException {\n    if (!fieldType().indexed()) {\n        return null;\n    }\n    final NumericType numericType \u003d fieldType().numericType();\n    if (numericType !\u003d null) {\n        if (!(internalTokenStream instanceof NumericTokenStream)) {\n            internalTokenStream \u003d new NumericTokenStream(type.numericPrecisionStep());\n        }\n        final NumericTokenStream nts \u003d (NumericTokenStream) internalTokenStream;\n        final Number val \u003d (Number) fieldsData;\n        switch(numericType) {\n            case INT:\n                nts.setIntValue(val.intValue());\n                break;\n            case LONG:\n                nts.setLongValue(val.longValue());\n                break;\n            case FLOAT:\n                nts.setFloatValue(val.floatValue());\n                break;\n            case DOUBLE:\n                nts.setDoubleValue(val.doubleValue());\n                break;\n            default:\n                throw new AssertionError(\"Should never get here\");\n        }\n        return internalTokenStream;\n    }\n    if (!fieldType().tokenized()) {\n        if (stringValue() \u003d\u003d null) {\n            throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n        }\n        if (!(internalTokenStream instanceof StringTokenStream)) {\n            internalTokenStream \u003d new StringTokenStream();\n        }\n        ((StringTokenStream) internalTokenStream).setValue(stringValue());\n        return internalTokenStream;\n    }\n    if (tokenStream !\u003d null) {\n        return tokenStream;\n    } else if (readerValue() !\u003d null) {\n        return analyzer.tokenStream(name(), readerValue());\n    } else if (stringValue() !\u003d null) {\n        return analyzer.tokenStream(name(), stringValue());\n    }\n    throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value\");\n}",
      "path": "lucene/core/src/java/org/apache/lucene/document/Field.java",
      "functionStartLine": 502,
      "functionName": "tokenStream",
      "functionAnnotation": "@Override",
      "functionDoc": "",
      "diff": "@@ -1,53 +1,49 @@\n @Override\n public TokenStream tokenStream(Analyzer analyzer) throws IOException {\n     if (!fieldType().indexed()) {\n         return null;\n     }\n     final NumericType numericType \u003d fieldType().numericType();\n     if (numericType !\u003d null) {\n         if (!(internalTokenStream instanceof NumericTokenStream)) {\n             internalTokenStream \u003d new NumericTokenStream(type.numericPrecisionStep());\n         }\n         final NumericTokenStream nts \u003d (NumericTokenStream) internalTokenStream;\n         final Number val \u003d (Number) fieldsData;\n         switch(numericType) {\n             case INT:\n                 nts.setIntValue(val.intValue());\n                 break;\n             case LONG:\n                 nts.setLongValue(val.longValue());\n                 break;\n             case FLOAT:\n                 nts.setFloatValue(val.floatValue());\n                 break;\n             case DOUBLE:\n                 nts.setDoubleValue(val.doubleValue());\n                 break;\n             default:\n                 throw new AssertionError(\"Should never get here\");\n         }\n         return internalTokenStream;\n     }\n     if (!fieldType().tokenized()) {\n         if (stringValue() \u003d\u003d null) {\n             throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n         }\n         if (!(internalTokenStream instanceof StringTokenStream)) {\n             internalTokenStream \u003d new StringTokenStream();\n         }\n         ((StringTokenStream) internalTokenStream).setValue(stringValue());\n         return internalTokenStream;\n     }\n     if (tokenStream !\u003d null) {\n         return tokenStream;\n     } else if (readerValue() !\u003d null) {\n         return analyzer.tokenStream(name(), readerValue());\n     } else if (stringValue() !\u003d null) {\n-        if (internalReader \u003d\u003d null) {\n-            internalReader \u003d new ReusableStringReader();\n-        }\n-        internalReader.setValue(stringValue());\n-        return analyzer.tokenStream(name(), internalReader);\n+        return analyzer.tokenStream(name(), stringValue());\n     }\n     throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value\");\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "e2f54df3ca7639f143b195f75adbc5ee97187b92": {
      "type": "Yannotationchange",
      "commitMessage": "fix missing Overrides\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1420195 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "2012/12/11 下午10:31",
      "commitName": "e2f54df3ca7639f143b195f75adbc5ee97187b92",
      "commitAuthor": "Shai Erera",
      "commitDateOld": "2012/9/20 上午8:17",
      "commitNameOld": "c52930873497009e3a623d00b5bd543bb9e6d12b",
      "commitAuthorOld": "Robert Muir",
      "daysBetweenCommits": 82.59,
      "commitsBetweenForRepo": 672,
      "commitsBetweenForFile": 1,
      "actualSource": "@Override\npublic TokenStream tokenStream(Analyzer analyzer) throws IOException {\n    if (!fieldType().indexed()) {\n        return null;\n    }\n    final NumericType numericType \u003d fieldType().numericType();\n    if (numericType !\u003d null) {\n        if (!(internalTokenStream instanceof NumericTokenStream)) {\n            internalTokenStream \u003d new NumericTokenStream(type.numericPrecisionStep());\n        }\n        final NumericTokenStream nts \u003d (NumericTokenStream) internalTokenStream;\n        final Number val \u003d (Number) fieldsData;\n        switch(numericType) {\n            case INT:\n                nts.setIntValue(val.intValue());\n                break;\n            case LONG:\n                nts.setLongValue(val.longValue());\n                break;\n            case FLOAT:\n                nts.setFloatValue(val.floatValue());\n                break;\n            case DOUBLE:\n                nts.setDoubleValue(val.doubleValue());\n                break;\n            default:\n                throw new AssertionError(\"Should never get here\");\n        }\n        return internalTokenStream;\n    }\n    if (!fieldType().tokenized()) {\n        if (stringValue() \u003d\u003d null) {\n            throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n        }\n        if (!(internalTokenStream instanceof StringTokenStream)) {\n            internalTokenStream \u003d new StringTokenStream();\n        }\n        ((StringTokenStream) internalTokenStream).setValue(stringValue());\n        return internalTokenStream;\n    }\n    if (tokenStream !\u003d null) {\n        return tokenStream;\n    } else if (readerValue() !\u003d null) {\n        return analyzer.tokenStream(name(), readerValue());\n    } else if (stringValue() !\u003d null) {\n        if (internalReader \u003d\u003d null) {\n            internalReader \u003d new ReusableStringReader();\n        }\n        internalReader.setValue(stringValue());\n        return analyzer.tokenStream(name(), internalReader);\n    }\n    throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value\");\n}",
      "path": "lucene/core/src/java/org/apache/lucene/document/Field.java",
      "functionStartLine": 509,
      "functionName": "tokenStream",
      "functionAnnotation": "@Override",
      "functionDoc": "",
      "diff": "@@ -1,52 +1,53 @@\n+@Override\n public TokenStream tokenStream(Analyzer analyzer) throws IOException {\n     if (!fieldType().indexed()) {\n         return null;\n     }\n     final NumericType numericType \u003d fieldType().numericType();\n     if (numericType !\u003d null) {\n         if (!(internalTokenStream instanceof NumericTokenStream)) {\n             internalTokenStream \u003d new NumericTokenStream(type.numericPrecisionStep());\n         }\n         final NumericTokenStream nts \u003d (NumericTokenStream) internalTokenStream;\n         final Number val \u003d (Number) fieldsData;\n         switch(numericType) {\n             case INT:\n                 nts.setIntValue(val.intValue());\n                 break;\n             case LONG:\n                 nts.setLongValue(val.longValue());\n                 break;\n             case FLOAT:\n                 nts.setFloatValue(val.floatValue());\n                 break;\n             case DOUBLE:\n                 nts.setDoubleValue(val.doubleValue());\n                 break;\n             default:\n                 throw new AssertionError(\"Should never get here\");\n         }\n         return internalTokenStream;\n     }\n     if (!fieldType().tokenized()) {\n         if (stringValue() \u003d\u003d null) {\n             throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n         }\n         if (!(internalTokenStream instanceof StringTokenStream)) {\n             internalTokenStream \u003d new StringTokenStream();\n         }\n         ((StringTokenStream) internalTokenStream).setValue(stringValue());\n         return internalTokenStream;\n     }\n     if (tokenStream !\u003d null) {\n         return tokenStream;\n     } else if (readerValue() !\u003d null) {\n         return analyzer.tokenStream(name(), readerValue());\n     } else if (stringValue() !\u003d null) {\n         if (internalReader \u003d\u003d null) {\n             internalReader \u003d new ReusableStringReader();\n         }\n         internalReader.setValue(stringValue());\n         return analyzer.tokenStream(name(), internalReader);\n     }\n     throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value\");\n }\n\\ No newline at end of file\n",
      "extendedDetails": {
        "oldValue": "",
        "newValue": "@Override"
      }
    },
    "8f88aa64978a61125adafff544c8e5084d497fb5": {
      "type": "Ybodychange",
      "commitMessage": "Turn some \"assert false\" in switch and switch-like statements into AssertionErrors. If we get into the default block we are wrong and we can also throw Ex, because then there is logic error (e.g. after new enum constant was added)\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1379450 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "2012/8/31 下午9:55",
      "commitName": "8f88aa64978a61125adafff544c8e5084d497fb5",
      "commitAuthor": "Uwe Schindler",
      "commitDateOld": "2012/8/30 下午10:33",
      "commitNameOld": "a4702d3711e8ad2ac5ef455e4182f2da80011c86",
      "commitAuthorOld": "Robert Muir",
      "daysBetweenCommits": 0.97,
      "commitsBetweenForRepo": 17,
      "commitsBetweenForFile": 1,
      "actualSource": "public TokenStream tokenStream(Analyzer analyzer) throws IOException {\n    if (!fieldType().indexed()) {\n        return null;\n    }\n    final NumericType numericType \u003d fieldType().numericType();\n    if (numericType !\u003d null) {\n        if (!(internalTokenStream instanceof NumericTokenStream)) {\n            internalTokenStream \u003d new NumericTokenStream(type.numericPrecisionStep());\n        }\n        final NumericTokenStream nts \u003d (NumericTokenStream) internalTokenStream;\n        final Number val \u003d (Number) fieldsData;\n        switch(numericType) {\n            case INT:\n                nts.setIntValue(val.intValue());\n                break;\n            case LONG:\n                nts.setLongValue(val.longValue());\n                break;\n            case FLOAT:\n                nts.setFloatValue(val.floatValue());\n                break;\n            case DOUBLE:\n                nts.setDoubleValue(val.doubleValue());\n                break;\n            default:\n                throw new AssertionError(\"Should never get here\");\n        }\n        return internalTokenStream;\n    }\n    if (!fieldType().tokenized()) {\n        if (stringValue() \u003d\u003d null) {\n            throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n        }\n        if (!(internalTokenStream instanceof StringTokenStream)) {\n            internalTokenStream \u003d new StringTokenStream();\n        }\n        ((StringTokenStream) internalTokenStream).setValue(stringValue());\n        return internalTokenStream;\n    }\n    if (tokenStream !\u003d null) {\n        return tokenStream;\n    } else if (readerValue() !\u003d null) {\n        return analyzer.tokenStream(name(), readerValue());\n    } else if (stringValue() !\u003d null) {\n        if (internalReader \u003d\u003d null) {\n            internalReader \u003d new ReusableStringReader();\n        }\n        internalReader.setValue(stringValue());\n        return analyzer.tokenStream(name(), internalReader);\n    }\n    throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value\");\n}",
      "path": "lucene/core/src/java/org/apache/lucene/document/Field.java",
      "functionStartLine": 495,
      "functionName": "tokenStream",
      "functionAnnotation": "",
      "functionDoc": "",
      "diff": "@@ -1,52 +1,52 @@\n public TokenStream tokenStream(Analyzer analyzer) throws IOException {\n     if (!fieldType().indexed()) {\n         return null;\n     }\n     final NumericType numericType \u003d fieldType().numericType();\n     if (numericType !\u003d null) {\n         if (!(internalTokenStream instanceof NumericTokenStream)) {\n             internalTokenStream \u003d new NumericTokenStream(type.numericPrecisionStep());\n         }\n         final NumericTokenStream nts \u003d (NumericTokenStream) internalTokenStream;\n         final Number val \u003d (Number) fieldsData;\n         switch(numericType) {\n             case INT:\n                 nts.setIntValue(val.intValue());\n                 break;\n             case LONG:\n                 nts.setLongValue(val.longValue());\n                 break;\n             case FLOAT:\n                 nts.setFloatValue(val.floatValue());\n                 break;\n             case DOUBLE:\n                 nts.setDoubleValue(val.doubleValue());\n                 break;\n             default:\n-                assert false : \"Should never get here\";\n+                throw new AssertionError(\"Should never get here\");\n         }\n         return internalTokenStream;\n     }\n     if (!fieldType().tokenized()) {\n         if (stringValue() \u003d\u003d null) {\n             throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n         }\n         if (!(internalTokenStream instanceof StringTokenStream)) {\n             internalTokenStream \u003d new StringTokenStream();\n         }\n         ((StringTokenStream) internalTokenStream).setValue(stringValue());\n         return internalTokenStream;\n     }\n     if (tokenStream !\u003d null) {\n         return tokenStream;\n     } else if (readerValue() !\u003d null) {\n         return analyzer.tokenStream(name(), readerValue());\n     } else if (stringValue() !\u003d null) {\n         if (internalReader \u003d\u003d null) {\n             internalReader \u003d new ReusableStringReader();\n         }\n         internalReader.setValue(stringValue());\n         return analyzer.tokenStream(name(), internalReader);\n     }\n     throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value\");\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "2afa06672fe204f468a72d7c85b23158345d5597": {
      "type": "Ydocchange",
      "commitMessage": "remove useless inheritdocs (if you dont add to it, it does nothing)\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1377893 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "2012/8/28 上午6:30",
      "commitName": "2afa06672fe204f468a72d7c85b23158345d5597",
      "commitAuthor": "Robert Muir",
      "commitDateOld": "2012/8/28 上午4:43",
      "commitNameOld": "682123b2feb71ec32f8f39d2889604ea6e6d2eb8",
      "commitAuthorOld": "Robert Muir",
      "daysBetweenCommits": 0.07,
      "commitsBetweenForRepo": 3,
      "commitsBetweenForFile": 1,
      "actualSource": "public TokenStream tokenStream(Analyzer analyzer) throws IOException {\n    if (!fieldType().indexed()) {\n        return null;\n    }\n    final NumericType numericType \u003d fieldType().numericType();\n    if (numericType !\u003d null) {\n        if (!(internalTokenStream instanceof NumericTokenStream)) {\n            internalTokenStream \u003d new NumericTokenStream(type.numericPrecisionStep());\n        }\n        final NumericTokenStream nts \u003d (NumericTokenStream) internalTokenStream;\n        final Number val \u003d (Number) fieldsData;\n        switch(numericType) {\n            case INT:\n                nts.setIntValue(val.intValue());\n                break;\n            case LONG:\n                nts.setLongValue(val.longValue());\n                break;\n            case FLOAT:\n                nts.setFloatValue(val.floatValue());\n                break;\n            case DOUBLE:\n                nts.setDoubleValue(val.doubleValue());\n                break;\n            default:\n                assert false : \"Should never get here\";\n        }\n        return internalTokenStream;\n    }\n    if (!fieldType().tokenized()) {\n        if (stringValue() \u003d\u003d null) {\n            throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n        }\n        if (!(internalTokenStream instanceof StringTokenStream)) {\n            internalTokenStream \u003d new StringTokenStream();\n        }\n        ((StringTokenStream) internalTokenStream).setValue(stringValue());\n        return internalTokenStream;\n    }\n    if (tokenStream !\u003d null) {\n        return tokenStream;\n    } else if (readerValue() !\u003d null) {\n        return analyzer.tokenStream(name(), readerValue());\n    } else if (stringValue() !\u003d null) {\n        if (internalReader \u003d\u003d null) {\n            internalReader \u003d new ReusableStringReader();\n        }\n        internalReader.setValue(stringValue());\n        return analyzer.tokenStream(name(), internalReader);\n    }\n    throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value\");\n}",
      "path": "lucene/core/src/java/org/apache/lucene/document/Field.java",
      "functionStartLine": 408,
      "functionName": "tokenStream",
      "functionAnnotation": "",
      "functionDoc": "",
      "diff": "",
      "extendedDetails": {
        "oldValue": "@inheritDoc}\n",
        "newValue": ""
      }
    },
    "518fc20d1cf385650202ff9a3b35136ed9d646e5": {
      "type": "Ybodychange",
      "commitMessage": "LUCENE-4315: Add ReusableStringReader to Field.java\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1376261 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "2012/8/23 上午5:29",
      "commitName": "518fc20d1cf385650202ff9a3b35136ed9d646e5",
      "commitAuthor": "Uwe Schindler",
      "commitDateOld": "2012/8/21 下午8:43",
      "commitNameOld": "e53aee7739be1c04bd1673a55b4956efb63c337f",
      "commitAuthorOld": "Uwe Schindler",
      "daysBetweenCommits": 1.37,
      "commitsBetweenForRepo": 8,
      "commitsBetweenForFile": 1,
      "actualSource": "public TokenStream tokenStream(Analyzer analyzer) throws IOException {\n    if (!fieldType().indexed()) {\n        return null;\n    }\n    final NumericType numericType \u003d fieldType().numericType();\n    if (numericType !\u003d null) {\n        if (!(internalTokenStream instanceof NumericTokenStream)) {\n            internalTokenStream \u003d new NumericTokenStream(type.numericPrecisionStep());\n        }\n        final NumericTokenStream nts \u003d (NumericTokenStream) internalTokenStream;\n        final Number val \u003d (Number) fieldsData;\n        switch(numericType) {\n            case INT:\n                nts.setIntValue(val.intValue());\n                break;\n            case LONG:\n                nts.setLongValue(val.longValue());\n                break;\n            case FLOAT:\n                nts.setFloatValue(val.floatValue());\n                break;\n            case DOUBLE:\n                nts.setDoubleValue(val.doubleValue());\n                break;\n            default:\n                assert false : \"Should never get here\";\n        }\n        return internalTokenStream;\n    }\n    if (!fieldType().tokenized()) {\n        if (stringValue() \u003d\u003d null) {\n            throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n        }\n        if (!(internalTokenStream instanceof StringTokenStream)) {\n            internalTokenStream \u003d new StringTokenStream();\n        }\n        ((StringTokenStream) internalTokenStream).setValue(stringValue());\n        return internalTokenStream;\n    }\n    if (tokenStream !\u003d null) {\n        return tokenStream;\n    } else if (readerValue() !\u003d null) {\n        return analyzer.tokenStream(name(), readerValue());\n    } else if (stringValue() !\u003d null) {\n        if (internalReader \u003d\u003d null) {\n            internalReader \u003d new ReusableStringReader();\n        }\n        internalReader.setValue(stringValue());\n        return analyzer.tokenStream(name(), internalReader);\n    }\n    throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value\");\n}",
      "path": "lucene/core/src/java/org/apache/lucene/document/Field.java",
      "functionStartLine": 411,
      "functionName": "tokenStream",
      "functionAnnotation": "",
      "functionDoc": "@inheritDoc}\n",
      "diff": "@@ -1,48 +1,52 @@\n public TokenStream tokenStream(Analyzer analyzer) throws IOException {\n     if (!fieldType().indexed()) {\n         return null;\n     }\n     final NumericType numericType \u003d fieldType().numericType();\n     if (numericType !\u003d null) {\n         if (!(internalTokenStream instanceof NumericTokenStream)) {\n             internalTokenStream \u003d new NumericTokenStream(type.numericPrecisionStep());\n         }\n         final NumericTokenStream nts \u003d (NumericTokenStream) internalTokenStream;\n         final Number val \u003d (Number) fieldsData;\n         switch(numericType) {\n             case INT:\n                 nts.setIntValue(val.intValue());\n                 break;\n             case LONG:\n                 nts.setLongValue(val.longValue());\n                 break;\n             case FLOAT:\n                 nts.setFloatValue(val.floatValue());\n                 break;\n             case DOUBLE:\n                 nts.setDoubleValue(val.doubleValue());\n                 break;\n             default:\n                 assert false : \"Should never get here\";\n         }\n         return internalTokenStream;\n     }\n     if (!fieldType().tokenized()) {\n         if (stringValue() \u003d\u003d null) {\n             throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n         }\n         if (!(internalTokenStream instanceof StringTokenStream)) {\n             internalTokenStream \u003d new StringTokenStream();\n         }\n         ((StringTokenStream) internalTokenStream).setValue(stringValue());\n         return internalTokenStream;\n     }\n     if (tokenStream !\u003d null) {\n         return tokenStream;\n     } else if (readerValue() !\u003d null) {\n         return analyzer.tokenStream(name(), readerValue());\n     } else if (stringValue() !\u003d null) {\n-        return analyzer.tokenStream(name(), new StringReader(stringValue()));\n+        if (internalReader \u003d\u003d null) {\n+            internalReader \u003d new ReusableStringReader();\n+        }\n+        internalReader.setValue(stringValue());\n+        return analyzer.tokenStream(name(), internalReader);\n     }\n     throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value\");\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "e53aee7739be1c04bd1673a55b4956efb63c337f": {
      "type": "Ybodychange",
      "commitMessage": "LUCENE-4317: Improve reuse of internal TokenStreams in oal.document.Field.\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1375507 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "2012/8/21 下午8:43",
      "commitName": "e53aee7739be1c04bd1673a55b4956efb63c337f",
      "commitAuthor": "Uwe Schindler",
      "commitDateOld": "2012/8/4 上午4:26",
      "commitNameOld": "8f726e254bc060d45590f72411db69c943e1216b",
      "commitAuthorOld": "Robert Muir",
      "daysBetweenCommits": 17.68,
      "commitsBetweenForRepo": 211,
      "commitsBetweenForFile": 1,
      "actualSource": "public TokenStream tokenStream(Analyzer analyzer) throws IOException {\n    if (!fieldType().indexed()) {\n        return null;\n    }\n    final NumericType numericType \u003d fieldType().numericType();\n    if (numericType !\u003d null) {\n        if (!(internalTokenStream instanceof NumericTokenStream)) {\n            internalTokenStream \u003d new NumericTokenStream(type.numericPrecisionStep());\n        }\n        final NumericTokenStream nts \u003d (NumericTokenStream) internalTokenStream;\n        final Number val \u003d (Number) fieldsData;\n        switch(numericType) {\n            case INT:\n                nts.setIntValue(val.intValue());\n                break;\n            case LONG:\n                nts.setLongValue(val.longValue());\n                break;\n            case FLOAT:\n                nts.setFloatValue(val.floatValue());\n                break;\n            case DOUBLE:\n                nts.setDoubleValue(val.doubleValue());\n                break;\n            default:\n                assert false : \"Should never get here\";\n        }\n        return internalTokenStream;\n    }\n    if (!fieldType().tokenized()) {\n        if (stringValue() \u003d\u003d null) {\n            throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n        }\n        if (!(internalTokenStream instanceof StringTokenStream)) {\n            internalTokenStream \u003d new StringTokenStream();\n        }\n        ((StringTokenStream) internalTokenStream).setValue(stringValue());\n        return internalTokenStream;\n    }\n    if (tokenStream !\u003d null) {\n        return tokenStream;\n    } else if (readerValue() !\u003d null) {\n        return analyzer.tokenStream(name(), readerValue());\n    } else if (stringValue() !\u003d null) {\n        return analyzer.tokenStream(name(), new StringReader(stringValue()));\n    }\n    throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value\");\n}",
      "path": "lucene/core/src/java/org/apache/lucene/document/Field.java",
      "functionStartLine": 411,
      "functionName": "tokenStream",
      "functionAnnotation": "",
      "functionDoc": "@inheritDoc}\n",
      "diff": "@@ -1,67 +1,48 @@\n public TokenStream tokenStream(Analyzer analyzer) throws IOException {\n     if (!fieldType().indexed()) {\n         return null;\n     }\n     final NumericType numericType \u003d fieldType().numericType();\n     if (numericType !\u003d null) {\n-        if (numericTokenStream \u003d\u003d null) {\n-            numericTokenStream \u003d new NumericTokenStream(type.numericPrecisionStep());\n-            final Number val \u003d (Number) fieldsData;\n-            switch(numericType) {\n-                case INT:\n-                    numericTokenStream.setIntValue(val.intValue());\n-                    break;\n-                case LONG:\n-                    numericTokenStream.setLongValue(val.longValue());\n-                    break;\n-                case FLOAT:\n-                    numericTokenStream.setFloatValue(val.floatValue());\n-                    break;\n-                case DOUBLE:\n-                    numericTokenStream.setDoubleValue(val.doubleValue());\n-                    break;\n-                default:\n-                    assert false : \"Should never get here\";\n-            }\n-        } else {\n+        if (!(internalTokenStream instanceof NumericTokenStream)) {\n+            internalTokenStream \u003d new NumericTokenStream(type.numericPrecisionStep());\n         }\n-        return numericTokenStream;\n+        final NumericTokenStream nts \u003d (NumericTokenStream) internalTokenStream;\n+        final Number val \u003d (Number) fieldsData;\n+        switch(numericType) {\n+            case INT:\n+                nts.setIntValue(val.intValue());\n+                break;\n+            case LONG:\n+                nts.setLongValue(val.longValue());\n+                break;\n+            case FLOAT:\n+                nts.setFloatValue(val.floatValue());\n+                break;\n+            case DOUBLE:\n+                nts.setDoubleValue(val.doubleValue());\n+                break;\n+            default:\n+                assert false : \"Should never get here\";\n+        }\n+        return internalTokenStream;\n     }\n     if (!fieldType().tokenized()) {\n         if (stringValue() \u003d\u003d null) {\n             throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n         }\n-        return new TokenStream() {\n-\n-            CharTermAttribute termAttribute \u003d addAttribute(CharTermAttribute.class);\n-\n-            OffsetAttribute offsetAttribute \u003d addAttribute(OffsetAttribute.class);\n-\n-            boolean used;\n-\n-            @Override\n-            public boolean incrementToken() {\n-                if (used) {\n-                    return false;\n-                }\n-                termAttribute.setEmpty().append(stringValue());\n-                offsetAttribute.setOffset(0, stringValue().length());\n-                used \u003d true;\n-                return true;\n-            }\n-\n-            @Override\n-            public void reset() {\n-                used \u003d false;\n-            }\n-        };\n+        if (!(internalTokenStream instanceof StringTokenStream)) {\n+            internalTokenStream \u003d new StringTokenStream();\n+        }\n+        ((StringTokenStream) internalTokenStream).setValue(stringValue());\n+        return internalTokenStream;\n     }\n     if (tokenStream !\u003d null) {\n         return tokenStream;\n     } else if (readerValue() !\u003d null) {\n         return analyzer.tokenStream(name(), readerValue());\n     } else if (stringValue() !\u003d null) {\n         return analyzer.tokenStream(name(), new StringReader(stringValue()));\n     }\n     throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value\");\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "fd16190940d7495e985f44ce7504562c8bbc91e6": {
      "type": "Ybodychange",
      "commitMessage": "LUCENE-4172: clean up redundant throws clauses\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1355069 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "2012/6/29 上午12:39",
      "commitName": "fd16190940d7495e985f44ce7504562c8bbc91e6",
      "commitAuthor": "Steven Rowe",
      "commitDateOld": "2012/6/12 上午3:26",
      "commitNameOld": "2ac3eb27c41691c7a61b58673be6fe9a5a0eed9e",
      "commitAuthorOld": "Chris M. Hostetter",
      "daysBetweenCommits": 16.88,
      "commitsBetweenForRepo": 110,
      "commitsBetweenForFile": 1,
      "actualSource": "public TokenStream tokenStream(Analyzer analyzer) throws IOException {\n    if (!fieldType().indexed()) {\n        return null;\n    }\n    final NumericType numericType \u003d fieldType().numericType();\n    if (numericType !\u003d null) {\n        if (numericTokenStream \u003d\u003d null) {\n            numericTokenStream \u003d new NumericTokenStream(type.numericPrecisionStep());\n            final Number val \u003d (Number) fieldsData;\n            switch(numericType) {\n                case INT:\n                    numericTokenStream.setIntValue(val.intValue());\n                    break;\n                case LONG:\n                    numericTokenStream.setLongValue(val.longValue());\n                    break;\n                case FLOAT:\n                    numericTokenStream.setFloatValue(val.floatValue());\n                    break;\n                case DOUBLE:\n                    numericTokenStream.setDoubleValue(val.doubleValue());\n                    break;\n                default:\n                    assert false : \"Should never get here\";\n            }\n        } else {\n        }\n        return numericTokenStream;\n    }\n    if (!fieldType().tokenized()) {\n        if (stringValue() \u003d\u003d null) {\n            throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n        }\n        return new TokenStream() {\n\n            CharTermAttribute termAttribute \u003d addAttribute(CharTermAttribute.class);\n\n            OffsetAttribute offsetAttribute \u003d addAttribute(OffsetAttribute.class);\n\n            boolean used;\n\n            @Override\n            public boolean incrementToken() {\n                if (used) {\n                    return false;\n                }\n                termAttribute.setEmpty().append(stringValue());\n                offsetAttribute.setOffset(0, stringValue().length());\n                used \u003d true;\n                return true;\n            }\n\n            @Override\n            public void reset() {\n                used \u003d false;\n            }\n        };\n    }\n    if (tokenStream !\u003d null) {\n        return tokenStream;\n    } else if (readerValue() !\u003d null) {\n        return analyzer.tokenStream(name(), readerValue());\n    } else if (stringValue() !\u003d null) {\n        return analyzer.tokenStream(name(), new StringReader(stringValue()));\n    }\n    throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value\");\n}",
      "path": "lucene/core/src/java/org/apache/lucene/document/Field.java",
      "functionStartLine": 424,
      "functionName": "tokenStream",
      "functionAnnotation": "",
      "functionDoc": "@inheritDoc}\n",
      "diff": "@@ -1,67 +1,67 @@\n public TokenStream tokenStream(Analyzer analyzer) throws IOException {\n     if (!fieldType().indexed()) {\n         return null;\n     }\n     final NumericType numericType \u003d fieldType().numericType();\n     if (numericType !\u003d null) {\n         if (numericTokenStream \u003d\u003d null) {\n             numericTokenStream \u003d new NumericTokenStream(type.numericPrecisionStep());\n             final Number val \u003d (Number) fieldsData;\n             switch(numericType) {\n                 case INT:\n                     numericTokenStream.setIntValue(val.intValue());\n                     break;\n                 case LONG:\n                     numericTokenStream.setLongValue(val.longValue());\n                     break;\n                 case FLOAT:\n                     numericTokenStream.setFloatValue(val.floatValue());\n                     break;\n                 case DOUBLE:\n                     numericTokenStream.setDoubleValue(val.doubleValue());\n                     break;\n                 default:\n                     assert false : \"Should never get here\";\n             }\n         } else {\n         }\n         return numericTokenStream;\n     }\n     if (!fieldType().tokenized()) {\n         if (stringValue() \u003d\u003d null) {\n             throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n         }\n         return new TokenStream() {\n \n             CharTermAttribute termAttribute \u003d addAttribute(CharTermAttribute.class);\n \n             OffsetAttribute offsetAttribute \u003d addAttribute(OffsetAttribute.class);\n \n             boolean used;\n \n             @Override\n-            public boolean incrementToken() throws IOException {\n+            public boolean incrementToken() {\n                 if (used) {\n                     return false;\n                 }\n                 termAttribute.setEmpty().append(stringValue());\n                 offsetAttribute.setOffset(0, stringValue().length());\n                 used \u003d true;\n                 return true;\n             }\n \n             @Override\n-            public void reset() throws IOException {\n+            public void reset() {\n                 used \u003d false;\n             }\n         };\n     }\n     if (tokenStream !\u003d null) {\n         return tokenStream;\n     } else if (readerValue() !\u003d null) {\n         return analyzer.tokenStream(name(), readerValue());\n     } else if (stringValue() !\u003d null) {\n         return analyzer.tokenStream(name(), new StringReader(stringValue()));\n     }\n     throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value\");\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "854c9ac45223b64acf3e7e4c0a77383a9441268f": {
      "type": "Ybodychange",
      "commitMessage": "LUCENE-3777: separate out Int/Long/Float/DoubleField to reduce traps\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1245583 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "2012/2/17 下午10:46",
      "commitName": "854c9ac45223b64acf3e7e4c0a77383a9441268f",
      "commitAuthor": "Michael McCandless",
      "commitDateOld": "2012/2/8 上午3:59",
      "commitNameOld": "eb0ab3d392a42c1835f79bcd7f5404bcc50c8e4c",
      "commitAuthorOld": "Steven Rowe",
      "daysBetweenCommits": 9.78,
      "commitsBetweenForRepo": 124,
      "commitsBetweenForFile": 1,
      "actualSource": "public TokenStream tokenStream(Analyzer analyzer) throws IOException {\n    if (!fieldType().indexed()) {\n        return null;\n    }\n    final NumericType numericType \u003d fieldType().numericType();\n    if (numericType !\u003d null) {\n        if (numericTokenStream \u003d\u003d null) {\n            numericTokenStream \u003d new NumericTokenStream(type.numericPrecisionStep());\n            final Number val \u003d (Number) fieldsData;\n            switch(numericType) {\n                case INT:\n                    numericTokenStream.setIntValue(val.intValue());\n                    break;\n                case LONG:\n                    numericTokenStream.setLongValue(val.longValue());\n                    break;\n                case FLOAT:\n                    numericTokenStream.setFloatValue(val.floatValue());\n                    break;\n                case DOUBLE:\n                    numericTokenStream.setDoubleValue(val.doubleValue());\n                    break;\n                default:\n                    assert false : \"Should never get here\";\n            }\n        } else {\n        }\n        return numericTokenStream;\n    }\n    if (!fieldType().tokenized()) {\n        if (stringValue() \u003d\u003d null) {\n            throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n        }\n        return new TokenStream() {\n\n            CharTermAttribute termAttribute \u003d addAttribute(CharTermAttribute.class);\n\n            OffsetAttribute offsetAttribute \u003d addAttribute(OffsetAttribute.class);\n\n            boolean used;\n\n            @Override\n            public boolean incrementToken() throws IOException {\n                if (used) {\n                    return false;\n                }\n                termAttribute.setEmpty().append(stringValue());\n                offsetAttribute.setOffset(0, stringValue().length());\n                used \u003d true;\n                return true;\n            }\n\n            @Override\n            public void reset() throws IOException {\n                used \u003d false;\n            }\n        };\n    }\n    if (tokenStream !\u003d null) {\n        return tokenStream;\n    } else if (readerValue() !\u003d null) {\n        return analyzer.tokenStream(name(), readerValue());\n    } else if (stringValue() !\u003d null) {\n        return analyzer.tokenStream(name(), new StringReader(stringValue()));\n    }\n    throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value\");\n}",
      "path": "lucene/core/src/java/org/apache/lucene/document/Field.java",
      "functionStartLine": 397,
      "functionName": "tokenStream",
      "functionAnnotation": "",
      "functionDoc": "@inheritDoc}\n",
      "diff": "@@ -1,67 +1,67 @@\n public TokenStream tokenStream(Analyzer analyzer) throws IOException {\n     if (!fieldType().indexed()) {\n         return null;\n     }\n-    final NumericField.DataType numericType \u003d fieldType().numericType();\n+    final NumericType numericType \u003d fieldType().numericType();\n     if (numericType !\u003d null) {\n         if (numericTokenStream \u003d\u003d null) {\n             numericTokenStream \u003d new NumericTokenStream(type.numericPrecisionStep());\n             final Number val \u003d (Number) fieldsData;\n             switch(numericType) {\n                 case INT:\n                     numericTokenStream.setIntValue(val.intValue());\n                     break;\n                 case LONG:\n                     numericTokenStream.setLongValue(val.longValue());\n                     break;\n                 case FLOAT:\n                     numericTokenStream.setFloatValue(val.floatValue());\n                     break;\n                 case DOUBLE:\n                     numericTokenStream.setDoubleValue(val.doubleValue());\n                     break;\n                 default:\n                     assert false : \"Should never get here\";\n             }\n         } else {\n         }\n         return numericTokenStream;\n     }\n     if (!fieldType().tokenized()) {\n         if (stringValue() \u003d\u003d null) {\n             throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n         }\n         return new TokenStream() {\n \n             CharTermAttribute termAttribute \u003d addAttribute(CharTermAttribute.class);\n \n             OffsetAttribute offsetAttribute \u003d addAttribute(OffsetAttribute.class);\n \n             boolean used;\n \n             @Override\n             public boolean incrementToken() throws IOException {\n                 if (used) {\n                     return false;\n                 }\n                 termAttribute.setEmpty().append(stringValue());\n                 offsetAttribute.setOffset(0, stringValue().length());\n                 used \u003d true;\n                 return true;\n             }\n \n             @Override\n             public void reset() throws IOException {\n                 used \u003d false;\n             }\n         };\n     }\n     if (tokenStream !\u003d null) {\n         return tokenStream;\n     } else if (readerValue() !\u003d null) {\n         return analyzer.tokenStream(name(), readerValue());\n     } else if (stringValue() !\u003d null) {\n         return analyzer.tokenStream(name(), new StringReader(stringValue()));\n     }\n     throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value\");\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "eb0ab3d392a42c1835f79bcd7f5404bcc50c8e4c": {
      "type": "Yfilerename",
      "commitMessage": "LUCENE-3753: Restructure the Lucene build system\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1241588 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "2012/2/8 上午3:59",
      "commitName": "eb0ab3d392a42c1835f79bcd7f5404bcc50c8e4c",
      "commitAuthor": "Steven Rowe",
      "commitDateOld": "2012/2/8 上午2:58",
      "commitNameOld": "8b939cb7d20160f9f8a7baf2030613f0e1e877b4",
      "commitAuthorOld": "Robert Muir",
      "daysBetweenCommits": 0.04,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "actualSource": "public TokenStream tokenStream(Analyzer analyzer) throws IOException {\n    if (!fieldType().indexed()) {\n        return null;\n    }\n    final NumericField.DataType numericType \u003d fieldType().numericType();\n    if (numericType !\u003d null) {\n        if (numericTokenStream \u003d\u003d null) {\n            numericTokenStream \u003d new NumericTokenStream(type.numericPrecisionStep());\n            final Number val \u003d (Number) fieldsData;\n            switch(numericType) {\n                case INT:\n                    numericTokenStream.setIntValue(val.intValue());\n                    break;\n                case LONG:\n                    numericTokenStream.setLongValue(val.longValue());\n                    break;\n                case FLOAT:\n                    numericTokenStream.setFloatValue(val.floatValue());\n                    break;\n                case DOUBLE:\n                    numericTokenStream.setDoubleValue(val.doubleValue());\n                    break;\n                default:\n                    assert false : \"Should never get here\";\n            }\n        } else {\n        }\n        return numericTokenStream;\n    }\n    if (!fieldType().tokenized()) {\n        if (stringValue() \u003d\u003d null) {\n            throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n        }\n        return new TokenStream() {\n\n            CharTermAttribute termAttribute \u003d addAttribute(CharTermAttribute.class);\n\n            OffsetAttribute offsetAttribute \u003d addAttribute(OffsetAttribute.class);\n\n            boolean used;\n\n            @Override\n            public boolean incrementToken() throws IOException {\n                if (used) {\n                    return false;\n                }\n                termAttribute.setEmpty().append(stringValue());\n                offsetAttribute.setOffset(0, stringValue().length());\n                used \u003d true;\n                return true;\n            }\n\n            @Override\n            public void reset() throws IOException {\n                used \u003d false;\n            }\n        };\n    }\n    if (tokenStream !\u003d null) {\n        return tokenStream;\n    } else if (readerValue() !\u003d null) {\n        return analyzer.tokenStream(name(), readerValue());\n    } else if (stringValue() !\u003d null) {\n        return analyzer.tokenStream(name(), new StringReader(stringValue()));\n    }\n    throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value\");\n}",
      "path": "lucene/core/src/java/org/apache/lucene/document/Field.java",
      "functionStartLine": 441,
      "functionName": "tokenStream",
      "functionAnnotation": "",
      "functionDoc": "@inheritDoc}\n",
      "diff": "",
      "extendedDetails": {
        "oldPath": "lucene/src/java/org/apache/lucene/document/Field.java",
        "newPath": "lucene/core/src/java/org/apache/lucene/document/Field.java"
      }
    },
    "9de01b56ebf252ffefe05e606e330a1787b94c9d": {
      "type": "Ybodychange",
      "commitMessage": "LUCENE-3453: simplify DocValues/Field API\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1231791 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "2012/1/16 上午7:05",
      "commitName": "9de01b56ebf252ffefe05e606e330a1787b94c9d",
      "commitAuthor": "Michael McCandless",
      "commitDateOld": "2011/12/11 上午2:17",
      "commitNameOld": "124728c97487911ab225397878e15c5469ba0360",
      "commitAuthorOld": "Robert Muir",
      "daysBetweenCommits": 36.2,
      "commitsBetweenForRepo": 163,
      "commitsBetweenForFile": 1,
      "actualSource": "public TokenStream tokenStream(Analyzer analyzer) throws IOException {\n    if (!fieldType().indexed()) {\n        return null;\n    }\n    final NumericField.DataType numericType \u003d fieldType().numericType();\n    if (numericType !\u003d null) {\n        if (numericTokenStream \u003d\u003d null) {\n            numericTokenStream \u003d new NumericTokenStream(type.numericPrecisionStep());\n            final Number val \u003d (Number) fieldsData;\n            switch(numericType) {\n                case INT:\n                    numericTokenStream.setIntValue(val.intValue());\n                    break;\n                case LONG:\n                    numericTokenStream.setLongValue(val.longValue());\n                    break;\n                case FLOAT:\n                    numericTokenStream.setFloatValue(val.floatValue());\n                    break;\n                case DOUBLE:\n                    numericTokenStream.setDoubleValue(val.doubleValue());\n                    break;\n                default:\n                    assert false : \"Should never get here\";\n            }\n        } else {\n        }\n        return numericTokenStream;\n    }\n    if (!fieldType().tokenized()) {\n        if (stringValue() \u003d\u003d null) {\n            throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n        }\n        return new TokenStream() {\n\n            CharTermAttribute termAttribute \u003d addAttribute(CharTermAttribute.class);\n\n            OffsetAttribute offsetAttribute \u003d addAttribute(OffsetAttribute.class);\n\n            boolean used;\n\n            @Override\n            public boolean incrementToken() throws IOException {\n                if (used) {\n                    return false;\n                }\n                termAttribute.setEmpty().append(stringValue());\n                offsetAttribute.setOffset(0, stringValue().length());\n                used \u003d true;\n                return true;\n            }\n\n            @Override\n            public void reset() throws IOException {\n                used \u003d false;\n            }\n        };\n    }\n    if (tokenStream !\u003d null) {\n        return tokenStream;\n    } else if (readerValue() !\u003d null) {\n        return analyzer.tokenStream(name(), readerValue());\n    } else if (stringValue() !\u003d null) {\n        return analyzer.tokenStream(name(), new StringReader(stringValue()));\n    }\n    throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value\");\n}",
      "path": "lucene/src/java/org/apache/lucene/document/Field.java",
      "functionStartLine": 440,
      "functionName": "tokenStream",
      "functionAnnotation": "",
      "functionDoc": "@inheritDoc}\n",
      "diff": "@@ -1,42 +1,67 @@\n public TokenStream tokenStream(Analyzer analyzer) throws IOException {\n     if (!fieldType().indexed()) {\n         return null;\n     }\n+    final NumericField.DataType numericType \u003d fieldType().numericType();\n+    if (numericType !\u003d null) {\n+        if (numericTokenStream \u003d\u003d null) {\n+            numericTokenStream \u003d new NumericTokenStream(type.numericPrecisionStep());\n+            final Number val \u003d (Number) fieldsData;\n+            switch(numericType) {\n+                case INT:\n+                    numericTokenStream.setIntValue(val.intValue());\n+                    break;\n+                case LONG:\n+                    numericTokenStream.setLongValue(val.longValue());\n+                    break;\n+                case FLOAT:\n+                    numericTokenStream.setFloatValue(val.floatValue());\n+                    break;\n+                case DOUBLE:\n+                    numericTokenStream.setDoubleValue(val.doubleValue());\n+                    break;\n+                default:\n+                    assert false : \"Should never get here\";\n+            }\n+        } else {\n+        }\n+        return numericTokenStream;\n+    }\n     if (!fieldType().tokenized()) {\n         if (stringValue() \u003d\u003d null) {\n             throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n         }\n         return new TokenStream() {\n \n             CharTermAttribute termAttribute \u003d addAttribute(CharTermAttribute.class);\n \n             OffsetAttribute offsetAttribute \u003d addAttribute(OffsetAttribute.class);\n \n             boolean used;\n \n             @Override\n             public boolean incrementToken() throws IOException {\n                 if (used) {\n                     return false;\n                 }\n                 termAttribute.setEmpty().append(stringValue());\n                 offsetAttribute.setOffset(0, stringValue().length());\n                 used \u003d true;\n                 return true;\n             }\n \n             @Override\n             public void reset() throws IOException {\n                 used \u003d false;\n             }\n         };\n     }\n     if (tokenStream !\u003d null) {\n         return tokenStream;\n     } else if (readerValue() !\u003d null) {\n         return analyzer.tokenStream(name(), readerValue());\n     } else if (stringValue() !\u003d null) {\n         return analyzer.tokenStream(name(), new StringReader(stringValue()));\n     }\n-    throw new IllegalArgumentException(\"Field must have either TokenStream, String or Reader value\");\n+    throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value\");\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "67c13bd2fe57d73a824f163f9c73018fa51a1a65": {
      "type": "Ybodychange",
      "commitMessage": "LUCENE-3455: Renamed Analyzer.reusableTokenStream to Analyzer.tokenStream\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1176728 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "2011/9/28 下午1:26",
      "commitName": "67c13bd2fe57d73a824f163f9c73018fa51a1a65",
      "commitAuthor": "Christopher John Male",
      "commitDateOld": "2011/9/23 上午11:16",
      "commitNameOld": "5d4502ad0a3249fec5fcc1e28ce7074f67e8a027",
      "commitAuthorOld": "Christopher John Male",
      "daysBetweenCommits": 5.09,
      "commitsBetweenForRepo": 44,
      "commitsBetweenForFile": 1,
      "actualSource": "public TokenStream tokenStream(Analyzer analyzer) throws IOException {\n    if (!fieldType().indexed()) {\n        return null;\n    }\n    if (!fieldType().tokenized()) {\n        if (stringValue() \u003d\u003d null) {\n            throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n        }\n        return new TokenStream() {\n\n            CharTermAttribute termAttribute \u003d addAttribute(CharTermAttribute.class);\n\n            OffsetAttribute offsetAttribute \u003d addAttribute(OffsetAttribute.class);\n\n            boolean used;\n\n            @Override\n            public boolean incrementToken() throws IOException {\n                if (used) {\n                    return false;\n                }\n                termAttribute.setEmpty().append(stringValue());\n                offsetAttribute.setOffset(0, stringValue().length());\n                used \u003d true;\n                return true;\n            }\n\n            @Override\n            public void reset() throws IOException {\n                used \u003d false;\n            }\n        };\n    }\n    if (tokenStream !\u003d null) {\n        return tokenStream;\n    } else if (readerValue() !\u003d null) {\n        return analyzer.tokenStream(name(), readerValue());\n    } else if (stringValue() !\u003d null) {\n        return analyzer.tokenStream(name(), new StringReader(stringValue()));\n    }\n    throw new IllegalArgumentException(\"Field must have either TokenStream, String or Reader value\");\n}",
      "path": "lucene/src/java/org/apache/lucene/document/Field.java",
      "functionStartLine": 317,
      "functionName": "tokenStream",
      "functionAnnotation": "",
      "functionDoc": "@inheritDoc}\n",
      "diff": "@@ -1,42 +1,42 @@\n public TokenStream tokenStream(Analyzer analyzer) throws IOException {\n     if (!fieldType().indexed()) {\n         return null;\n     }\n     if (!fieldType().tokenized()) {\n         if (stringValue() \u003d\u003d null) {\n             throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n         }\n         return new TokenStream() {\n \n             CharTermAttribute termAttribute \u003d addAttribute(CharTermAttribute.class);\n \n             OffsetAttribute offsetAttribute \u003d addAttribute(OffsetAttribute.class);\n \n             boolean used;\n \n             @Override\n             public boolean incrementToken() throws IOException {\n                 if (used) {\n                     return false;\n                 }\n                 termAttribute.setEmpty().append(stringValue());\n                 offsetAttribute.setOffset(0, stringValue().length());\n                 used \u003d true;\n                 return true;\n             }\n \n             @Override\n             public void reset() throws IOException {\n                 used \u003d false;\n             }\n         };\n     }\n     if (tokenStream !\u003d null) {\n         return tokenStream;\n     } else if (readerValue() !\u003d null) {\n-        return analyzer.reusableTokenStream(name(), readerValue());\n+        return analyzer.tokenStream(name(), readerValue());\n     } else if (stringValue() !\u003d null) {\n-        return analyzer.reusableTokenStream(name(), new StringReader(stringValue()));\n+        return analyzer.tokenStream(name(), new StringReader(stringValue()));\n     }\n     throw new IllegalArgumentException(\"Field must have either TokenStream, String or Reader value\");\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "5d4502ad0a3249fec5fcc1e28ce7074f67e8a027": {
      "type": "Ymultichange(Ymovefromfile,Yexceptionschange,Ybodychange,Ydocchange,Yrename,Yparameterchange)",
      "commitMessage": "LUCENE-2309: Moved to Field.tokenStream(Analyzer)\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1174506 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "2011/9/23 上午11:16",
      "commitName": "5d4502ad0a3249fec5fcc1e28ce7074f67e8a027",
      "commitAuthor": "Christopher John Male",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "LUCENE-2309: Moved to Field.tokenStream(Analyzer)\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1174506 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "2011/9/23 上午11:16",
          "commitName": "5d4502ad0a3249fec5fcc1e28ce7074f67e8a027",
          "commitAuthor": "Christopher John Male",
          "commitDateOld": "2011/9/23 上午5:56",
          "commitNameOld": "c8b7bb7aac7f362f937bc9db86105b1d33c15048",
          "commitAuthorOld": "Uwe Schindler",
          "daysBetweenCommits": 0.22,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "actualSource": "public TokenStream tokenStream(Analyzer analyzer) throws IOException {\n    if (!fieldType().indexed()) {\n        return null;\n    }\n    if (!fieldType().tokenized()) {\n        if (stringValue() \u003d\u003d null) {\n            throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n        }\n        return new TokenStream() {\n\n            CharTermAttribute termAttribute \u003d addAttribute(CharTermAttribute.class);\n\n            OffsetAttribute offsetAttribute \u003d addAttribute(OffsetAttribute.class);\n\n            boolean used;\n\n            @Override\n            public boolean incrementToken() throws IOException {\n                if (used) {\n                    return false;\n                }\n                termAttribute.setEmpty().append(stringValue());\n                offsetAttribute.setOffset(0, stringValue().length());\n                used \u003d true;\n                return true;\n            }\n\n            @Override\n            public void reset() throws IOException {\n                used \u003d false;\n            }\n        };\n    }\n    if (tokenStream !\u003d null) {\n        return tokenStream;\n    } else if (readerValue() !\u003d null) {\n        return analyzer.reusableTokenStream(name(), readerValue());\n    } else if (stringValue() !\u003d null) {\n        return analyzer.reusableTokenStream(name(), new StringReader(stringValue()));\n    }\n    throw new IllegalArgumentException(\"Field must have either TokenStream, String or Reader value\");\n}",
          "path": "lucene/src/java/org/apache/lucene/document/Field.java",
          "functionStartLine": 317,
          "functionName": "tokenStream",
          "functionAnnotation": "",
          "functionDoc": "@inheritDoc}\n",
          "diff": "@@ -1,28 +1,42 @@\n-public TokenStream tokenStreamValue() {\n-    if (!type.indexed())\n+public TokenStream tokenStream(Analyzer analyzer) throws IOException {\n+    if (!fieldType().indexed()) {\n         return null;\n-    if (numericTS \u003d\u003d null) {\n-        numericTS \u003d new NumericTokenStream(precisionStep);\n-        if (fieldsData !\u003d null) {\n-            assert dataType !\u003d null;\n-            final Number val \u003d (Number) fieldsData;\n-            switch(dataType) {\n-                case INT:\n-                    numericTS.setIntValue(val.intValue());\n-                    break;\n-                case LONG:\n-                    numericTS.setLongValue(val.longValue());\n-                    break;\n-                case FLOAT:\n-                    numericTS.setFloatValue(val.floatValue());\n-                    break;\n-                case DOUBLE:\n-                    numericTS.setDoubleValue(val.doubleValue());\n-                    break;\n-                default:\n-                    assert false : \"Should never get here\";\n-            }\n-        }\n     }\n-    return numericTS;\n+    if (!fieldType().tokenized()) {\n+        if (stringValue() \u003d\u003d null) {\n+            throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n+        }\n+        return new TokenStream() {\n+\n+            CharTermAttribute termAttribute \u003d addAttribute(CharTermAttribute.class);\n+\n+            OffsetAttribute offsetAttribute \u003d addAttribute(OffsetAttribute.class);\n+\n+            boolean used;\n+\n+            @Override\n+            public boolean incrementToken() throws IOException {\n+                if (used) {\n+                    return false;\n+                }\n+                termAttribute.setEmpty().append(stringValue());\n+                offsetAttribute.setOffset(0, stringValue().length());\n+                used \u003d true;\n+                return true;\n+            }\n+\n+            @Override\n+            public void reset() throws IOException {\n+                used \u003d false;\n+            }\n+        };\n+    }\n+    if (tokenStream !\u003d null) {\n+        return tokenStream;\n+    } else if (readerValue() !\u003d null) {\n+        return analyzer.reusableTokenStream(name(), readerValue());\n+    } else if (stringValue() !\u003d null) {\n+        return analyzer.reusableTokenStream(name(), new StringReader(stringValue()));\n+    }\n+    throw new IllegalArgumentException(\"Field must have either TokenStream, String or Reader value\");\n }\n\\ No newline at end of file\n",
          "extendedDetails": {
            "oldPath": "lucene/src/java/org/apache/lucene/document/NumericField.java",
            "newPath": "lucene/src/java/org/apache/lucene/document/Field.java",
            "oldMethodName": "tokenStreamValue",
            "newMethodName": "tokenStream"
          }
        },
        {
          "type": "Yexceptionschange",
          "commitMessage": "LUCENE-2309: Moved to Field.tokenStream(Analyzer)\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1174506 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "2011/9/23 上午11:16",
          "commitName": "5d4502ad0a3249fec5fcc1e28ce7074f67e8a027",
          "commitAuthor": "Christopher John Male",
          "commitDateOld": "2011/9/23 上午5:56",
          "commitNameOld": "c8b7bb7aac7f362f937bc9db86105b1d33c15048",
          "commitAuthorOld": "Uwe Schindler",
          "daysBetweenCommits": 0.22,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "actualSource": "public TokenStream tokenStream(Analyzer analyzer) throws IOException {\n    if (!fieldType().indexed()) {\n        return null;\n    }\n    if (!fieldType().tokenized()) {\n        if (stringValue() \u003d\u003d null) {\n            throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n        }\n        return new TokenStream() {\n\n            CharTermAttribute termAttribute \u003d addAttribute(CharTermAttribute.class);\n\n            OffsetAttribute offsetAttribute \u003d addAttribute(OffsetAttribute.class);\n\n            boolean used;\n\n            @Override\n            public boolean incrementToken() throws IOException {\n                if (used) {\n                    return false;\n                }\n                termAttribute.setEmpty().append(stringValue());\n                offsetAttribute.setOffset(0, stringValue().length());\n                used \u003d true;\n                return true;\n            }\n\n            @Override\n            public void reset() throws IOException {\n                used \u003d false;\n            }\n        };\n    }\n    if (tokenStream !\u003d null) {\n        return tokenStream;\n    } else if (readerValue() !\u003d null) {\n        return analyzer.reusableTokenStream(name(), readerValue());\n    } else if (stringValue() !\u003d null) {\n        return analyzer.reusableTokenStream(name(), new StringReader(stringValue()));\n    }\n    throw new IllegalArgumentException(\"Field must have either TokenStream, String or Reader value\");\n}",
          "path": "lucene/src/java/org/apache/lucene/document/Field.java",
          "functionStartLine": 317,
          "functionName": "tokenStream",
          "functionAnnotation": "",
          "functionDoc": "@inheritDoc}\n",
          "diff": "@@ -1,28 +1,42 @@\n-public TokenStream tokenStreamValue() {\n-    if (!type.indexed())\n+public TokenStream tokenStream(Analyzer analyzer) throws IOException {\n+    if (!fieldType().indexed()) {\n         return null;\n-    if (numericTS \u003d\u003d null) {\n-        numericTS \u003d new NumericTokenStream(precisionStep);\n-        if (fieldsData !\u003d null) {\n-            assert dataType !\u003d null;\n-            final Number val \u003d (Number) fieldsData;\n-            switch(dataType) {\n-                case INT:\n-                    numericTS.setIntValue(val.intValue());\n-                    break;\n-                case LONG:\n-                    numericTS.setLongValue(val.longValue());\n-                    break;\n-                case FLOAT:\n-                    numericTS.setFloatValue(val.floatValue());\n-                    break;\n-                case DOUBLE:\n-                    numericTS.setDoubleValue(val.doubleValue());\n-                    break;\n-                default:\n-                    assert false : \"Should never get here\";\n-            }\n-        }\n     }\n-    return numericTS;\n+    if (!fieldType().tokenized()) {\n+        if (stringValue() \u003d\u003d null) {\n+            throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n+        }\n+        return new TokenStream() {\n+\n+            CharTermAttribute termAttribute \u003d addAttribute(CharTermAttribute.class);\n+\n+            OffsetAttribute offsetAttribute \u003d addAttribute(OffsetAttribute.class);\n+\n+            boolean used;\n+\n+            @Override\n+            public boolean incrementToken() throws IOException {\n+                if (used) {\n+                    return false;\n+                }\n+                termAttribute.setEmpty().append(stringValue());\n+                offsetAttribute.setOffset(0, stringValue().length());\n+                used \u003d true;\n+                return true;\n+            }\n+\n+            @Override\n+            public void reset() throws IOException {\n+                used \u003d false;\n+            }\n+        };\n+    }\n+    if (tokenStream !\u003d null) {\n+        return tokenStream;\n+    } else if (readerValue() !\u003d null) {\n+        return analyzer.reusableTokenStream(name(), readerValue());\n+    } else if (stringValue() !\u003d null) {\n+        return analyzer.reusableTokenStream(name(), new StringReader(stringValue()));\n+    }\n+    throw new IllegalArgumentException(\"Field must have either TokenStream, String or Reader value\");\n }\n\\ No newline at end of file\n",
          "extendedDetails": {
            "oldValue": "[]",
            "newValue": "[IOException]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "LUCENE-2309: Moved to Field.tokenStream(Analyzer)\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1174506 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "2011/9/23 上午11:16",
          "commitName": "5d4502ad0a3249fec5fcc1e28ce7074f67e8a027",
          "commitAuthor": "Christopher John Male",
          "commitDateOld": "2011/9/23 上午5:56",
          "commitNameOld": "c8b7bb7aac7f362f937bc9db86105b1d33c15048",
          "commitAuthorOld": "Uwe Schindler",
          "daysBetweenCommits": 0.22,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "actualSource": "public TokenStream tokenStream(Analyzer analyzer) throws IOException {\n    if (!fieldType().indexed()) {\n        return null;\n    }\n    if (!fieldType().tokenized()) {\n        if (stringValue() \u003d\u003d null) {\n            throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n        }\n        return new TokenStream() {\n\n            CharTermAttribute termAttribute \u003d addAttribute(CharTermAttribute.class);\n\n            OffsetAttribute offsetAttribute \u003d addAttribute(OffsetAttribute.class);\n\n            boolean used;\n\n            @Override\n            public boolean incrementToken() throws IOException {\n                if (used) {\n                    return false;\n                }\n                termAttribute.setEmpty().append(stringValue());\n                offsetAttribute.setOffset(0, stringValue().length());\n                used \u003d true;\n                return true;\n            }\n\n            @Override\n            public void reset() throws IOException {\n                used \u003d false;\n            }\n        };\n    }\n    if (tokenStream !\u003d null) {\n        return tokenStream;\n    } else if (readerValue() !\u003d null) {\n        return analyzer.reusableTokenStream(name(), readerValue());\n    } else if (stringValue() !\u003d null) {\n        return analyzer.reusableTokenStream(name(), new StringReader(stringValue()));\n    }\n    throw new IllegalArgumentException(\"Field must have either TokenStream, String or Reader value\");\n}",
          "path": "lucene/src/java/org/apache/lucene/document/Field.java",
          "functionStartLine": 317,
          "functionName": "tokenStream",
          "functionAnnotation": "",
          "functionDoc": "@inheritDoc}\n",
          "diff": "@@ -1,28 +1,42 @@\n-public TokenStream tokenStreamValue() {\n-    if (!type.indexed())\n+public TokenStream tokenStream(Analyzer analyzer) throws IOException {\n+    if (!fieldType().indexed()) {\n         return null;\n-    if (numericTS \u003d\u003d null) {\n-        numericTS \u003d new NumericTokenStream(precisionStep);\n-        if (fieldsData !\u003d null) {\n-            assert dataType !\u003d null;\n-            final Number val \u003d (Number) fieldsData;\n-            switch(dataType) {\n-                case INT:\n-                    numericTS.setIntValue(val.intValue());\n-                    break;\n-                case LONG:\n-                    numericTS.setLongValue(val.longValue());\n-                    break;\n-                case FLOAT:\n-                    numericTS.setFloatValue(val.floatValue());\n-                    break;\n-                case DOUBLE:\n-                    numericTS.setDoubleValue(val.doubleValue());\n-                    break;\n-                default:\n-                    assert false : \"Should never get here\";\n-            }\n-        }\n     }\n-    return numericTS;\n+    if (!fieldType().tokenized()) {\n+        if (stringValue() \u003d\u003d null) {\n+            throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n+        }\n+        return new TokenStream() {\n+\n+            CharTermAttribute termAttribute \u003d addAttribute(CharTermAttribute.class);\n+\n+            OffsetAttribute offsetAttribute \u003d addAttribute(OffsetAttribute.class);\n+\n+            boolean used;\n+\n+            @Override\n+            public boolean incrementToken() throws IOException {\n+                if (used) {\n+                    return false;\n+                }\n+                termAttribute.setEmpty().append(stringValue());\n+                offsetAttribute.setOffset(0, stringValue().length());\n+                used \u003d true;\n+                return true;\n+            }\n+\n+            @Override\n+            public void reset() throws IOException {\n+                used \u003d false;\n+            }\n+        };\n+    }\n+    if (tokenStream !\u003d null) {\n+        return tokenStream;\n+    } else if (readerValue() !\u003d null) {\n+        return analyzer.reusableTokenStream(name(), readerValue());\n+    } else if (stringValue() !\u003d null) {\n+        return analyzer.reusableTokenStream(name(), new StringReader(stringValue()));\n+    }\n+    throw new IllegalArgumentException(\"Field must have either TokenStream, String or Reader value\");\n }\n\\ No newline at end of file\n",
          "extendedDetails": {}
        },
        {
          "type": "Ydocchange",
          "commitMessage": "LUCENE-2309: Moved to Field.tokenStream(Analyzer)\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1174506 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "2011/9/23 上午11:16",
          "commitName": "5d4502ad0a3249fec5fcc1e28ce7074f67e8a027",
          "commitAuthor": "Christopher John Male",
          "commitDateOld": "2011/9/23 上午5:56",
          "commitNameOld": "c8b7bb7aac7f362f937bc9db86105b1d33c15048",
          "commitAuthorOld": "Uwe Schindler",
          "daysBetweenCommits": 0.22,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "actualSource": "public TokenStream tokenStream(Analyzer analyzer) throws IOException {\n    if (!fieldType().indexed()) {\n        return null;\n    }\n    if (!fieldType().tokenized()) {\n        if (stringValue() \u003d\u003d null) {\n            throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n        }\n        return new TokenStream() {\n\n            CharTermAttribute termAttribute \u003d addAttribute(CharTermAttribute.class);\n\n            OffsetAttribute offsetAttribute \u003d addAttribute(OffsetAttribute.class);\n\n            boolean used;\n\n            @Override\n            public boolean incrementToken() throws IOException {\n                if (used) {\n                    return false;\n                }\n                termAttribute.setEmpty().append(stringValue());\n                offsetAttribute.setOffset(0, stringValue().length());\n                used \u003d true;\n                return true;\n            }\n\n            @Override\n            public void reset() throws IOException {\n                used \u003d false;\n            }\n        };\n    }\n    if (tokenStream !\u003d null) {\n        return tokenStream;\n    } else if (readerValue() !\u003d null) {\n        return analyzer.reusableTokenStream(name(), readerValue());\n    } else if (stringValue() !\u003d null) {\n        return analyzer.reusableTokenStream(name(), new StringReader(stringValue()));\n    }\n    throw new IllegalArgumentException(\"Field must have either TokenStream, String or Reader value\");\n}",
          "path": "lucene/src/java/org/apache/lucene/document/Field.java",
          "functionStartLine": 317,
          "functionName": "tokenStream",
          "functionAnnotation": "",
          "functionDoc": "@inheritDoc}\n",
          "diff": "@@ -1,28 +1,42 @@\n-public TokenStream tokenStreamValue() {\n-    if (!type.indexed())\n+public TokenStream tokenStream(Analyzer analyzer) throws IOException {\n+    if (!fieldType().indexed()) {\n         return null;\n-    if (numericTS \u003d\u003d null) {\n-        numericTS \u003d new NumericTokenStream(precisionStep);\n-        if (fieldsData !\u003d null) {\n-            assert dataType !\u003d null;\n-            final Number val \u003d (Number) fieldsData;\n-            switch(dataType) {\n-                case INT:\n-                    numericTS.setIntValue(val.intValue());\n-                    break;\n-                case LONG:\n-                    numericTS.setLongValue(val.longValue());\n-                    break;\n-                case FLOAT:\n-                    numericTS.setFloatValue(val.floatValue());\n-                    break;\n-                case DOUBLE:\n-                    numericTS.setDoubleValue(val.doubleValue());\n-                    break;\n-                default:\n-                    assert false : \"Should never get here\";\n-            }\n-        }\n     }\n-    return numericTS;\n+    if (!fieldType().tokenized()) {\n+        if (stringValue() \u003d\u003d null) {\n+            throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n+        }\n+        return new TokenStream() {\n+\n+            CharTermAttribute termAttribute \u003d addAttribute(CharTermAttribute.class);\n+\n+            OffsetAttribute offsetAttribute \u003d addAttribute(OffsetAttribute.class);\n+\n+            boolean used;\n+\n+            @Override\n+            public boolean incrementToken() throws IOException {\n+                if (used) {\n+                    return false;\n+                }\n+                termAttribute.setEmpty().append(stringValue());\n+                offsetAttribute.setOffset(0, stringValue().length());\n+                used \u003d true;\n+                return true;\n+            }\n+\n+            @Override\n+            public void reset() throws IOException {\n+                used \u003d false;\n+            }\n+        };\n+    }\n+    if (tokenStream !\u003d null) {\n+        return tokenStream;\n+    } else if (readerValue() !\u003d null) {\n+        return analyzer.reusableTokenStream(name(), readerValue());\n+    } else if (stringValue() !\u003d null) {\n+        return analyzer.reusableTokenStream(name(), new StringReader(stringValue()));\n+    }\n+    throw new IllegalArgumentException(\"Field must have either TokenStream, String or Reader value\");\n }\n\\ No newline at end of file\n",
          "extendedDetails": {
            "oldValue": "Returns a {@link NumericTokenStream} for indexing the numeric value.\n",
            "newValue": "@inheritDoc}\n"
          }
        },
        {
          "type": "Yrename",
          "commitMessage": "LUCENE-2309: Moved to Field.tokenStream(Analyzer)\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1174506 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "2011/9/23 上午11:16",
          "commitName": "5d4502ad0a3249fec5fcc1e28ce7074f67e8a027",
          "commitAuthor": "Christopher John Male",
          "commitDateOld": "2011/9/23 上午5:56",
          "commitNameOld": "c8b7bb7aac7f362f937bc9db86105b1d33c15048",
          "commitAuthorOld": "Uwe Schindler",
          "daysBetweenCommits": 0.22,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "actualSource": "public TokenStream tokenStream(Analyzer analyzer) throws IOException {\n    if (!fieldType().indexed()) {\n        return null;\n    }\n    if (!fieldType().tokenized()) {\n        if (stringValue() \u003d\u003d null) {\n            throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n        }\n        return new TokenStream() {\n\n            CharTermAttribute termAttribute \u003d addAttribute(CharTermAttribute.class);\n\n            OffsetAttribute offsetAttribute \u003d addAttribute(OffsetAttribute.class);\n\n            boolean used;\n\n            @Override\n            public boolean incrementToken() throws IOException {\n                if (used) {\n                    return false;\n                }\n                termAttribute.setEmpty().append(stringValue());\n                offsetAttribute.setOffset(0, stringValue().length());\n                used \u003d true;\n                return true;\n            }\n\n            @Override\n            public void reset() throws IOException {\n                used \u003d false;\n            }\n        };\n    }\n    if (tokenStream !\u003d null) {\n        return tokenStream;\n    } else if (readerValue() !\u003d null) {\n        return analyzer.reusableTokenStream(name(), readerValue());\n    } else if (stringValue() !\u003d null) {\n        return analyzer.reusableTokenStream(name(), new StringReader(stringValue()));\n    }\n    throw new IllegalArgumentException(\"Field must have either TokenStream, String or Reader value\");\n}",
          "path": "lucene/src/java/org/apache/lucene/document/Field.java",
          "functionStartLine": 317,
          "functionName": "tokenStream",
          "functionAnnotation": "",
          "functionDoc": "@inheritDoc}\n",
          "diff": "@@ -1,28 +1,42 @@\n-public TokenStream tokenStreamValue() {\n-    if (!type.indexed())\n+public TokenStream tokenStream(Analyzer analyzer) throws IOException {\n+    if (!fieldType().indexed()) {\n         return null;\n-    if (numericTS \u003d\u003d null) {\n-        numericTS \u003d new NumericTokenStream(precisionStep);\n-        if (fieldsData !\u003d null) {\n-            assert dataType !\u003d null;\n-            final Number val \u003d (Number) fieldsData;\n-            switch(dataType) {\n-                case INT:\n-                    numericTS.setIntValue(val.intValue());\n-                    break;\n-                case LONG:\n-                    numericTS.setLongValue(val.longValue());\n-                    break;\n-                case FLOAT:\n-                    numericTS.setFloatValue(val.floatValue());\n-                    break;\n-                case DOUBLE:\n-                    numericTS.setDoubleValue(val.doubleValue());\n-                    break;\n-                default:\n-                    assert false : \"Should never get here\";\n-            }\n-        }\n     }\n-    return numericTS;\n+    if (!fieldType().tokenized()) {\n+        if (stringValue() \u003d\u003d null) {\n+            throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n+        }\n+        return new TokenStream() {\n+\n+            CharTermAttribute termAttribute \u003d addAttribute(CharTermAttribute.class);\n+\n+            OffsetAttribute offsetAttribute \u003d addAttribute(OffsetAttribute.class);\n+\n+            boolean used;\n+\n+            @Override\n+            public boolean incrementToken() throws IOException {\n+                if (used) {\n+                    return false;\n+                }\n+                termAttribute.setEmpty().append(stringValue());\n+                offsetAttribute.setOffset(0, stringValue().length());\n+                used \u003d true;\n+                return true;\n+            }\n+\n+            @Override\n+            public void reset() throws IOException {\n+                used \u003d false;\n+            }\n+        };\n+    }\n+    if (tokenStream !\u003d null) {\n+        return tokenStream;\n+    } else if (readerValue() !\u003d null) {\n+        return analyzer.reusableTokenStream(name(), readerValue());\n+    } else if (stringValue() !\u003d null) {\n+        return analyzer.reusableTokenStream(name(), new StringReader(stringValue()));\n+    }\n+    throw new IllegalArgumentException(\"Field must have either TokenStream, String or Reader value\");\n }\n\\ No newline at end of file\n",
          "extendedDetails": {
            "oldValue": "tokenStreamValue",
            "newValue": "tokenStream"
          }
        },
        {
          "type": "Yparameterchange",
          "commitMessage": "LUCENE-2309: Moved to Field.tokenStream(Analyzer)\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1174506 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "2011/9/23 上午11:16",
          "commitName": "5d4502ad0a3249fec5fcc1e28ce7074f67e8a027",
          "commitAuthor": "Christopher John Male",
          "commitDateOld": "2011/9/23 上午5:56",
          "commitNameOld": "c8b7bb7aac7f362f937bc9db86105b1d33c15048",
          "commitAuthorOld": "Uwe Schindler",
          "daysBetweenCommits": 0.22,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "actualSource": "public TokenStream tokenStream(Analyzer analyzer) throws IOException {\n    if (!fieldType().indexed()) {\n        return null;\n    }\n    if (!fieldType().tokenized()) {\n        if (stringValue() \u003d\u003d null) {\n            throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n        }\n        return new TokenStream() {\n\n            CharTermAttribute termAttribute \u003d addAttribute(CharTermAttribute.class);\n\n            OffsetAttribute offsetAttribute \u003d addAttribute(OffsetAttribute.class);\n\n            boolean used;\n\n            @Override\n            public boolean incrementToken() throws IOException {\n                if (used) {\n                    return false;\n                }\n                termAttribute.setEmpty().append(stringValue());\n                offsetAttribute.setOffset(0, stringValue().length());\n                used \u003d true;\n                return true;\n            }\n\n            @Override\n            public void reset() throws IOException {\n                used \u003d false;\n            }\n        };\n    }\n    if (tokenStream !\u003d null) {\n        return tokenStream;\n    } else if (readerValue() !\u003d null) {\n        return analyzer.reusableTokenStream(name(), readerValue());\n    } else if (stringValue() !\u003d null) {\n        return analyzer.reusableTokenStream(name(), new StringReader(stringValue()));\n    }\n    throw new IllegalArgumentException(\"Field must have either TokenStream, String or Reader value\");\n}",
          "path": "lucene/src/java/org/apache/lucene/document/Field.java",
          "functionStartLine": 317,
          "functionName": "tokenStream",
          "functionAnnotation": "",
          "functionDoc": "@inheritDoc}\n",
          "diff": "@@ -1,28 +1,42 @@\n-public TokenStream tokenStreamValue() {\n-    if (!type.indexed())\n+public TokenStream tokenStream(Analyzer analyzer) throws IOException {\n+    if (!fieldType().indexed()) {\n         return null;\n-    if (numericTS \u003d\u003d null) {\n-        numericTS \u003d new NumericTokenStream(precisionStep);\n-        if (fieldsData !\u003d null) {\n-            assert dataType !\u003d null;\n-            final Number val \u003d (Number) fieldsData;\n-            switch(dataType) {\n-                case INT:\n-                    numericTS.setIntValue(val.intValue());\n-                    break;\n-                case LONG:\n-                    numericTS.setLongValue(val.longValue());\n-                    break;\n-                case FLOAT:\n-                    numericTS.setFloatValue(val.floatValue());\n-                    break;\n-                case DOUBLE:\n-                    numericTS.setDoubleValue(val.doubleValue());\n-                    break;\n-                default:\n-                    assert false : \"Should never get here\";\n-            }\n-        }\n     }\n-    return numericTS;\n+    if (!fieldType().tokenized()) {\n+        if (stringValue() \u003d\u003d null) {\n+            throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n+        }\n+        return new TokenStream() {\n+\n+            CharTermAttribute termAttribute \u003d addAttribute(CharTermAttribute.class);\n+\n+            OffsetAttribute offsetAttribute \u003d addAttribute(OffsetAttribute.class);\n+\n+            boolean used;\n+\n+            @Override\n+            public boolean incrementToken() throws IOException {\n+                if (used) {\n+                    return false;\n+                }\n+                termAttribute.setEmpty().append(stringValue());\n+                offsetAttribute.setOffset(0, stringValue().length());\n+                used \u003d true;\n+                return true;\n+            }\n+\n+            @Override\n+            public void reset() throws IOException {\n+                used \u003d false;\n+            }\n+        };\n+    }\n+    if (tokenStream !\u003d null) {\n+        return tokenStream;\n+    } else if (readerValue() !\u003d null) {\n+        return analyzer.reusableTokenStream(name(), readerValue());\n+    } else if (stringValue() !\u003d null) {\n+        return analyzer.reusableTokenStream(name(), new StringReader(stringValue()));\n+    }\n+    throw new IllegalArgumentException(\"Field must have either TokenStream, String or Reader value\");\n }\n\\ No newline at end of file\n",
          "extendedDetails": {
            "oldValue": "[]",
            "newValue": "[analyzer-Analyzer]"
          }
        }
      ]
    },
    "ffb3cbee57e1b075dac827bcc46bc95483c603e0": {
      "type": "Ybodychange",
      "commitMessage": "LUCENE-2308: Moved over to using IndexableFieldType interface\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1167668 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "2011/9/11 下午12:07",
      "commitName": "ffb3cbee57e1b075dac827bcc46bc95483c603e0",
      "commitAuthor": "Christopher John Male",
      "commitDateOld": "2011/8/27 下午9:27",
      "commitNameOld": "4dad0ba89f1d663939999be9005433dd629955f1",
      "commitAuthorOld": "Michael McCandless",
      "daysBetweenCommits": 14.61,
      "commitsBetweenForRepo": 64,
      "commitsBetweenForFile": 1,
      "actualSource": "public TokenStream tokenStreamValue() {\n    if (!type.indexed())\n        return null;\n    if (numericTS \u003d\u003d null) {\n        numericTS \u003d new NumericTokenStream(precisionStep);\n        if (fieldsData !\u003d null) {\n            assert dataType !\u003d null;\n            final Number val \u003d (Number) fieldsData;\n            switch(dataType) {\n                case INT:\n                    numericTS.setIntValue(val.intValue());\n                    break;\n                case LONG:\n                    numericTS.setLongValue(val.longValue());\n                    break;\n                case FLOAT:\n                    numericTS.setFloatValue(val.floatValue());\n                    break;\n                case DOUBLE:\n                    numericTS.setDoubleValue(val.doubleValue());\n                    break;\n                default:\n                    assert false : \"Should never get here\";\n            }\n        }\n    }\n    return numericTS;\n}",
      "path": "lucene/src/java/org/apache/lucene/document/NumericField.java",
      "functionStartLine": 240,
      "functionName": "tokenStreamValue",
      "functionAnnotation": "",
      "functionDoc": "Returns a {@link NumericTokenStream} for indexing the numeric value.\n",
      "diff": "@@ -1,28 +1,28 @@\n public TokenStream tokenStreamValue() {\n-    if (!indexed())\n+    if (!type.indexed())\n         return null;\n     if (numericTS \u003d\u003d null) {\n         numericTS \u003d new NumericTokenStream(precisionStep);\n         if (fieldsData !\u003d null) {\n             assert dataType !\u003d null;\n             final Number val \u003d (Number) fieldsData;\n             switch(dataType) {\n                 case INT:\n                     numericTS.setIntValue(val.intValue());\n                     break;\n                 case LONG:\n                     numericTS.setLongValue(val.longValue());\n                     break;\n                 case FLOAT:\n                     numericTS.setFloatValue(val.floatValue());\n                     break;\n                 case DOUBLE:\n                     numericTS.setDoubleValue(val.doubleValue());\n                     break;\n                 default:\n                     assert false : \"Should never get here\";\n             }\n         }\n     }\n     return numericTS;\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "4dad0ba89f1d663939999be9005433dd629955f1": {
      "type": "Ybodychange",
      "commitMessage": "LUCENE-2308: cutover to FieldType\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1162347 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "2011/8/27 下午9:27",
      "commitName": "4dad0ba89f1d663939999be9005433dd629955f1",
      "commitAuthor": "Michael McCandless",
      "commitDateOld": "2011/7/12 下午9:31",
      "commitNameOld": "1c646d24c9f9118e770fca947c2bc5b68775f425",
      "commitAuthorOld": "Robert Muir",
      "daysBetweenCommits": 46.0,
      "commitsBetweenForRepo": 260,
      "commitsBetweenForFile": 1,
      "actualSource": "public TokenStream tokenStreamValue() {\n    if (!indexed())\n        return null;\n    if (numericTS \u003d\u003d null) {\n        numericTS \u003d new NumericTokenStream(precisionStep);\n        if (fieldsData !\u003d null) {\n            assert dataType !\u003d null;\n            final Number val \u003d (Number) fieldsData;\n            switch(dataType) {\n                case INT:\n                    numericTS.setIntValue(val.intValue());\n                    break;\n                case LONG:\n                    numericTS.setLongValue(val.longValue());\n                    break;\n                case FLOAT:\n                    numericTS.setFloatValue(val.floatValue());\n                    break;\n                case DOUBLE:\n                    numericTS.setDoubleValue(val.doubleValue());\n                    break;\n                default:\n                    assert false : \"Should never get here\";\n            }\n        }\n    }\n    return numericTS;\n}",
      "path": "lucene/src/java/org/apache/lucene/document/NumericField.java",
      "functionStartLine": 240,
      "functionName": "tokenStreamValue",
      "functionAnnotation": "",
      "functionDoc": "Returns a {@link NumericTokenStream} for indexing the numeric value.\n",
      "diff": "@@ -1,28 +1,28 @@\n public TokenStream tokenStreamValue() {\n-    if (!isIndexed())\n+    if (!indexed())\n         return null;\n     if (numericTS \u003d\u003d null) {\n         numericTS \u003d new NumericTokenStream(precisionStep);\n         if (fieldsData !\u003d null) {\n-            assert type !\u003d null;\n+            assert dataType !\u003d null;\n             final Number val \u003d (Number) fieldsData;\n-            switch(type) {\n+            switch(dataType) {\n                 case INT:\n                     numericTS.setIntValue(val.intValue());\n                     break;\n                 case LONG:\n                     numericTS.setLongValue(val.longValue());\n                     break;\n                 case FLOAT:\n                     numericTS.setFloatValue(val.floatValue());\n                     break;\n                 case DOUBLE:\n                     numericTS.setDoubleValue(val.doubleValue());\n                     break;\n                 default:\n                     assert false : \"Should never get here\";\n             }\n         }\n     }\n     return numericTS;\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "400639f54e54ba2cf90b2436652450ded25861f7": {
      "type": "Ybodychange",
      "commitMessage": "LUCENE-3065, SOLR-2497: When a NumericField is retrieved from a Document loaded from IndexReader (or IndexSearcher), it will now come back as NumericField. Solr now uses NumericField solely (no more magic).\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1100526 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "2011/5/7 下午9:14",
      "commitName": "400639f54e54ba2cf90b2436652450ded25861f7",
      "commitAuthor": "Uwe Schindler",
      "commitDateOld": "2011/2/10 下午7:50",
      "commitNameOld": "f4e977bb26143619a034574ef4a61e1dd136a3f4",
      "commitAuthorOld": "Uwe Schindler",
      "daysBetweenCommits": 86.06,
      "commitsBetweenForRepo": 535,
      "commitsBetweenForFile": 1,
      "actualSource": "public TokenStream tokenStreamValue() {\n    if (!isIndexed())\n        return null;\n    if (numericTS \u003d\u003d null) {\n        numericTS \u003d new NumericTokenStream(precisionStep);\n        if (fieldsData !\u003d null) {\n            assert type !\u003d null;\n            final Number val \u003d (Number) fieldsData;\n            switch(type) {\n                case INT:\n                    numericTS.setIntValue(val.intValue());\n                    break;\n                case LONG:\n                    numericTS.setLongValue(val.longValue());\n                    break;\n                case FLOAT:\n                    numericTS.setFloatValue(val.floatValue());\n                    break;\n                case DOUBLE:\n                    numericTS.setDoubleValue(val.doubleValue());\n                    break;\n                default:\n                    assert false : \"Should never get here\";\n            }\n        }\n    }\n    return numericTS;\n}",
      "path": "lucene/src/java/org/apache/lucene/document/NumericField.java",
      "functionStartLine": 200,
      "functionName": "tokenStreamValue",
      "functionAnnotation": "",
      "functionDoc": "Returns a {@link NumericTokenStream} for indexing the numeric value.\n",
      "diff": "@@ -1,3 +1,28 @@\n public TokenStream tokenStreamValue() {\n-    return isIndexed() ? numericTS : null;\n+    if (!isIndexed())\n+        return null;\n+    if (numericTS \u003d\u003d null) {\n+        numericTS \u003d new NumericTokenStream(precisionStep);\n+        if (fieldsData !\u003d null) {\n+            assert type !\u003d null;\n+            final Number val \u003d (Number) fieldsData;\n+            switch(type) {\n+                case INT:\n+                    numericTS.setIntValue(val.intValue());\n+                    break;\n+                case LONG:\n+                    numericTS.setLongValue(val.longValue());\n+                    break;\n+                case FLOAT:\n+                    numericTS.setFloatValue(val.floatValue());\n+                    break;\n+                case DOUBLE:\n+                    numericTS.setDoubleValue(val.doubleValue());\n+                    break;\n+                default:\n+                    assert false : \"Should never get here\";\n+            }\n+        }\n+    }\n+    return numericTS;\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "778d96752fa94636a2136ea2b4d58a3fcbe283ec": {
      "type": "Yfilerename",
      "commitMessage": "SVN-GIT conversion, path copy emulation.\n",
      "commitDate": "2016/1/23 上午8:18",
      "commitName": "778d96752fa94636a2136ea2b4d58a3fcbe283ec",
      "commitAuthor": "Dawid Weiss",
      "commitDateOld": "2010/3/17 下午10:57",
      "commitNameOld": "2e5c6cdadc820220f8cb86e1b6e215da941649f9",
      "commitAuthorOld": "Uwe Schindler",
      "daysBetweenCommits": 2137.39,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "actualSource": "public TokenStream tokenStreamValue() {\n    return isIndexed() ? numericTS : null;\n}",
      "path": "lucene/src/java/org/apache/lucene/document/NumericField.java",
      "functionStartLine": 202,
      "functionName": "tokenStreamValue",
      "functionAnnotation": "",
      "functionDoc": "Returns a {@link NumericTokenStream} for indexing the numeric value.\n",
      "diff": "",
      "extendedDetails": {
        "oldPath": "src/java/org/apache/lucene/document/NumericField.java",
        "newPath": "lucene/src/java/org/apache/lucene/document/NumericField.java"
      }
    },
    "efb74380fda0da18650dbc66372a7bb1cd41dcf6": {
      "type": "Ybodychange",
      "commitMessage": "LUCENE-2285: Code cleanups to remove compiler warnings in eclipse.\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/java/trunk@917019 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "2010/2/28 上午3:14",
      "commitName": "efb74380fda0da18650dbc66372a7bb1cd41dcf6",
      "commitAuthor": "Uwe Schindler",
      "commitDateOld": "2010/1/31 下午11:20",
      "commitNameOld": "39b9f97cd414a6fbf7439091e1a42c83f1c71caf",
      "commitAuthorOld": "Robert Muir",
      "daysBetweenCommits": 27.16,
      "commitsBetweenForRepo": 59,
      "commitsBetweenForFile": 1,
      "actualSource": "public TokenStream tokenStreamValue() {\n    return isIndexed() ? numericTS : null;\n}",
      "path": "src/java/org/apache/lucene/document/NumericField.java",
      "functionStartLine": 202,
      "functionName": "tokenStreamValue",
      "functionAnnotation": "",
      "functionDoc": "Returns a {@link NumericTokenStream} for indexing the numeric value.\n",
      "diff": "@@ -1,3 +1,3 @@\n public TokenStream tokenStreamValue() {\n-    return isIndexed() ? tokenStream : null;\n+    return isIndexed() ? numericTS : null;\n }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "edfce675a575bf83baecb52ca58c6e307d50eaad": {
      "type": "Yintroduced",
      "commitMessage": "LUCENE-1701, LUCENE-1687: Add NumericField , make plain text numeric parsers public in FieldCache, move trie parsers to FieldCache, merge ExtendedFieldCache and FieldCache\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/java/trunk@787723 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "2009/6/23 下午11:42",
      "commitName": "edfce675a575bf83baecb52ca58c6e307d50eaad",
      "commitAuthor": "Uwe Schindler",
      "diff": "@@ -0,0 +1,3 @@\n+public TokenStream tokenStreamValue() {\n+    return isIndexed() ? tokenStream : null;\n+}\n\\ No newline at end of file\n",
      "actualSource": "public TokenStream tokenStreamValue() {\n    return isIndexed() ? tokenStream : null;\n}",
      "path": "src/java/org/apache/lucene/document/NumericField.java",
      "functionStartLine": 115,
      "functionName": "tokenStreamValue",
      "functionAnnotation": "",
      "functionDoc": "Returns a {@link NumericTokenStream} for indexing the numeric value.\n"
    }
  }
}