{
  "origin": "codeshovel",
  "repositoryName": "keras",
  "repositoryPath": "/Users/franky/Documents/Homework/毕业设计/testcase/keras/.git",
  "startCommitName": "ccecd39dd9281d65bada97f6762f622563227315",
  "sourceFileName": "models.py",
  "functionName": "_clone_functional_model",
  "functionId": "___clone_functional_model___model__input_tensors(default-None)",
  "sourceFilePath": "keras/models.py",
  "functionAnnotation": "",
  "functionStartLine": 26,
  "functionEndLine": 177,
  "numCommitsSeen": 317,
  "timeTaken": 3740,
  "changeHistory": [
    "555ca942df407b8c1bf1d48383c60fa1bf09cc1d",
    "c13d2723d01212d09dfdda39b0ad439803ec9230",
    "98465b85d020f1326bcef7632f1261a9a7a84e92",
    "3b440235e237ef59ec5763c413e7f4292dab5d79",
    "49f5b931410bc2e56378f20a15e8ac919e0efb88",
    "958239c621a6be037c5f8b30be9270310735f725",
    "e27b8b9343da4558b98570d6d45599bd0e365723"
  ],
  "changeHistoryShort": {
    "555ca942df407b8c1bf1d48383c60fa1bf09cc1d": "Ybodychange",
    "c13d2723d01212d09dfdda39b0ad439803ec9230": "Ybodychange",
    "98465b85d020f1326bcef7632f1261a9a7a84e92": "Ybodychange",
    "3b440235e237ef59ec5763c413e7f4292dab5d79": "Ybodychange",
    "49f5b931410bc2e56378f20a15e8ac919e0efb88": "Ybodychange",
    "958239c621a6be037c5f8b30be9270310735f725": "Ybodychange",
    "e27b8b9343da4558b98570d6d45599bd0e365723": "Yintroduced"
  },
  "changeHistoryDetails": {
    "555ca942df407b8c1bf1d48383c60fa1bf09cc1d": {
      "type": "Ybodychange",
      "commitMessage": "Introduces fixes for tensor equality in TF 2.0\n",
      "commitDate": "2019/8/29 上午5:54",
      "commitName": "555ca942df407b8c1bf1d48383c60fa1bf09cc1d",
      "commitAuthor": "François Chollet",
      "commitDateOld": "2019/2/16 上午7:58",
      "commitNameOld": "c13d2723d01212d09dfdda39b0ad439803ec9230",
      "commitAuthorOld": "Mist",
      "daysBetweenCommits": 193.91,
      "commitsBetweenForRepo": 182,
      "commitsBetweenForFile": 1,
      "actualSource": "def _clone_functional_model(model, input_tensors\u003dNone):\n    \"\"\"Clone a functional `Model` instance.\n\n    Model cloning is similar to calling a model on new inputs,\n    except that it creates new layers (and thus new weights) instead\n    of sharing the weights of the existing layers.\n\n    # Arguments\n        model: Instance of `Model`.\n        input_tensors: optional list of input tensors\n            to build the model upon. If not provided,\n            placeholders will be created.\n\n    # Returns\n        An instance of `Model` reproducing the behavior\n        of the original model, on top of new inputs tensors,\n        using newly instantiated weights.\n\n    # Raises\n        ValueError: in case of invalid `model` argument value.\n    \"\"\"\n    if not isinstance(model, Model):\n        raise ValueError(\u0027Expected `model` argument \u0027\n                         \u0027to be a `Model` instance, got \u0027, model)\n    if isinstance(model, Sequential):\n        raise ValueError(\u0027Expected `model` argument \u0027\n                         \u0027to be a functional `Model` instance, \u0027\n                         \u0027got a `Sequential` instance instead:\u0027, model)\n\n    layer_map \u003d {}  # Cache for created layers.\n    tensor_map \u003d {}  # Map {reference_tensor: (corresponding_tensor, mask)}\n    if input_tensors is None:\n        # Create placeholders to build the model on top of.\n        input_layers \u003d []\n        input_tensors \u003d []\n        for layer in model._input_layers:\n            input_tensor \u003d Input(batch_shape\u003dlayer.batch_input_shape,\n                                 dtype\u003dlayer.dtype,\n                                 sparse\u003dlayer.sparse,\n                                 name\u003dlayer.name)\n            input_tensors.append(input_tensor)\n            # Cache newly created input layer.\n            newly_created_input_layer \u003d input_tensor._keras_history[0]\n            layer_map[layer] \u003d newly_created_input_layer\n        for _original, _cloned in zip(model._input_layers, input_layers):\n            layer_map[_original] \u003d _cloned\n    else:\n        # Make sure that all input tensors come from a Keras layer.\n        # If tensor comes from an input layer: cache the input layer.\n        input_tensors \u003d to_list(input_tensors)\n        _input_tensors \u003d []\n        for i, x in enumerate(input_tensors):\n            if not K.is_keras_tensor(x):\n                name \u003d model._input_layers[i].name\n                input_tensor \u003d Input(tensor\u003dx,\n                                     name\u003d\u0027input_wrapper_for_\u0027 + name)\n                _input_tensors.append(input_tensor)\n                # Cache newly created input layer.\n                original_input_layer \u003d x._keras_history[0]\n                newly_created_input_layer \u003d input_tensor._keras_history[0]\n                layer_map[original_input_layer] \u003d newly_created_input_layer\n            else:\n                _input_tensors.append(x)\n        input_tensors \u003d _input_tensors\n\n    for x, y in zip(model.inputs, input_tensors):\n        tensor_map[id(x)] \u003d (y, None)  # tensor, mask\n\n    # Iterated over every node in the reference model, in depth order.\n    depth_keys \u003d list(model._nodes_by_depth.keys())\n    depth_keys.sort(reverse\u003dTrue)\n    for depth in depth_keys:\n        nodes \u003d model._nodes_by_depth[depth]\n        for node in nodes:\n            # Recover the corresponding layer.\n            layer \u003d node.outbound_layer\n\n            # Get or create layer.\n            if layer not in layer_map:\n                # Clone layer.\n                new_layer \u003d layer.__class__.from_config(layer.get_config())\n                layer_map[layer] \u003d new_layer\n                layer \u003d new_layer\n            else:\n                # Reuse previously cloned layer.\n                layer \u003d layer_map[layer]\n                # Don\u0027t call InputLayer multiple times.\n                if isinstance(layer, InputLayer):\n                    continue\n\n            # Gather inputs to call the new layer.\n            reference_input_tensors \u003d node.input_tensors\n            reference_output_tensors \u003d node.output_tensors\n\n            # If all previous input tensors are available in tensor_map,\n            # then call node.inbound_layer on them.\n            computed_data \u003d []  # List of tuples (input, mask).\n            for x in reference_input_tensors:\n                if id(x) in tensor_map:\n                    computed_data.append(tensor_map[id(x)])\n\n            if len(computed_data) \u003d\u003d len(reference_input_tensors):\n                # Call layer.\n                if node.arguments:\n                    kwargs \u003d node.arguments\n                else:\n                    kwargs \u003d {}\n                if len(computed_data) \u003d\u003d 1:\n                    computed_tensor, computed_mask \u003d computed_data[0]\n                    if has_arg(layer.call, \u0027mask\u0027):\n                        if \u0027mask\u0027 not in kwargs:\n                            kwargs[\u0027mask\u0027] \u003d computed_mask\n                    output_tensors \u003d to_list(\n                        layer(computed_tensor, **kwargs))\n                    if layer.supports_masking:\n                        output_masks \u003d to_list(\n                            layer.compute_mask(computed_tensor,\n                                               computed_mask))\n                    else:\n                        output_masks \u003d [None] * len(output_tensors)\n                    computed_tensors \u003d [computed_tensor]\n                    computed_masks \u003d [computed_mask]\n                else:\n                    computed_tensors \u003d [x[0] for x in computed_data]\n                    computed_masks \u003d [x[1] for x in computed_data]\n                    if has_arg(layer.call, \u0027mask\u0027):\n                        if \u0027mask\u0027 not in kwargs:\n                            kwargs[\u0027mask\u0027] \u003d computed_masks\n                    output_tensors \u003d to_list(\n                        layer(computed_tensors, **kwargs))\n                    if layer.supports_masking:\n                        output_masks \u003d to_list(\n                            layer.compute_mask(computed_tensors,\n                                               computed_masks))\n                    else:\n                        output_masks \u003d [None] * len(output_tensors)\n                # Update tensor_map.\n                for x, y, mask in zip(reference_output_tensors,\n                                      output_tensors,\n                                      output_masks):\n                    tensor_map[id(x)] \u003d (y, mask)\n\n    # Check that we did compute the model outputs,\n    # then instantiate a new model from inputs and outputs.\n    output_tensors \u003d []\n    for x in model.outputs:\n        assert id(x) in tensor_map, \u0027Could not compute output \u0027 + str(x)\n        tensor, _ \u003d tensor_map[id(x)]\n        output_tensors.append(tensor)\n    return Model(input_tensors, output_tensors, name\u003dmodel.name)\n\n",
      "path": "keras/models.py",
      "functionStartLine": 26,
      "functionName": "_clone_functional_model",
      "functionAnnotation": "",
      "diff": "@@ -1,151 +1,151 @@\n def _clone_functional_model(model, input_tensors\u003dNone):\n     \"\"\"Clone a functional `Model` instance.\n \n     Model cloning is similar to calling a model on new inputs,\n     except that it creates new layers (and thus new weights) instead\n     of sharing the weights of the existing layers.\n \n     # Arguments\n         model: Instance of `Model`.\n         input_tensors: optional list of input tensors\n             to build the model upon. If not provided,\n             placeholders will be created.\n \n     # Returns\n         An instance of `Model` reproducing the behavior\n         of the original model, on top of new inputs tensors,\n         using newly instantiated weights.\n \n     # Raises\n         ValueError: in case of invalid `model` argument value.\n     \"\"\"\n     if not isinstance(model, Model):\n         raise ValueError(\u0027Expected `model` argument \u0027\n                          \u0027to be a `Model` instance, got \u0027, model)\n     if isinstance(model, Sequential):\n         raise ValueError(\u0027Expected `model` argument \u0027\n                          \u0027to be a functional `Model` instance, \u0027\n                          \u0027got a `Sequential` instance instead:\u0027, model)\n \n     layer_map \u003d {}  # Cache for created layers.\n     tensor_map \u003d {}  # Map {reference_tensor: (corresponding_tensor, mask)}\n     if input_tensors is None:\n         # Create placeholders to build the model on top of.\n         input_layers \u003d []\n         input_tensors \u003d []\n         for layer in model._input_layers:\n             input_tensor \u003d Input(batch_shape\u003dlayer.batch_input_shape,\n                                  dtype\u003dlayer.dtype,\n                                  sparse\u003dlayer.sparse,\n                                  name\u003dlayer.name)\n             input_tensors.append(input_tensor)\n             # Cache newly created input layer.\n             newly_created_input_layer \u003d input_tensor._keras_history[0]\n             layer_map[layer] \u003d newly_created_input_layer\n         for _original, _cloned in zip(model._input_layers, input_layers):\n             layer_map[_original] \u003d _cloned\n     else:\n         # Make sure that all input tensors come from a Keras layer.\n         # If tensor comes from an input layer: cache the input layer.\n         input_tensors \u003d to_list(input_tensors)\n         _input_tensors \u003d []\n         for i, x in enumerate(input_tensors):\n             if not K.is_keras_tensor(x):\n                 name \u003d model._input_layers[i].name\n                 input_tensor \u003d Input(tensor\u003dx,\n                                      name\u003d\u0027input_wrapper_for_\u0027 + name)\n                 _input_tensors.append(input_tensor)\n                 # Cache newly created input layer.\n                 original_input_layer \u003d x._keras_history[0]\n                 newly_created_input_layer \u003d input_tensor._keras_history[0]\n                 layer_map[original_input_layer] \u003d newly_created_input_layer\n             else:\n                 _input_tensors.append(x)\n         input_tensors \u003d _input_tensors\n \n     for x, y in zip(model.inputs, input_tensors):\n-        tensor_map[x] \u003d (y, None)  # tensor, mask\n+        tensor_map[id(x)] \u003d (y, None)  # tensor, mask\n \n     # Iterated over every node in the reference model, in depth order.\n     depth_keys \u003d list(model._nodes_by_depth.keys())\n     depth_keys.sort(reverse\u003dTrue)\n     for depth in depth_keys:\n         nodes \u003d model._nodes_by_depth[depth]\n         for node in nodes:\n             # Recover the corresponding layer.\n             layer \u003d node.outbound_layer\n \n             # Get or create layer.\n             if layer not in layer_map:\n                 # Clone layer.\n                 new_layer \u003d layer.__class__.from_config(layer.get_config())\n                 layer_map[layer] \u003d new_layer\n                 layer \u003d new_layer\n             else:\n                 # Reuse previously cloned layer.\n                 layer \u003d layer_map[layer]\n                 # Don\u0027t call InputLayer multiple times.\n                 if isinstance(layer, InputLayer):\n                     continue\n \n             # Gather inputs to call the new layer.\n             reference_input_tensors \u003d node.input_tensors\n             reference_output_tensors \u003d node.output_tensors\n \n             # If all previous input tensors are available in tensor_map,\n             # then call node.inbound_layer on them.\n             computed_data \u003d []  # List of tuples (input, mask).\n             for x in reference_input_tensors:\n-                if x in tensor_map:\n-                    computed_data.append(tensor_map[x])\n+                if id(x) in tensor_map:\n+                    computed_data.append(tensor_map[id(x)])\n \n             if len(computed_data) \u003d\u003d len(reference_input_tensors):\n                 # Call layer.\n                 if node.arguments:\n                     kwargs \u003d node.arguments\n                 else:\n                     kwargs \u003d {}\n                 if len(computed_data) \u003d\u003d 1:\n                     computed_tensor, computed_mask \u003d computed_data[0]\n                     if has_arg(layer.call, \u0027mask\u0027):\n                         if \u0027mask\u0027 not in kwargs:\n                             kwargs[\u0027mask\u0027] \u003d computed_mask\n                     output_tensors \u003d to_list(\n                         layer(computed_tensor, **kwargs))\n                     if layer.supports_masking:\n                         output_masks \u003d to_list(\n                             layer.compute_mask(computed_tensor,\n                                                computed_mask))\n                     else:\n                         output_masks \u003d [None] * len(output_tensors)\n                     computed_tensors \u003d [computed_tensor]\n                     computed_masks \u003d [computed_mask]\n                 else:\n                     computed_tensors \u003d [x[0] for x in computed_data]\n                     computed_masks \u003d [x[1] for x in computed_data]\n                     if has_arg(layer.call, \u0027mask\u0027):\n                         if \u0027mask\u0027 not in kwargs:\n                             kwargs[\u0027mask\u0027] \u003d computed_masks\n                     output_tensors \u003d to_list(\n                         layer(computed_tensors, **kwargs))\n                     if layer.supports_masking:\n                         output_masks \u003d to_list(\n                             layer.compute_mask(computed_tensors,\n                                                computed_masks))\n                     else:\n                         output_masks \u003d [None] * len(output_tensors)\n                 # Update tensor_map.\n                 for x, y, mask in zip(reference_output_tensors,\n                                       output_tensors,\n                                       output_masks):\n-                    tensor_map[x] \u003d (y, mask)\n+                    tensor_map[id(x)] \u003d (y, mask)\n \n     # Check that we did compute the model outputs,\n     # then instantiate a new model from inputs and outputs.\n     output_tensors \u003d []\n     for x in model.outputs:\n-        assert x in tensor_map, \u0027Could not compute output \u0027 + str(x)\n-        tensor, _ \u003d tensor_map[x]\n+        assert id(x) in tensor_map, \u0027Could not compute output \u0027 + str(x)\n+        tensor, _ \u003d tensor_map[id(x)]\n         output_tensors.append(tensor)\n     return Model(input_tensors, output_tensors, name\u003dmodel.name)\n \n",
      "extendedDetails": {}
    },
    "c13d2723d01212d09dfdda39b0ad439803ec9230": {
      "type": "Ybodychange",
      "commitMessage": "[P?] Fix clone_model (#12205)\n\n* Fix clone_model\r\n\r\n* Fix clone_model, using if-blocks\r\n\r\n* Add unit test\r\n\r\n* Add unit test, fix compatibility for Theano\r\n\r\n* Add unit test, reformat to limit line length\r\n\r\n* Add unit test, reformat to limit line length\r\n",
      "commitDate": "2019/2/16 上午7:58",
      "commitName": "c13d2723d01212d09dfdda39b0ad439803ec9230",
      "commitAuthor": "Mist",
      "commitDateOld": "2018/9/23 下午4:44",
      "commitNameOld": "98465b85d020f1326bcef7632f1261a9a7a84e92",
      "commitAuthorOld": "Taehoon Lee",
      "daysBetweenCommits": 145.63,
      "commitsBetweenForRepo": 243,
      "commitsBetweenForFile": 1,
      "actualSource": "def _clone_functional_model(model, input_tensors\u003dNone):\n    \"\"\"Clone a functional `Model` instance.\n\n    Model cloning is similar to calling a model on new inputs,\n    except that it creates new layers (and thus new weights) instead\n    of sharing the weights of the existing layers.\n\n    # Arguments\n        model: Instance of `Model`.\n        input_tensors: optional list of input tensors\n            to build the model upon. If not provided,\n            placeholders will be created.\n\n    # Returns\n        An instance of `Model` reproducing the behavior\n        of the original model, on top of new inputs tensors,\n        using newly instantiated weights.\n\n    # Raises\n        ValueError: in case of invalid `model` argument value.\n    \"\"\"\n    if not isinstance(model, Model):\n        raise ValueError(\u0027Expected `model` argument \u0027\n                         \u0027to be a `Model` instance, got \u0027, model)\n    if isinstance(model, Sequential):\n        raise ValueError(\u0027Expected `model` argument \u0027\n                         \u0027to be a functional `Model` instance, \u0027\n                         \u0027got a `Sequential` instance instead:\u0027, model)\n\n    layer_map \u003d {}  # Cache for created layers.\n    tensor_map \u003d {}  # Map {reference_tensor: (corresponding_tensor, mask)}\n    if input_tensors is None:\n        # Create placeholders to build the model on top of.\n        input_layers \u003d []\n        input_tensors \u003d []\n        for layer in model._input_layers:\n            input_tensor \u003d Input(batch_shape\u003dlayer.batch_input_shape,\n                                 dtype\u003dlayer.dtype,\n                                 sparse\u003dlayer.sparse,\n                                 name\u003dlayer.name)\n            input_tensors.append(input_tensor)\n            # Cache newly created input layer.\n            newly_created_input_layer \u003d input_tensor._keras_history[0]\n            layer_map[layer] \u003d newly_created_input_layer\n        for _original, _cloned in zip(model._input_layers, input_layers):\n            layer_map[_original] \u003d _cloned\n    else:\n        # Make sure that all input tensors come from a Keras layer.\n        # If tensor comes from an input layer: cache the input layer.\n        input_tensors \u003d to_list(input_tensors)\n        _input_tensors \u003d []\n        for i, x in enumerate(input_tensors):\n            if not K.is_keras_tensor(x):\n                name \u003d model._input_layers[i].name\n                input_tensor \u003d Input(tensor\u003dx,\n                                     name\u003d\u0027input_wrapper_for_\u0027 + name)\n                _input_tensors.append(input_tensor)\n                # Cache newly created input layer.\n                original_input_layer \u003d x._keras_history[0]\n                newly_created_input_layer \u003d input_tensor._keras_history[0]\n                layer_map[original_input_layer] \u003d newly_created_input_layer\n            else:\n                _input_tensors.append(x)\n        input_tensors \u003d _input_tensors\n\n    for x, y in zip(model.inputs, input_tensors):\n        tensor_map[x] \u003d (y, None)  # tensor, mask\n\n    # Iterated over every node in the reference model, in depth order.\n    depth_keys \u003d list(model._nodes_by_depth.keys())\n    depth_keys.sort(reverse\u003dTrue)\n    for depth in depth_keys:\n        nodes \u003d model._nodes_by_depth[depth]\n        for node in nodes:\n            # Recover the corresponding layer.\n            layer \u003d node.outbound_layer\n\n            # Get or create layer.\n            if layer not in layer_map:\n                # Clone layer.\n                new_layer \u003d layer.__class__.from_config(layer.get_config())\n                layer_map[layer] \u003d new_layer\n                layer \u003d new_layer\n            else:\n                # Reuse previously cloned layer.\n                layer \u003d layer_map[layer]\n                # Don\u0027t call InputLayer multiple times.\n                if isinstance(layer, InputLayer):\n                    continue\n\n            # Gather inputs to call the new layer.\n            reference_input_tensors \u003d node.input_tensors\n            reference_output_tensors \u003d node.output_tensors\n\n            # If all previous input tensors are available in tensor_map,\n            # then call node.inbound_layer on them.\n            computed_data \u003d []  # List of tuples (input, mask).\n            for x in reference_input_tensors:\n                if x in tensor_map:\n                    computed_data.append(tensor_map[x])\n\n            if len(computed_data) \u003d\u003d len(reference_input_tensors):\n                # Call layer.\n                if node.arguments:\n                    kwargs \u003d node.arguments\n                else:\n                    kwargs \u003d {}\n                if len(computed_data) \u003d\u003d 1:\n                    computed_tensor, computed_mask \u003d computed_data[0]\n                    if has_arg(layer.call, \u0027mask\u0027):\n                        if \u0027mask\u0027 not in kwargs:\n                            kwargs[\u0027mask\u0027] \u003d computed_mask\n                    output_tensors \u003d to_list(\n                        layer(computed_tensor, **kwargs))\n                    if layer.supports_masking:\n                        output_masks \u003d to_list(\n                            layer.compute_mask(computed_tensor,\n                                               computed_mask))\n                    else:\n                        output_masks \u003d [None] * len(output_tensors)\n                    computed_tensors \u003d [computed_tensor]\n                    computed_masks \u003d [computed_mask]\n                else:\n                    computed_tensors \u003d [x[0] for x in computed_data]\n                    computed_masks \u003d [x[1] for x in computed_data]\n                    if has_arg(layer.call, \u0027mask\u0027):\n                        if \u0027mask\u0027 not in kwargs:\n                            kwargs[\u0027mask\u0027] \u003d computed_masks\n                    output_tensors \u003d to_list(\n                        layer(computed_tensors, **kwargs))\n                    if layer.supports_masking:\n                        output_masks \u003d to_list(\n                            layer.compute_mask(computed_tensors,\n                                               computed_masks))\n                    else:\n                        output_masks \u003d [None] * len(output_tensors)\n                # Update tensor_map.\n                for x, y, mask in zip(reference_output_tensors,\n                                      output_tensors,\n                                      output_masks):\n                    tensor_map[x] \u003d (y, mask)\n\n    # Check that we did compute the model outputs,\n    # then instantiate a new model from inputs and outputs.\n    output_tensors \u003d []\n    for x in model.outputs:\n        assert x in tensor_map, \u0027Could not compute output \u0027 + str(x)\n        tensor, _ \u003d tensor_map[x]\n        output_tensors.append(tensor)\n    return Model(input_tensors, output_tensors, name\u003dmodel.name)\n\n",
      "path": "keras/models.py",
      "functionStartLine": 26,
      "functionName": "_clone_functional_model",
      "functionAnnotation": "",
      "diff": "@@ -1,145 +1,151 @@\n def _clone_functional_model(model, input_tensors\u003dNone):\n     \"\"\"Clone a functional `Model` instance.\n \n     Model cloning is similar to calling a model on new inputs,\n     except that it creates new layers (and thus new weights) instead\n     of sharing the weights of the existing layers.\n \n     # Arguments\n         model: Instance of `Model`.\n         input_tensors: optional list of input tensors\n             to build the model upon. If not provided,\n             placeholders will be created.\n \n     # Returns\n         An instance of `Model` reproducing the behavior\n         of the original model, on top of new inputs tensors,\n         using newly instantiated weights.\n \n     # Raises\n         ValueError: in case of invalid `model` argument value.\n     \"\"\"\n     if not isinstance(model, Model):\n         raise ValueError(\u0027Expected `model` argument \u0027\n                          \u0027to be a `Model` instance, got \u0027, model)\n     if isinstance(model, Sequential):\n         raise ValueError(\u0027Expected `model` argument \u0027\n                          \u0027to be a functional `Model` instance, \u0027\n                          \u0027got a `Sequential` instance instead:\u0027, model)\n \n     layer_map \u003d {}  # Cache for created layers.\n     tensor_map \u003d {}  # Map {reference_tensor: (corresponding_tensor, mask)}\n     if input_tensors is None:\n         # Create placeholders to build the model on top of.\n         input_layers \u003d []\n         input_tensors \u003d []\n         for layer in model._input_layers:\n             input_tensor \u003d Input(batch_shape\u003dlayer.batch_input_shape,\n                                  dtype\u003dlayer.dtype,\n                                  sparse\u003dlayer.sparse,\n                                  name\u003dlayer.name)\n             input_tensors.append(input_tensor)\n             # Cache newly created input layer.\n             newly_created_input_layer \u003d input_tensor._keras_history[0]\n             layer_map[layer] \u003d newly_created_input_layer\n         for _original, _cloned in zip(model._input_layers, input_layers):\n             layer_map[_original] \u003d _cloned\n     else:\n         # Make sure that all input tensors come from a Keras layer.\n         # If tensor comes from an input layer: cache the input layer.\n         input_tensors \u003d to_list(input_tensors)\n         _input_tensors \u003d []\n         for i, x in enumerate(input_tensors):\n             if not K.is_keras_tensor(x):\n                 name \u003d model._input_layers[i].name\n                 input_tensor \u003d Input(tensor\u003dx,\n                                      name\u003d\u0027input_wrapper_for_\u0027 + name)\n                 _input_tensors.append(input_tensor)\n                 # Cache newly created input layer.\n                 original_input_layer \u003d x._keras_history[0]\n                 newly_created_input_layer \u003d input_tensor._keras_history[0]\n                 layer_map[original_input_layer] \u003d newly_created_input_layer\n             else:\n                 _input_tensors.append(x)\n         input_tensors \u003d _input_tensors\n \n     for x, y in zip(model.inputs, input_tensors):\n         tensor_map[x] \u003d (y, None)  # tensor, mask\n \n     # Iterated over every node in the reference model, in depth order.\n     depth_keys \u003d list(model._nodes_by_depth.keys())\n     depth_keys.sort(reverse\u003dTrue)\n     for depth in depth_keys:\n         nodes \u003d model._nodes_by_depth[depth]\n         for node in nodes:\n             # Recover the corresponding layer.\n             layer \u003d node.outbound_layer\n \n             # Get or create layer.\n             if layer not in layer_map:\n                 # Clone layer.\n                 new_layer \u003d layer.__class__.from_config(layer.get_config())\n                 layer_map[layer] \u003d new_layer\n                 layer \u003d new_layer\n             else:\n                 # Reuse previously cloned layer.\n                 layer \u003d layer_map[layer]\n                 # Don\u0027t call InputLayer multiple times.\n                 if isinstance(layer, InputLayer):\n                     continue\n \n             # Gather inputs to call the new layer.\n             reference_input_tensors \u003d node.input_tensors\n             reference_output_tensors \u003d node.output_tensors\n \n             # If all previous input tensors are available in tensor_map,\n             # then call node.inbound_layer on them.\n             computed_data \u003d []  # List of tuples (input, mask).\n             for x in reference_input_tensors:\n                 if x in tensor_map:\n                     computed_data.append(tensor_map[x])\n \n             if len(computed_data) \u003d\u003d len(reference_input_tensors):\n                 # Call layer.\n                 if node.arguments:\n                     kwargs \u003d node.arguments\n                 else:\n                     kwargs \u003d {}\n                 if len(computed_data) \u003d\u003d 1:\n                     computed_tensor, computed_mask \u003d computed_data[0]\n                     if has_arg(layer.call, \u0027mask\u0027):\n                         if \u0027mask\u0027 not in kwargs:\n                             kwargs[\u0027mask\u0027] \u003d computed_mask\n                     output_tensors \u003d to_list(\n                         layer(computed_tensor, **kwargs))\n-                    output_masks \u003d to_list(\n-                        layer.compute_mask(computed_tensor,\n-                                           computed_mask))\n+                    if layer.supports_masking:\n+                        output_masks \u003d to_list(\n+                            layer.compute_mask(computed_tensor,\n+                                               computed_mask))\n+                    else:\n+                        output_masks \u003d [None] * len(output_tensors)\n                     computed_tensors \u003d [computed_tensor]\n                     computed_masks \u003d [computed_mask]\n                 else:\n                     computed_tensors \u003d [x[0] for x in computed_data]\n                     computed_masks \u003d [x[1] for x in computed_data]\n                     if has_arg(layer.call, \u0027mask\u0027):\n                         if \u0027mask\u0027 not in kwargs:\n                             kwargs[\u0027mask\u0027] \u003d computed_masks\n                     output_tensors \u003d to_list(\n                         layer(computed_tensors, **kwargs))\n-                    output_masks \u003d to_list(\n-                        layer.compute_mask(computed_tensors,\n-                                           computed_masks))\n+                    if layer.supports_masking:\n+                        output_masks \u003d to_list(\n+                            layer.compute_mask(computed_tensors,\n+                                               computed_masks))\n+                    else:\n+                        output_masks \u003d [None] * len(output_tensors)\n                 # Update tensor_map.\n                 for x, y, mask in zip(reference_output_tensors,\n                                       output_tensors,\n                                       output_masks):\n                     tensor_map[x] \u003d (y, mask)\n \n     # Check that we did compute the model outputs,\n     # then instantiate a new model from inputs and outputs.\n     output_tensors \u003d []\n     for x in model.outputs:\n         assert x in tensor_map, \u0027Could not compute output \u0027 + str(x)\n         tensor, _ \u003d tensor_map[x]\n         output_tensors.append(tensor)\n     return Model(input_tensors, output_tensors, name\u003dmodel.name)\n \n",
      "extendedDetails": {}
    },
    "98465b85d020f1326bcef7632f1261a9a7a84e92": {
      "type": "Ybodychange",
      "commitMessage": "Style fixes for enabling PEP8 501 (#11199)\n\n* Style fixes for enabling PEP8 501\r\n\r\n* Style fixes\r\n",
      "commitDate": "2018/9/23 下午4:44",
      "commitName": "98465b85d020f1326bcef7632f1261a9a7a84e92",
      "commitAuthor": "Taehoon Lee",
      "commitDateOld": "2018/4/27 上午9:10",
      "commitNameOld": "3b440235e237ef59ec5763c413e7f4292dab5d79",
      "commitAuthorOld": "François Chollet",
      "daysBetweenCommits": 149.32,
      "commitsBetweenForRepo": 296,
      "commitsBetweenForFile": 1,
      "actualSource": "def _clone_functional_model(model, input_tensors\u003dNone):\n    \"\"\"Clone a functional `Model` instance.\n\n    Model cloning is similar to calling a model on new inputs,\n    except that it creates new layers (and thus new weights) instead\n    of sharing the weights of the existing layers.\n\n    # Arguments\n        model: Instance of `Model`.\n        input_tensors: optional list of input tensors\n            to build the model upon. If not provided,\n            placeholders will be created.\n\n    # Returns\n        An instance of `Model` reproducing the behavior\n        of the original model, on top of new inputs tensors,\n        using newly instantiated weights.\n\n    # Raises\n        ValueError: in case of invalid `model` argument value.\n    \"\"\"\n    if not isinstance(model, Model):\n        raise ValueError(\u0027Expected `model` argument \u0027\n                         \u0027to be a `Model` instance, got \u0027, model)\n    if isinstance(model, Sequential):\n        raise ValueError(\u0027Expected `model` argument \u0027\n                         \u0027to be a functional `Model` instance, \u0027\n                         \u0027got a `Sequential` instance instead:\u0027, model)\n\n    layer_map \u003d {}  # Cache for created layers.\n    tensor_map \u003d {}  # Map {reference_tensor: (corresponding_tensor, mask)}\n    if input_tensors is None:\n        # Create placeholders to build the model on top of.\n        input_layers \u003d []\n        input_tensors \u003d []\n        for layer in model._input_layers:\n            input_tensor \u003d Input(batch_shape\u003dlayer.batch_input_shape,\n                                 dtype\u003dlayer.dtype,\n                                 sparse\u003dlayer.sparse,\n                                 name\u003dlayer.name)\n            input_tensors.append(input_tensor)\n            # Cache newly created input layer.\n            newly_created_input_layer \u003d input_tensor._keras_history[0]\n            layer_map[layer] \u003d newly_created_input_layer\n        for _original, _cloned in zip(model._input_layers, input_layers):\n            layer_map[_original] \u003d _cloned\n    else:\n        # Make sure that all input tensors come from a Keras layer.\n        # If tensor comes from an input layer: cache the input layer.\n        input_tensors \u003d to_list(input_tensors)\n        _input_tensors \u003d []\n        for i, x in enumerate(input_tensors):\n            if not K.is_keras_tensor(x):\n                name \u003d model._input_layers[i].name\n                input_tensor \u003d Input(tensor\u003dx,\n                                     name\u003d\u0027input_wrapper_for_\u0027 + name)\n                _input_tensors.append(input_tensor)\n                # Cache newly created input layer.\n                original_input_layer \u003d x._keras_history[0]\n                newly_created_input_layer \u003d input_tensor._keras_history[0]\n                layer_map[original_input_layer] \u003d newly_created_input_layer\n            else:\n                _input_tensors.append(x)\n        input_tensors \u003d _input_tensors\n\n    for x, y in zip(model.inputs, input_tensors):\n        tensor_map[x] \u003d (y, None)  # tensor, mask\n\n    # Iterated over every node in the reference model, in depth order.\n    depth_keys \u003d list(model._nodes_by_depth.keys())\n    depth_keys.sort(reverse\u003dTrue)\n    for depth in depth_keys:\n        nodes \u003d model._nodes_by_depth[depth]\n        for node in nodes:\n            # Recover the corresponding layer.\n            layer \u003d node.outbound_layer\n\n            # Get or create layer.\n            if layer not in layer_map:\n                # Clone layer.\n                new_layer \u003d layer.__class__.from_config(layer.get_config())\n                layer_map[layer] \u003d new_layer\n                layer \u003d new_layer\n            else:\n                # Reuse previously cloned layer.\n                layer \u003d layer_map[layer]\n                # Don\u0027t call InputLayer multiple times.\n                if isinstance(layer, InputLayer):\n                    continue\n\n            # Gather inputs to call the new layer.\n            reference_input_tensors \u003d node.input_tensors\n            reference_output_tensors \u003d node.output_tensors\n\n            # If all previous input tensors are available in tensor_map,\n            # then call node.inbound_layer on them.\n            computed_data \u003d []  # List of tuples (input, mask).\n            for x in reference_input_tensors:\n                if x in tensor_map:\n                    computed_data.append(tensor_map[x])\n\n            if len(computed_data) \u003d\u003d len(reference_input_tensors):\n                # Call layer.\n                if node.arguments:\n                    kwargs \u003d node.arguments\n                else:\n                    kwargs \u003d {}\n                if len(computed_data) \u003d\u003d 1:\n                    computed_tensor, computed_mask \u003d computed_data[0]\n                    if has_arg(layer.call, \u0027mask\u0027):\n                        if \u0027mask\u0027 not in kwargs:\n                            kwargs[\u0027mask\u0027] \u003d computed_mask\n                    output_tensors \u003d to_list(\n                        layer(computed_tensor, **kwargs))\n                    output_masks \u003d to_list(\n                        layer.compute_mask(computed_tensor,\n                                           computed_mask))\n                    computed_tensors \u003d [computed_tensor]\n                    computed_masks \u003d [computed_mask]\n                else:\n                    computed_tensors \u003d [x[0] for x in computed_data]\n                    computed_masks \u003d [x[1] for x in computed_data]\n                    if has_arg(layer.call, \u0027mask\u0027):\n                        if \u0027mask\u0027 not in kwargs:\n                            kwargs[\u0027mask\u0027] \u003d computed_masks\n                    output_tensors \u003d to_list(\n                        layer(computed_tensors, **kwargs))\n                    output_masks \u003d to_list(\n                        layer.compute_mask(computed_tensors,\n                                           computed_masks))\n                # Update tensor_map.\n                for x, y, mask in zip(reference_output_tensors,\n                                      output_tensors,\n                                      output_masks):\n                    tensor_map[x] \u003d (y, mask)\n\n    # Check that we did compute the model outputs,\n    # then instantiate a new model from inputs and outputs.\n    output_tensors \u003d []\n    for x in model.outputs:\n        assert x in tensor_map, \u0027Could not compute output \u0027 + str(x)\n        tensor, _ \u003d tensor_map[x]\n        output_tensors.append(tensor)\n    return Model(input_tensors, output_tensors, name\u003dmodel.name)\n\n",
      "path": "keras/models.py",
      "functionStartLine": 26,
      "functionName": "_clone_functional_model",
      "functionAnnotation": "",
      "diff": "@@ -1,145 +1,145 @@\n def _clone_functional_model(model, input_tensors\u003dNone):\n     \"\"\"Clone a functional `Model` instance.\n \n     Model cloning is similar to calling a model on new inputs,\n     except that it creates new layers (and thus new weights) instead\n     of sharing the weights of the existing layers.\n \n     # Arguments\n         model: Instance of `Model`.\n         input_tensors: optional list of input tensors\n             to build the model upon. If not provided,\n             placeholders will be created.\n \n     # Returns\n         An instance of `Model` reproducing the behavior\n         of the original model, on top of new inputs tensors,\n         using newly instantiated weights.\n \n     # Raises\n         ValueError: in case of invalid `model` argument value.\n     \"\"\"\n     if not isinstance(model, Model):\n         raise ValueError(\u0027Expected `model` argument \u0027\n                          \u0027to be a `Model` instance, got \u0027, model)\n     if isinstance(model, Sequential):\n         raise ValueError(\u0027Expected `model` argument \u0027\n                          \u0027to be a functional `Model` instance, \u0027\n                          \u0027got a `Sequential` instance instead:\u0027, model)\n \n     layer_map \u003d {}  # Cache for created layers.\n     tensor_map \u003d {}  # Map {reference_tensor: (corresponding_tensor, mask)}\n     if input_tensors is None:\n         # Create placeholders to build the model on top of.\n         input_layers \u003d []\n         input_tensors \u003d []\n         for layer in model._input_layers:\n             input_tensor \u003d Input(batch_shape\u003dlayer.batch_input_shape,\n                                  dtype\u003dlayer.dtype,\n                                  sparse\u003dlayer.sparse,\n                                  name\u003dlayer.name)\n             input_tensors.append(input_tensor)\n             # Cache newly created input layer.\n             newly_created_input_layer \u003d input_tensor._keras_history[0]\n             layer_map[layer] \u003d newly_created_input_layer\n-        for original_input_layer, cloned_input_layer in zip(model._input_layers, input_layers):\n-            layer_map[original_input_layer] \u003d cloned_input_layer\n+        for _original, _cloned in zip(model._input_layers, input_layers):\n+            layer_map[_original] \u003d _cloned\n     else:\n         # Make sure that all input tensors come from a Keras layer.\n         # If tensor comes from an input layer: cache the input layer.\n         input_tensors \u003d to_list(input_tensors)\n         _input_tensors \u003d []\n         for i, x in enumerate(input_tensors):\n             if not K.is_keras_tensor(x):\n                 name \u003d model._input_layers[i].name\n                 input_tensor \u003d Input(tensor\u003dx,\n                                      name\u003d\u0027input_wrapper_for_\u0027 + name)\n                 _input_tensors.append(input_tensor)\n                 # Cache newly created input layer.\n                 original_input_layer \u003d x._keras_history[0]\n                 newly_created_input_layer \u003d input_tensor._keras_history[0]\n                 layer_map[original_input_layer] \u003d newly_created_input_layer\n             else:\n                 _input_tensors.append(x)\n         input_tensors \u003d _input_tensors\n \n     for x, y in zip(model.inputs, input_tensors):\n         tensor_map[x] \u003d (y, None)  # tensor, mask\n \n     # Iterated over every node in the reference model, in depth order.\n     depth_keys \u003d list(model._nodes_by_depth.keys())\n     depth_keys.sort(reverse\u003dTrue)\n     for depth in depth_keys:\n         nodes \u003d model._nodes_by_depth[depth]\n         for node in nodes:\n             # Recover the corresponding layer.\n             layer \u003d node.outbound_layer\n \n             # Get or create layer.\n             if layer not in layer_map:\n                 # Clone layer.\n                 new_layer \u003d layer.__class__.from_config(layer.get_config())\n                 layer_map[layer] \u003d new_layer\n                 layer \u003d new_layer\n             else:\n                 # Reuse previously cloned layer.\n                 layer \u003d layer_map[layer]\n                 # Don\u0027t call InputLayer multiple times.\n                 if isinstance(layer, InputLayer):\n                     continue\n \n             # Gather inputs to call the new layer.\n             reference_input_tensors \u003d node.input_tensors\n             reference_output_tensors \u003d node.output_tensors\n \n             # If all previous input tensors are available in tensor_map,\n             # then call node.inbound_layer on them.\n             computed_data \u003d []  # List of tuples (input, mask).\n             for x in reference_input_tensors:\n                 if x in tensor_map:\n                     computed_data.append(tensor_map[x])\n \n             if len(computed_data) \u003d\u003d len(reference_input_tensors):\n                 # Call layer.\n                 if node.arguments:\n                     kwargs \u003d node.arguments\n                 else:\n                     kwargs \u003d {}\n                 if len(computed_data) \u003d\u003d 1:\n                     computed_tensor, computed_mask \u003d computed_data[0]\n                     if has_arg(layer.call, \u0027mask\u0027):\n                         if \u0027mask\u0027 not in kwargs:\n                             kwargs[\u0027mask\u0027] \u003d computed_mask\n                     output_tensors \u003d to_list(\n                         layer(computed_tensor, **kwargs))\n                     output_masks \u003d to_list(\n                         layer.compute_mask(computed_tensor,\n                                            computed_mask))\n                     computed_tensors \u003d [computed_tensor]\n                     computed_masks \u003d [computed_mask]\n                 else:\n                     computed_tensors \u003d [x[0] for x in computed_data]\n                     computed_masks \u003d [x[1] for x in computed_data]\n                     if has_arg(layer.call, \u0027mask\u0027):\n                         if \u0027mask\u0027 not in kwargs:\n                             kwargs[\u0027mask\u0027] \u003d computed_masks\n                     output_tensors \u003d to_list(\n                         layer(computed_tensors, **kwargs))\n                     output_masks \u003d to_list(\n                         layer.compute_mask(computed_tensors,\n                                            computed_masks))\n                 # Update tensor_map.\n                 for x, y, mask in zip(reference_output_tensors,\n                                       output_tensors,\n                                       output_masks):\n                     tensor_map[x] \u003d (y, mask)\n \n     # Check that we did compute the model outputs,\n     # then instantiate a new model from inputs and outputs.\n     output_tensors \u003d []\n     for x in model.outputs:\n         assert x in tensor_map, \u0027Could not compute output \u0027 + str(x)\n         tensor, _ \u003d tensor_map[x]\n         output_tensors.append(tensor)\n     return Model(input_tensors, output_tensors, name\u003dmodel.name)\n \n",
      "extendedDetails": {}
    },
    "3b440235e237ef59ec5763c413e7f4292dab5d79": {
      "type": "Ybodychange",
      "commitMessage": "Enable Model subclassing API (#10046)\n\n* Refactor topological part of Keras engine.\r\n\r\n* Fix imports\r\n\r\n* Fix merge mixup.\r\n\r\n* Refactor training part of the Keras engine.\r\n\r\n* Fix unit tests.\r\n\r\n* Refactor Network to prepare support for Model subclassing\r\n\r\n* Finish enabling Model subclassing.\r\n",
      "commitDate": "2018/4/27 上午9:10",
      "commitName": "3b440235e237ef59ec5763c413e7f4292dab5d79",
      "commitAuthor": "François Chollet",
      "commitDateOld": "2018/4/25 上午3:34",
      "commitNameOld": "49f5b931410bc2e56378f20a15e8ac919e0efb88",
      "commitAuthorOld": "François Chollet",
      "daysBetweenCommits": 2.23,
      "commitsBetweenForRepo": 7,
      "commitsBetweenForFile": 1,
      "actualSource": "def _clone_functional_model(model, input_tensors\u003dNone):\n    \"\"\"Clone a functional `Model` instance.\n\n    Model cloning is similar to calling a model on new inputs,\n    except that it creates new layers (and thus new weights) instead\n    of sharing the weights of the existing layers.\n\n    # Arguments\n        model: Instance of `Model`.\n        input_tensors: optional list of input tensors\n            to build the model upon. If not provided,\n            placeholders will be created.\n\n    # Returns\n        An instance of `Model` reproducing the behavior\n        of the original model, on top of new inputs tensors,\n        using newly instantiated weights.\n\n    # Raises\n        ValueError: in case of invalid `model` argument value.\n    \"\"\"\n    if not isinstance(model, Model):\n        raise ValueError(\u0027Expected `model` argument \u0027\n                         \u0027to be a `Model` instance, got \u0027, model)\n    if isinstance(model, Sequential):\n        raise ValueError(\u0027Expected `model` argument \u0027\n                         \u0027to be a functional `Model` instance, \u0027\n                         \u0027got a `Sequential` instance instead:\u0027, model)\n\n    layer_map \u003d {}  # Cache for created layers.\n    tensor_map \u003d {}  # Map {reference_tensor: (corresponding_tensor, mask)}\n    if input_tensors is None:\n        # Create placeholders to build the model on top of.\n        input_layers \u003d []\n        input_tensors \u003d []\n        for layer in model._input_layers:\n            input_tensor \u003d Input(batch_shape\u003dlayer.batch_input_shape,\n                                 dtype\u003dlayer.dtype,\n                                 sparse\u003dlayer.sparse,\n                                 name\u003dlayer.name)\n            input_tensors.append(input_tensor)\n            # Cache newly created input layer.\n            newly_created_input_layer \u003d input_tensor._keras_history[0]\n            layer_map[layer] \u003d newly_created_input_layer\n        for original_input_layer, cloned_input_layer in zip(model._input_layers, input_layers):\n            layer_map[original_input_layer] \u003d cloned_input_layer\n    else:\n        # Make sure that all input tensors come from a Keras layer.\n        # If tensor comes from an input layer: cache the input layer.\n        input_tensors \u003d to_list(input_tensors)\n        _input_tensors \u003d []\n        for i, x in enumerate(input_tensors):\n            if not K.is_keras_tensor(x):\n                name \u003d model._input_layers[i].name\n                input_tensor \u003d Input(tensor\u003dx,\n                                     name\u003d\u0027input_wrapper_for_\u0027 + name)\n                _input_tensors.append(input_tensor)\n                # Cache newly created input layer.\n                original_input_layer \u003d x._keras_history[0]\n                newly_created_input_layer \u003d input_tensor._keras_history[0]\n                layer_map[original_input_layer] \u003d newly_created_input_layer\n            else:\n                _input_tensors.append(x)\n        input_tensors \u003d _input_tensors\n\n    for x, y in zip(model.inputs, input_tensors):\n        tensor_map[x] \u003d (y, None)  # tensor, mask\n\n    # Iterated over every node in the reference model, in depth order.\n    depth_keys \u003d list(model._nodes_by_depth.keys())\n    depth_keys.sort(reverse\u003dTrue)\n    for depth in depth_keys:\n        nodes \u003d model._nodes_by_depth[depth]\n        for node in nodes:\n            # Recover the corresponding layer.\n            layer \u003d node.outbound_layer\n\n            # Get or create layer.\n            if layer not in layer_map:\n                # Clone layer.\n                new_layer \u003d layer.__class__.from_config(layer.get_config())\n                layer_map[layer] \u003d new_layer\n                layer \u003d new_layer\n            else:\n                # Reuse previously cloned layer.\n                layer \u003d layer_map[layer]\n                # Don\u0027t call InputLayer multiple times.\n                if isinstance(layer, InputLayer):\n                    continue\n\n            # Gather inputs to call the new layer.\n            reference_input_tensors \u003d node.input_tensors\n            reference_output_tensors \u003d node.output_tensors\n\n            # If all previous input tensors are available in tensor_map,\n            # then call node.inbound_layer on them.\n            computed_data \u003d []  # List of tuples (input, mask).\n            for x in reference_input_tensors:\n                if x in tensor_map:\n                    computed_data.append(tensor_map[x])\n\n            if len(computed_data) \u003d\u003d len(reference_input_tensors):\n                # Call layer.\n                if node.arguments:\n                    kwargs \u003d node.arguments\n                else:\n                    kwargs \u003d {}\n                if len(computed_data) \u003d\u003d 1:\n                    computed_tensor, computed_mask \u003d computed_data[0]\n                    if has_arg(layer.call, \u0027mask\u0027):\n                        if \u0027mask\u0027 not in kwargs:\n                            kwargs[\u0027mask\u0027] \u003d computed_mask\n                    output_tensors \u003d to_list(\n                        layer(computed_tensor, **kwargs))\n                    output_masks \u003d to_list(\n                        layer.compute_mask(computed_tensor,\n                                           computed_mask))\n                    computed_tensors \u003d [computed_tensor]\n                    computed_masks \u003d [computed_mask]\n                else:\n                    computed_tensors \u003d [x[0] for x in computed_data]\n                    computed_masks \u003d [x[1] for x in computed_data]\n                    if has_arg(layer.call, \u0027mask\u0027):\n                        if \u0027mask\u0027 not in kwargs:\n                            kwargs[\u0027mask\u0027] \u003d computed_masks\n                    output_tensors \u003d to_list(\n                        layer(computed_tensors, **kwargs))\n                    output_masks \u003d to_list(\n                        layer.compute_mask(computed_tensors,\n                                           computed_masks))\n                # Update tensor_map.\n                for x, y, mask in zip(reference_output_tensors,\n                                      output_tensors,\n                                      output_masks):\n                    tensor_map[x] \u003d (y, mask)\n\n    # Check that we did compute the model outputs,\n    # then instantiate a new model from inputs and outputs.\n    output_tensors \u003d []\n    for x in model.outputs:\n        assert x in tensor_map, \u0027Could not compute output \u0027 + str(x)\n        tensor, _ \u003d tensor_map[x]\n        output_tensors.append(tensor)\n    return Model(input_tensors, output_tensors, name\u003dmodel.name)\n\n",
      "path": "keras/models.py",
      "functionStartLine": 26,
      "functionName": "_clone_functional_model",
      "functionAnnotation": "",
      "diff": "@@ -1,145 +1,145 @@\n def _clone_functional_model(model, input_tensors\u003dNone):\n     \"\"\"Clone a functional `Model` instance.\n \n     Model cloning is similar to calling a model on new inputs,\n     except that it creates new layers (and thus new weights) instead\n     of sharing the weights of the existing layers.\n \n     # Arguments\n         model: Instance of `Model`.\n         input_tensors: optional list of input tensors\n             to build the model upon. If not provided,\n             placeholders will be created.\n \n     # Returns\n         An instance of `Model` reproducing the behavior\n         of the original model, on top of new inputs tensors,\n         using newly instantiated weights.\n \n     # Raises\n         ValueError: in case of invalid `model` argument value.\n     \"\"\"\n     if not isinstance(model, Model):\n         raise ValueError(\u0027Expected `model` argument \u0027\n                          \u0027to be a `Model` instance, got \u0027, model)\n     if isinstance(model, Sequential):\n         raise ValueError(\u0027Expected `model` argument \u0027\n                          \u0027to be a functional `Model` instance, \u0027\n                          \u0027got a `Sequential` instance instead:\u0027, model)\n \n     layer_map \u003d {}  # Cache for created layers.\n     tensor_map \u003d {}  # Map {reference_tensor: (corresponding_tensor, mask)}\n     if input_tensors is None:\n         # Create placeholders to build the model on top of.\n         input_layers \u003d []\n         input_tensors \u003d []\n-        for layer in model.input_layers:\n+        for layer in model._input_layers:\n             input_tensor \u003d Input(batch_shape\u003dlayer.batch_input_shape,\n                                  dtype\u003dlayer.dtype,\n                                  sparse\u003dlayer.sparse,\n                                  name\u003dlayer.name)\n             input_tensors.append(input_tensor)\n             # Cache newly created input layer.\n             newly_created_input_layer \u003d input_tensor._keras_history[0]\n             layer_map[layer] \u003d newly_created_input_layer\n-        for original_input_layer, cloned_input_layer in zip(model.input_layers, input_layers):\n+        for original_input_layer, cloned_input_layer in zip(model._input_layers, input_layers):\n             layer_map[original_input_layer] \u003d cloned_input_layer\n     else:\n         # Make sure that all input tensors come from a Keras layer.\n         # If tensor comes from an input layer: cache the input layer.\n         input_tensors \u003d to_list(input_tensors)\n         _input_tensors \u003d []\n         for i, x in enumerate(input_tensors):\n             if not K.is_keras_tensor(x):\n-                name \u003d model.input_layers[i].name\n+                name \u003d model._input_layers[i].name\n                 input_tensor \u003d Input(tensor\u003dx,\n                                      name\u003d\u0027input_wrapper_for_\u0027 + name)\n                 _input_tensors.append(input_tensor)\n                 # Cache newly created input layer.\n                 original_input_layer \u003d x._keras_history[0]\n                 newly_created_input_layer \u003d input_tensor._keras_history[0]\n                 layer_map[original_input_layer] \u003d newly_created_input_layer\n             else:\n                 _input_tensors.append(x)\n         input_tensors \u003d _input_tensors\n \n     for x, y in zip(model.inputs, input_tensors):\n         tensor_map[x] \u003d (y, None)  # tensor, mask\n \n     # Iterated over every node in the reference model, in depth order.\n     depth_keys \u003d list(model._nodes_by_depth.keys())\n     depth_keys.sort(reverse\u003dTrue)\n     for depth in depth_keys:\n         nodes \u003d model._nodes_by_depth[depth]\n         for node in nodes:\n             # Recover the corresponding layer.\n             layer \u003d node.outbound_layer\n \n             # Get or create layer.\n             if layer not in layer_map:\n                 # Clone layer.\n                 new_layer \u003d layer.__class__.from_config(layer.get_config())\n                 layer_map[layer] \u003d new_layer\n                 layer \u003d new_layer\n             else:\n                 # Reuse previously cloned layer.\n                 layer \u003d layer_map[layer]\n                 # Don\u0027t call InputLayer multiple times.\n                 if isinstance(layer, InputLayer):\n                     continue\n \n             # Gather inputs to call the new layer.\n             reference_input_tensors \u003d node.input_tensors\n             reference_output_tensors \u003d node.output_tensors\n \n             # If all previous input tensors are available in tensor_map,\n             # then call node.inbound_layer on them.\n             computed_data \u003d []  # List of tuples (input, mask).\n             for x in reference_input_tensors:\n                 if x in tensor_map:\n                     computed_data.append(tensor_map[x])\n \n             if len(computed_data) \u003d\u003d len(reference_input_tensors):\n                 # Call layer.\n                 if node.arguments:\n                     kwargs \u003d node.arguments\n                 else:\n                     kwargs \u003d {}\n                 if len(computed_data) \u003d\u003d 1:\n                     computed_tensor, computed_mask \u003d computed_data[0]\n                     if has_arg(layer.call, \u0027mask\u0027):\n                         if \u0027mask\u0027 not in kwargs:\n                             kwargs[\u0027mask\u0027] \u003d computed_mask\n                     output_tensors \u003d to_list(\n                         layer(computed_tensor, **kwargs))\n                     output_masks \u003d to_list(\n                         layer.compute_mask(computed_tensor,\n                                            computed_mask))\n                     computed_tensors \u003d [computed_tensor]\n                     computed_masks \u003d [computed_mask]\n                 else:\n                     computed_tensors \u003d [x[0] for x in computed_data]\n                     computed_masks \u003d [x[1] for x in computed_data]\n                     if has_arg(layer.call, \u0027mask\u0027):\n                         if \u0027mask\u0027 not in kwargs:\n                             kwargs[\u0027mask\u0027] \u003d computed_masks\n                     output_tensors \u003d to_list(\n                         layer(computed_tensors, **kwargs))\n                     output_masks \u003d to_list(\n                         layer.compute_mask(computed_tensors,\n                                            computed_masks))\n                 # Update tensor_map.\n                 for x, y, mask in zip(reference_output_tensors,\n                                       output_tensors,\n                                       output_masks):\n                     tensor_map[x] \u003d (y, mask)\n \n     # Check that we did compute the model outputs,\n     # then instantiate a new model from inputs and outputs.\n     output_tensors \u003d []\n     for x in model.outputs:\n         assert x in tensor_map, \u0027Could not compute output \u0027 + str(x)\n         tensor, _ \u003d tensor_map[x]\n         output_tensors.append(tensor)\n     return Model(input_tensors, output_tensors, name\u003dmodel.name)\n \n",
      "extendedDetails": {}
    },
    "49f5b931410bc2e56378f20a15e8ac919e0efb88": {
      "type": "Ybodychange",
      "commitMessage": "Refactor topological part of `engine` module (#10023)\n\n* Refactor topological part of Keras engine.\r\n\r\n* Fix imports\r\n\r\n* Fix merge mixup.\r\n",
      "commitDate": "2018/4/25 上午3:34",
      "commitName": "49f5b931410bc2e56378f20a15e8ac919e0efb88",
      "commitAuthor": "François Chollet",
      "commitDateOld": "2018/4/14 上午8:29",
      "commitNameOld": "083a41cc6be7b1796e3817df198d1557bb8557b8",
      "commitAuthorOld": "FirefoxMetzger",
      "daysBetweenCommits": 10.8,
      "commitsBetweenForRepo": 16,
      "commitsBetweenForFile": 1,
      "actualSource": "def _clone_functional_model(model, input_tensors\u003dNone):\n    \"\"\"Clone a functional `Model` instance.\n\n    Model cloning is similar to calling a model on new inputs,\n    except that it creates new layers (and thus new weights) instead\n    of sharing the weights of the existing layers.\n\n    # Arguments\n        model: Instance of `Model`.\n        input_tensors: optional list of input tensors\n            to build the model upon. If not provided,\n            placeholders will be created.\n\n    # Returns\n        An instance of `Model` reproducing the behavior\n        of the original model, on top of new inputs tensors,\n        using newly instantiated weights.\n\n    # Raises\n        ValueError: in case of invalid `model` argument value.\n    \"\"\"\n    if not isinstance(model, Model):\n        raise ValueError(\u0027Expected `model` argument \u0027\n                         \u0027to be a `Model` instance, got \u0027, model)\n    if isinstance(model, Sequential):\n        raise ValueError(\u0027Expected `model` argument \u0027\n                         \u0027to be a functional `Model` instance, \u0027\n                         \u0027got a `Sequential` instance instead:\u0027, model)\n\n    layer_map \u003d {}  # Cache for created layers.\n    tensor_map \u003d {}  # Map {reference_tensor: (corresponding_tensor, mask)}\n    if input_tensors is None:\n        # Create placeholders to build the model on top of.\n        input_layers \u003d []\n        input_tensors \u003d []\n        for layer in model.input_layers:\n            input_tensor \u003d Input(batch_shape\u003dlayer.batch_input_shape,\n                                 dtype\u003dlayer.dtype,\n                                 sparse\u003dlayer.sparse,\n                                 name\u003dlayer.name)\n            input_tensors.append(input_tensor)\n            # Cache newly created input layer.\n            newly_created_input_layer \u003d input_tensor._keras_history[0]\n            layer_map[layer] \u003d newly_created_input_layer\n        for original_input_layer, cloned_input_layer in zip(model.input_layers, input_layers):\n            layer_map[original_input_layer] \u003d cloned_input_layer\n    else:\n        # Make sure that all input tensors come from a Keras layer.\n        # If tensor comes from an input layer: cache the input layer.\n        input_tensors \u003d to_list(input_tensors)\n        _input_tensors \u003d []\n        for i, x in enumerate(input_tensors):\n            if not K.is_keras_tensor(x):\n                name \u003d model.input_layers[i].name\n                input_tensor \u003d Input(tensor\u003dx,\n                                     name\u003d\u0027input_wrapper_for_\u0027 + name)\n                _input_tensors.append(input_tensor)\n                # Cache newly created input layer.\n                original_input_layer \u003d x._keras_history[0]\n                newly_created_input_layer \u003d input_tensor._keras_history[0]\n                layer_map[original_input_layer] \u003d newly_created_input_layer\n            else:\n                _input_tensors.append(x)\n        input_tensors \u003d _input_tensors\n\n    for x, y in zip(model.inputs, input_tensors):\n        tensor_map[x] \u003d (y, None)  # tensor, mask\n\n    # Iterated over every node in the reference model, in depth order.\n    depth_keys \u003d list(model._nodes_by_depth.keys())\n    depth_keys.sort(reverse\u003dTrue)\n    for depth in depth_keys:\n        nodes \u003d model._nodes_by_depth[depth]\n        for node in nodes:\n            # Recover the corresponding layer.\n            layer \u003d node.outbound_layer\n\n            # Get or create layer.\n            if layer not in layer_map:\n                # Clone layer.\n                new_layer \u003d layer.__class__.from_config(layer.get_config())\n                layer_map[layer] \u003d new_layer\n                layer \u003d new_layer\n            else:\n                # Reuse previously cloned layer.\n                layer \u003d layer_map[layer]\n                # Don\u0027t call InputLayer multiple times.\n                if isinstance(layer, InputLayer):\n                    continue\n\n            # Gather inputs to call the new layer.\n            reference_input_tensors \u003d node.input_tensors\n            reference_output_tensors \u003d node.output_tensors\n\n            # If all previous input tensors are available in tensor_map,\n            # then call node.inbound_layer on them.\n            computed_data \u003d []  # List of tuples (input, mask).\n            for x in reference_input_tensors:\n                if x in tensor_map:\n                    computed_data.append(tensor_map[x])\n\n            if len(computed_data) \u003d\u003d len(reference_input_tensors):\n                # Call layer.\n                if node.arguments:\n                    kwargs \u003d node.arguments\n                else:\n                    kwargs \u003d {}\n                if len(computed_data) \u003d\u003d 1:\n                    computed_tensor, computed_mask \u003d computed_data[0]\n                    if has_arg(layer.call, \u0027mask\u0027):\n                        if \u0027mask\u0027 not in kwargs:\n                            kwargs[\u0027mask\u0027] \u003d computed_mask\n                    output_tensors \u003d to_list(\n                        layer(computed_tensor, **kwargs))\n                    output_masks \u003d to_list(\n                        layer.compute_mask(computed_tensor,\n                                           computed_mask))\n                    computed_tensors \u003d [computed_tensor]\n                    computed_masks \u003d [computed_mask]\n                else:\n                    computed_tensors \u003d [x[0] for x in computed_data]\n                    computed_masks \u003d [x[1] for x in computed_data]\n                    if has_arg(layer.call, \u0027mask\u0027):\n                        if \u0027mask\u0027 not in kwargs:\n                            kwargs[\u0027mask\u0027] \u003d computed_masks\n                    output_tensors \u003d to_list(\n                        layer(computed_tensors, **kwargs))\n                    output_masks \u003d to_list(\n                        layer.compute_mask(computed_tensors,\n                                           computed_masks))\n                # Update tensor_map.\n                for x, y, mask in zip(reference_output_tensors,\n                                      output_tensors,\n                                      output_masks):\n                    tensor_map[x] \u003d (y, mask)\n\n    # Check that we did compute the model outputs,\n    # then instantiate a new model from inputs and outputs.\n    output_tensors \u003d []\n    for x in model.outputs:\n        assert x in tensor_map, \u0027Could not compute output \u0027 + str(x)\n        tensor, _ \u003d tensor_map[x]\n        output_tensors.append(tensor)\n    return Model(input_tensors, output_tensors, name\u003dmodel.name)\n\n",
      "path": "keras/models.py",
      "functionStartLine": 26,
      "functionName": "_clone_functional_model",
      "functionAnnotation": "",
      "diff": "@@ -1,145 +1,145 @@\n def _clone_functional_model(model, input_tensors\u003dNone):\n     \"\"\"Clone a functional `Model` instance.\n \n     Model cloning is similar to calling a model on new inputs,\n     except that it creates new layers (and thus new weights) instead\n     of sharing the weights of the existing layers.\n \n     # Arguments\n         model: Instance of `Model`.\n         input_tensors: optional list of input tensors\n             to build the model upon. If not provided,\n             placeholders will be created.\n \n     # Returns\n         An instance of `Model` reproducing the behavior\n         of the original model, on top of new inputs tensors,\n         using newly instantiated weights.\n \n     # Raises\n         ValueError: in case of invalid `model` argument value.\n     \"\"\"\n     if not isinstance(model, Model):\n         raise ValueError(\u0027Expected `model` argument \u0027\n                          \u0027to be a `Model` instance, got \u0027, model)\n     if isinstance(model, Sequential):\n         raise ValueError(\u0027Expected `model` argument \u0027\n                          \u0027to be a functional `Model` instance, \u0027\n                          \u0027got a `Sequential` instance instead:\u0027, model)\n \n     layer_map \u003d {}  # Cache for created layers.\n     tensor_map \u003d {}  # Map {reference_tensor: (corresponding_tensor, mask)}\n     if input_tensors is None:\n         # Create placeholders to build the model on top of.\n         input_layers \u003d []\n         input_tensors \u003d []\n         for layer in model.input_layers:\n             input_tensor \u003d Input(batch_shape\u003dlayer.batch_input_shape,\n                                  dtype\u003dlayer.dtype,\n                                  sparse\u003dlayer.sparse,\n                                  name\u003dlayer.name)\n             input_tensors.append(input_tensor)\n             # Cache newly created input layer.\n             newly_created_input_layer \u003d input_tensor._keras_history[0]\n             layer_map[layer] \u003d newly_created_input_layer\n         for original_input_layer, cloned_input_layer in zip(model.input_layers, input_layers):\n             layer_map[original_input_layer] \u003d cloned_input_layer\n     else:\n         # Make sure that all input tensors come from a Keras layer.\n         # If tensor comes from an input layer: cache the input layer.\n-        input_tensors \u003d topology._to_list(input_tensors)\n+        input_tensors \u003d to_list(input_tensors)\n         _input_tensors \u003d []\n         for i, x in enumerate(input_tensors):\n             if not K.is_keras_tensor(x):\n                 name \u003d model.input_layers[i].name\n                 input_tensor \u003d Input(tensor\u003dx,\n                                      name\u003d\u0027input_wrapper_for_\u0027 + name)\n                 _input_tensors.append(input_tensor)\n                 # Cache newly created input layer.\n                 original_input_layer \u003d x._keras_history[0]\n                 newly_created_input_layer \u003d input_tensor._keras_history[0]\n                 layer_map[original_input_layer] \u003d newly_created_input_layer\n             else:\n                 _input_tensors.append(x)\n         input_tensors \u003d _input_tensors\n \n     for x, y in zip(model.inputs, input_tensors):\n         tensor_map[x] \u003d (y, None)  # tensor, mask\n \n     # Iterated over every node in the reference model, in depth order.\n     depth_keys \u003d list(model._nodes_by_depth.keys())\n     depth_keys.sort(reverse\u003dTrue)\n     for depth in depth_keys:\n         nodes \u003d model._nodes_by_depth[depth]\n         for node in nodes:\n             # Recover the corresponding layer.\n             layer \u003d node.outbound_layer\n \n             # Get or create layer.\n             if layer not in layer_map:\n                 # Clone layer.\n                 new_layer \u003d layer.__class__.from_config(layer.get_config())\n                 layer_map[layer] \u003d new_layer\n                 layer \u003d new_layer\n             else:\n                 # Reuse previously cloned layer.\n                 layer \u003d layer_map[layer]\n                 # Don\u0027t call InputLayer multiple times.\n-                if isinstance(layer, topology.InputLayer):\n+                if isinstance(layer, InputLayer):\n                     continue\n \n             # Gather inputs to call the new layer.\n             reference_input_tensors \u003d node.input_tensors\n             reference_output_tensors \u003d node.output_tensors\n \n             # If all previous input tensors are available in tensor_map,\n             # then call node.inbound_layer on them.\n             computed_data \u003d []  # List of tuples (input, mask).\n             for x in reference_input_tensors:\n                 if x in tensor_map:\n                     computed_data.append(tensor_map[x])\n \n             if len(computed_data) \u003d\u003d len(reference_input_tensors):\n                 # Call layer.\n                 if node.arguments:\n                     kwargs \u003d node.arguments\n                 else:\n                     kwargs \u003d {}\n                 if len(computed_data) \u003d\u003d 1:\n                     computed_tensor, computed_mask \u003d computed_data[0]\n                     if has_arg(layer.call, \u0027mask\u0027):\n                         if \u0027mask\u0027 not in kwargs:\n                             kwargs[\u0027mask\u0027] \u003d computed_mask\n-                    output_tensors \u003d topology._to_list(\n+                    output_tensors \u003d to_list(\n                         layer(computed_tensor, **kwargs))\n-                    output_masks \u003d topology._to_list(\n+                    output_masks \u003d to_list(\n                         layer.compute_mask(computed_tensor,\n                                            computed_mask))\n                     computed_tensors \u003d [computed_tensor]\n                     computed_masks \u003d [computed_mask]\n                 else:\n                     computed_tensors \u003d [x[0] for x in computed_data]\n                     computed_masks \u003d [x[1] for x in computed_data]\n                     if has_arg(layer.call, \u0027mask\u0027):\n                         if \u0027mask\u0027 not in kwargs:\n                             kwargs[\u0027mask\u0027] \u003d computed_masks\n-                    output_tensors \u003d topology._to_list(\n+                    output_tensors \u003d to_list(\n                         layer(computed_tensors, **kwargs))\n-                    output_masks \u003d topology._to_list(\n+                    output_masks \u003d to_list(\n                         layer.compute_mask(computed_tensors,\n                                            computed_masks))\n                 # Update tensor_map.\n                 for x, y, mask in zip(reference_output_tensors,\n                                       output_tensors,\n                                       output_masks):\n                     tensor_map[x] \u003d (y, mask)\n \n     # Check that we did compute the model outputs,\n     # then instantiate a new model from inputs and outputs.\n     output_tensors \u003d []\n     for x in model.outputs:\n         assert x in tensor_map, \u0027Could not compute output \u0027 + str(x)\n         tensor, _ \u003d tensor_map[x]\n         output_tensors.append(tensor)\n     return Model(input_tensors, output_tensors, name\u003dmodel.name)\n \n",
      "extendedDetails": {}
    },
    "958239c621a6be037c5f8b30be9270310735f725": {
      "type": "Ybodychange",
      "commitMessage": "Make private topological properties Python-private\n",
      "commitDate": "2018/1/10 上午3:41",
      "commitName": "958239c621a6be037c5f8b30be9270310735f725",
      "commitAuthor": "Francois Chollet",
      "commitDateOld": "2018/1/6 上午5:37",
      "commitNameOld": "f6eda660f7bc3ec9b7b2423b47e4804a31fcff8b",
      "commitAuthorOld": "Francois Chollet",
      "daysBetweenCommits": 3.92,
      "commitsBetweenForRepo": 19,
      "commitsBetweenForFile": 1,
      "actualSource": "def _clone_functional_model(model, input_tensors\u003dNone):\n    \"\"\"Clone a functional `Model` instance.\n\n    Model cloning is similar to calling a model on new inputs,\n    except that it creates new layers (and thus new weights) instead\n    of sharing the weights of the existing layers.\n\n    # Arguments\n        model: Instance of `Model`.\n        input_tensors: optional list of input tensors\n            to build the model upon. If not provided,\n            placeholders will be created.\n\n    # Returns\n        An instance of `Model` reproducing the behavior\n        of the original model, on top of new inputs tensors,\n        using newly instantiated weights.\n\n    # Raises\n        ValueError: in case of invalid `model` argument value.\n    \"\"\"\n    if not isinstance(model, Model):\n        raise ValueError(\u0027Expected `model` argument \u0027\n                         \u0027to be a `Model` instance, got \u0027, model)\n    if isinstance(model, Sequential):\n        raise ValueError(\u0027Expected `model` argument \u0027\n                         \u0027to be a functional `Model` instance, \u0027\n                         \u0027got a `Sequential` instance instead:\u0027, model)\n\n    layer_map \u003d {}  # Cache for created layers.\n    tensor_map \u003d {}  # Map {reference_tensor: (corresponding_tensor, mask)}\n    if input_tensors is None:\n        # Create placeholders to build the model on top of.\n        input_layers \u003d []\n        input_tensors \u003d []\n        for layer in model.input_layers:\n            input_tensor \u003d Input(batch_shape\u003dlayer.batch_input_shape,\n                                 dtype\u003dlayer.dtype,\n                                 sparse\u003dlayer.sparse,\n                                 name\u003dlayer.name)\n            input_tensors.append(input_tensor)\n            # Cache newly created input layer.\n            newly_created_input_layer \u003d input_tensor._keras_history[0]\n            layer_map[layer] \u003d newly_created_input_layer\n        for original_input_layer, cloned_input_layer in zip(model.input_layers, input_layers):\n            layer_map[original_input_layer] \u003d cloned_input_layer\n    else:\n        # Make sure that all input tensors come from a Keras layer.\n        # If tensor comes from an input layer: cache the input layer.\n        input_tensors \u003d topology._to_list(input_tensors)\n        _input_tensors \u003d []\n        for i, x in enumerate(input_tensors):\n            if not K.is_keras_tensor(x):\n                name \u003d model.input_layers[i].name\n                input_tensor \u003d Input(tensor\u003dx,\n                                     name\u003d\u0027input_wrapper_for_\u0027 + name)\n                _input_tensors.append(input_tensor)\n                # Cache newly created input layer.\n                original_input_layer \u003d x._keras_history[0]\n                newly_created_input_layer \u003d input_tensor._keras_history[0]\n                layer_map[original_input_layer] \u003d newly_created_input_layer\n            else:\n                _input_tensors.append(x)\n        input_tensors \u003d _input_tensors\n\n    for x, y in zip(model.inputs, input_tensors):\n        tensor_map[x] \u003d (y, None)  # tensor, mask\n\n    # Iterated over every node in the reference model, in depth order.\n    depth_keys \u003d list(model._nodes_by_depth.keys())\n    depth_keys.sort(reverse\u003dTrue)\n    for depth in depth_keys:\n        nodes \u003d model._nodes_by_depth[depth]\n        for node in nodes:\n            # Recover the corresponding layer.\n            layer \u003d node.outbound_layer\n\n            # Get or create layer.\n            if layer not in layer_map:\n                # Clone layer.\n                new_layer \u003d layer.__class__.from_config(layer.get_config())\n                layer_map[layer] \u003d new_layer\n                layer \u003d new_layer\n            else:\n                # Reuse previously cloned layer.\n                layer \u003d layer_map[layer]\n                # Don\u0027t call InputLayer multiple times.\n                if isinstance(layer, topology.InputLayer):\n                    continue\n\n            # Gather inputs to call the new layer.\n            reference_input_tensors \u003d node.input_tensors\n            reference_output_tensors \u003d node.output_tensors\n\n            # If all previous input tensors are available in tensor_map,\n            # then call node.inbound_layer on them.\n            computed_data \u003d []  # List of tuples (input, mask).\n            for x in reference_input_tensors:\n                if x in tensor_map:\n                    computed_data.append(tensor_map[x])\n\n            if len(computed_data) \u003d\u003d len(reference_input_tensors):\n                # Call layer.\n                if node.arguments:\n                    kwargs \u003d node.arguments\n                else:\n                    kwargs \u003d {}\n                if len(computed_data) \u003d\u003d 1:\n                    computed_tensor, computed_mask \u003d computed_data[0]\n                    if has_arg(layer.call, \u0027mask\u0027):\n                        if \u0027mask\u0027 not in kwargs:\n                            kwargs[\u0027mask\u0027] \u003d computed_mask\n                    output_tensors \u003d topology._to_list(\n                        layer(computed_tensor, **kwargs))\n                    output_masks \u003d topology._to_list(\n                        layer.compute_mask(computed_tensor,\n                                           computed_mask))\n                    computed_tensors \u003d [computed_tensor]\n                    computed_masks \u003d [computed_mask]\n                else:\n                    computed_tensors \u003d [x[0] for x in computed_data]\n                    computed_masks \u003d [x[1] for x in computed_data]\n                    if has_arg(layer.call, \u0027mask\u0027):\n                        if \u0027mask\u0027 not in kwargs:\n                            kwargs[\u0027mask\u0027] \u003d computed_masks\n                    output_tensors \u003d topology._to_list(\n                        layer(computed_tensors, **kwargs))\n                    output_masks \u003d topology._to_list(\n                        layer.compute_mask(computed_tensors,\n                                           computed_masks))\n                # Update tensor_map.\n                for x, y, mask in zip(reference_output_tensors,\n                                      output_tensors,\n                                      output_masks):\n                    tensor_map[x] \u003d (y, mask)\n\n    # Check that we did compute the model outputs,\n    # then instantiate a new model from inputs and outputs.\n    output_tensors \u003d []\n    for x in model.outputs:\n        assert x in tensor_map, \u0027Could not compute output \u0027 + str(x)\n        tensor, _ \u003d tensor_map[x]\n        output_tensors.append(tensor)\n    return Model(input_tensors, output_tensors, name\u003dmodel.name)\n\n",
      "path": "keras/models.py",
      "functionStartLine": 1448,
      "functionName": "_clone_functional_model",
      "functionAnnotation": "",
      "diff": "@@ -1,145 +1,145 @@\n def _clone_functional_model(model, input_tensors\u003dNone):\n     \"\"\"Clone a functional `Model` instance.\n \n     Model cloning is similar to calling a model on new inputs,\n     except that it creates new layers (and thus new weights) instead\n     of sharing the weights of the existing layers.\n \n     # Arguments\n         model: Instance of `Model`.\n         input_tensors: optional list of input tensors\n             to build the model upon. If not provided,\n             placeholders will be created.\n \n     # Returns\n         An instance of `Model` reproducing the behavior\n         of the original model, on top of new inputs tensors,\n         using newly instantiated weights.\n \n     # Raises\n         ValueError: in case of invalid `model` argument value.\n     \"\"\"\n     if not isinstance(model, Model):\n         raise ValueError(\u0027Expected `model` argument \u0027\n                          \u0027to be a `Model` instance, got \u0027, model)\n     if isinstance(model, Sequential):\n         raise ValueError(\u0027Expected `model` argument \u0027\n                          \u0027to be a functional `Model` instance, \u0027\n                          \u0027got a `Sequential` instance instead:\u0027, model)\n \n     layer_map \u003d {}  # Cache for created layers.\n     tensor_map \u003d {}  # Map {reference_tensor: (corresponding_tensor, mask)}\n     if input_tensors is None:\n         # Create placeholders to build the model on top of.\n         input_layers \u003d []\n         input_tensors \u003d []\n         for layer in model.input_layers:\n             input_tensor \u003d Input(batch_shape\u003dlayer.batch_input_shape,\n                                  dtype\u003dlayer.dtype,\n                                  sparse\u003dlayer.sparse,\n                                  name\u003dlayer.name)\n             input_tensors.append(input_tensor)\n             # Cache newly created input layer.\n             newly_created_input_layer \u003d input_tensor._keras_history[0]\n             layer_map[layer] \u003d newly_created_input_layer\n         for original_input_layer, cloned_input_layer in zip(model.input_layers, input_layers):\n             layer_map[original_input_layer] \u003d cloned_input_layer\n     else:\n         # Make sure that all input tensors come from a Keras layer.\n         # If tensor comes from an input layer: cache the input layer.\n         input_tensors \u003d topology._to_list(input_tensors)\n         _input_tensors \u003d []\n         for i, x in enumerate(input_tensors):\n             if not K.is_keras_tensor(x):\n                 name \u003d model.input_layers[i].name\n                 input_tensor \u003d Input(tensor\u003dx,\n                                      name\u003d\u0027input_wrapper_for_\u0027 + name)\n                 _input_tensors.append(input_tensor)\n                 # Cache newly created input layer.\n                 original_input_layer \u003d x._keras_history[0]\n                 newly_created_input_layer \u003d input_tensor._keras_history[0]\n                 layer_map[original_input_layer] \u003d newly_created_input_layer\n             else:\n                 _input_tensors.append(x)\n         input_tensors \u003d _input_tensors\n \n     for x, y in zip(model.inputs, input_tensors):\n         tensor_map[x] \u003d (y, None)  # tensor, mask\n \n     # Iterated over every node in the reference model, in depth order.\n-    depth_keys \u003d list(model.nodes_by_depth.keys())\n+    depth_keys \u003d list(model._nodes_by_depth.keys())\n     depth_keys.sort(reverse\u003dTrue)\n     for depth in depth_keys:\n-        nodes \u003d model.nodes_by_depth[depth]\n+        nodes \u003d model._nodes_by_depth[depth]\n         for node in nodes:\n             # Recover the corresponding layer.\n             layer \u003d node.outbound_layer\n \n             # Get or create layer.\n             if layer not in layer_map:\n                 # Clone layer.\n                 new_layer \u003d layer.__class__.from_config(layer.get_config())\n                 layer_map[layer] \u003d new_layer\n                 layer \u003d new_layer\n             else:\n                 # Reuse previously cloned layer.\n                 layer \u003d layer_map[layer]\n                 # Don\u0027t call InputLayer multiple times.\n                 if isinstance(layer, topology.InputLayer):\n                     continue\n \n             # Gather inputs to call the new layer.\n             reference_input_tensors \u003d node.input_tensors\n             reference_output_tensors \u003d node.output_tensors\n \n             # If all previous input tensors are available in tensor_map,\n             # then call node.inbound_layer on them.\n             computed_data \u003d []  # List of tuples (input, mask).\n             for x in reference_input_tensors:\n                 if x in tensor_map:\n                     computed_data.append(tensor_map[x])\n \n             if len(computed_data) \u003d\u003d len(reference_input_tensors):\n                 # Call layer.\n                 if node.arguments:\n                     kwargs \u003d node.arguments\n                 else:\n                     kwargs \u003d {}\n                 if len(computed_data) \u003d\u003d 1:\n                     computed_tensor, computed_mask \u003d computed_data[0]\n                     if has_arg(layer.call, \u0027mask\u0027):\n                         if \u0027mask\u0027 not in kwargs:\n                             kwargs[\u0027mask\u0027] \u003d computed_mask\n                     output_tensors \u003d topology._to_list(\n                         layer(computed_tensor, **kwargs))\n                     output_masks \u003d topology._to_list(\n                         layer.compute_mask(computed_tensor,\n                                            computed_mask))\n                     computed_tensors \u003d [computed_tensor]\n                     computed_masks \u003d [computed_mask]\n                 else:\n                     computed_tensors \u003d [x[0] for x in computed_data]\n                     computed_masks \u003d [x[1] for x in computed_data]\n                     if has_arg(layer.call, \u0027mask\u0027):\n                         if \u0027mask\u0027 not in kwargs:\n                             kwargs[\u0027mask\u0027] \u003d computed_masks\n                     output_tensors \u003d topology._to_list(\n                         layer(computed_tensors, **kwargs))\n                     output_masks \u003d topology._to_list(\n                         layer.compute_mask(computed_tensors,\n                                            computed_masks))\n                 # Update tensor_map.\n                 for x, y, mask in zip(reference_output_tensors,\n                                       output_tensors,\n                                       output_masks):\n                     tensor_map[x] \u003d (y, mask)\n \n     # Check that we did compute the model outputs,\n     # then instantiate a new model from inputs and outputs.\n     output_tensors \u003d []\n     for x in model.outputs:\n         assert x in tensor_map, \u0027Could not compute output \u0027 + str(x)\n         tensor, _ \u003d tensor_map[x]\n         output_tensors.append(tensor)\n     return Model(input_tensors, output_tensors, name\u003dmodel.name)\n \n",
      "extendedDetails": {}
    },
    "e27b8b9343da4558b98570d6d45599bd0e365723": {
      "type": "Yintroduced",
      "commitMessage": "[RELNOTES] Add `clone_model`. (#7631)\n\n* Add `clone_model`.\r\n\r\n* Restrict use of `clear_session` in test to TF backend.\r\n\r\n* Fix naming issue\r\n",
      "commitDate": "2017/8/14 上午10:03",
      "commitName": "e27b8b9343da4558b98570d6d45599bd0e365723",
      "commitAuthor": "François Chollet",
      "diff": "@@ -0,0 +1,145 @@\n+def _clone_functional_model(model, input_tensors\u003dNone):\n+    \"\"\"Clone a functional `Model` instance.\n+\n+    Model cloning is similar to calling a model on new inputs,\n+    except that it creates new layers (and thus new weights) instead\n+    of sharing the weights of the existing layers.\n+\n+    # Arguments\n+        model: Instance of `Model`.\n+        input_tensors: optional list of input tensors\n+            to build the model upon. If not provided,\n+            placeholders will be created.\n+\n+    # Returns\n+        An instance of `Model` reproducing the behavior\n+        of the original model, on top of new inputs tensors,\n+        using newly instantiated weights.\n+\n+    # Raises\n+        ValueError: in case of invalid `model` argument value.\n+    \"\"\"\n+    if not isinstance(model, Model):\n+        raise ValueError(\u0027Expected `model` argument \u0027\n+                         \u0027to be a `Model` instance, got \u0027, model)\n+    if isinstance(model, Sequential):\n+        raise ValueError(\u0027Expected `model` argument \u0027\n+                         \u0027to be a functional `Model` instance, \u0027\n+                         \u0027got a `Sequential` instance instead:\u0027, model)\n+\n+    layer_map \u003d {}  # Cache for created layers.\n+    tensor_map \u003d {}  # Map {reference_tensor: (corresponding_tensor, mask)}\n+    if input_tensors is None:\n+        # Create placeholders to build the model on top of.\n+        input_layers \u003d []\n+        input_tensors \u003d []\n+        for layer in model.input_layers:\n+            input_tensor \u003d Input(batch_shape\u003dlayer.batch_input_shape,\n+                                 dtype\u003dlayer.dtype,\n+                                 sparse\u003dlayer.sparse,\n+                                 name\u003dlayer.name)\n+            input_tensors.append(input_tensor)\n+            # Cache newly created input layer.\n+            newly_created_input_layer \u003d input_tensor._keras_history[0]\n+            layer_map[layer] \u003d newly_created_input_layer\n+        for original_input_layer, cloned_input_layer in zip(model.input_layers, input_layers):\n+            layer_map[original_input_layer] \u003d cloned_input_layer\n+    else:\n+        # Make sure that all input tensors come from a Keras layer.\n+        # If tensor comes from an input layer: cache the input layer.\n+        input_tensors \u003d topology._to_list(input_tensors)\n+        _input_tensors \u003d []\n+        for i, x in enumerate(input_tensors):\n+            if not K.is_keras_tensor(x):\n+                name \u003d model.input_layers[i].name\n+                input_tensor \u003d Input(tensor\u003dx,\n+                                     name\u003d\u0027input_wrapper_for_\u0027 + name)\n+                _input_tensors.append(input_tensor)\n+                # Cache newly created input layer.\n+                original_input_layer \u003d x._keras_history[0]\n+                newly_created_input_layer \u003d input_tensor._keras_history[0]\n+                layer_map[original_input_layer] \u003d newly_created_input_layer\n+            else:\n+                _input_tensors.append(x)\n+        input_tensors \u003d _input_tensors\n+\n+    for x, y in zip(model.inputs, input_tensors):\n+        tensor_map[x] \u003d (y, None)  # tensor, mask\n+\n+    # Iterated over every node in the reference model, in depth order.\n+    depth_keys \u003d list(model.nodes_by_depth.keys())\n+    depth_keys.sort(reverse\u003dTrue)\n+    for depth in depth_keys:\n+        nodes \u003d model.nodes_by_depth[depth]\n+        for node in nodes:\n+            # Recover the corresponding layer.\n+            layer \u003d node.outbound_layer\n+\n+            # Get or create layer.\n+            if layer not in layer_map:\n+                # Clone layer.\n+                new_layer \u003d layer.__class__.from_config(layer.get_config())\n+                layer_map[layer] \u003d new_layer\n+                layer \u003d new_layer\n+            else:\n+                # Reuse previously cloned layer.\n+                layer \u003d layer_map[layer]\n+                # Don\u0027t call InputLayer multiple times.\n+                if isinstance(layer, topology.InputLayer):\n+                    continue\n+\n+            # Gather inputs to call the new layer.\n+            reference_input_tensors \u003d node.input_tensors\n+            reference_output_tensors \u003d node.output_tensors\n+\n+            # If all previous input tensors are available in tensor_map,\n+            # then call node.inbound_layer on them.\n+            computed_data \u003d []  # List of tuples (input, mask).\n+            for x in reference_input_tensors:\n+                if x in tensor_map:\n+                    computed_data.append(tensor_map[x])\n+\n+            if len(computed_data) \u003d\u003d len(reference_input_tensors):\n+                # Call layer.\n+                if node.arguments:\n+                    kwargs \u003d node.arguments\n+                else:\n+                    kwargs \u003d {}\n+                if len(computed_data) \u003d\u003d 1:\n+                    computed_tensor, computed_mask \u003d computed_data[0]\n+                    if has_arg(layer.call, \u0027mask\u0027):\n+                        if \u0027mask\u0027 not in kwargs:\n+                            kwargs[\u0027mask\u0027] \u003d computed_mask\n+                    output_tensors \u003d topology._to_list(\n+                        layer(computed_tensor, **kwargs))\n+                    output_masks \u003d topology._to_list(\n+                        layer.compute_mask(computed_tensor,\n+                                           computed_mask))\n+                    computed_tensors \u003d [computed_tensor]\n+                    computed_masks \u003d [computed_mask]\n+                else:\n+                    computed_tensors \u003d [x[0] for x in computed_data]\n+                    computed_masks \u003d [x[1] for x in computed_data]\n+                    if has_arg(layer.call, \u0027mask\u0027):\n+                        if \u0027mask\u0027 not in kwargs:\n+                            kwargs[\u0027mask\u0027] \u003d computed_masks\n+                    output_tensors \u003d topology._to_list(\n+                        layer(computed_tensors, **kwargs))\n+                    output_masks \u003d topology._to_list(\n+                        layer.compute_mask(computed_tensors,\n+                                           computed_masks))\n+                # Update tensor_map.\n+                for x, y, mask in zip(reference_output_tensors,\n+                                      output_tensors,\n+                                      output_masks):\n+                    tensor_map[x] \u003d (y, mask)\n+\n+    # Check that we did compute the model outputs,\n+    # then instantiate a new model from inputs and outputs.\n+    output_tensors \u003d []\n+    for x in model.outputs:\n+        assert x in tensor_map, \u0027Could not compute output \u0027 + str(x)\n+        tensor, _ \u003d tensor_map[x]\n+        output_tensors.append(tensor)\n+    return Model(input_tensors, output_tensors, name\u003dmodel.name)\n+\n",
      "actualSource": "def _clone_functional_model(model, input_tensors\u003dNone):\n    \"\"\"Clone a functional `Model` instance.\n\n    Model cloning is similar to calling a model on new inputs,\n    except that it creates new layers (and thus new weights) instead\n    of sharing the weights of the existing layers.\n\n    # Arguments\n        model: Instance of `Model`.\n        input_tensors: optional list of input tensors\n            to build the model upon. If not provided,\n            placeholders will be created.\n\n    # Returns\n        An instance of `Model` reproducing the behavior\n        of the original model, on top of new inputs tensors,\n        using newly instantiated weights.\n\n    # Raises\n        ValueError: in case of invalid `model` argument value.\n    \"\"\"\n    if not isinstance(model, Model):\n        raise ValueError(\u0027Expected `model` argument \u0027\n                         \u0027to be a `Model` instance, got \u0027, model)\n    if isinstance(model, Sequential):\n        raise ValueError(\u0027Expected `model` argument \u0027\n                         \u0027to be a functional `Model` instance, \u0027\n                         \u0027got a `Sequential` instance instead:\u0027, model)\n\n    layer_map \u003d {}  # Cache for created layers.\n    tensor_map \u003d {}  # Map {reference_tensor: (corresponding_tensor, mask)}\n    if input_tensors is None:\n        # Create placeholders to build the model on top of.\n        input_layers \u003d []\n        input_tensors \u003d []\n        for layer in model.input_layers:\n            input_tensor \u003d Input(batch_shape\u003dlayer.batch_input_shape,\n                                 dtype\u003dlayer.dtype,\n                                 sparse\u003dlayer.sparse,\n                                 name\u003dlayer.name)\n            input_tensors.append(input_tensor)\n            # Cache newly created input layer.\n            newly_created_input_layer \u003d input_tensor._keras_history[0]\n            layer_map[layer] \u003d newly_created_input_layer\n        for original_input_layer, cloned_input_layer in zip(model.input_layers, input_layers):\n            layer_map[original_input_layer] \u003d cloned_input_layer\n    else:\n        # Make sure that all input tensors come from a Keras layer.\n        # If tensor comes from an input layer: cache the input layer.\n        input_tensors \u003d topology._to_list(input_tensors)\n        _input_tensors \u003d []\n        for i, x in enumerate(input_tensors):\n            if not K.is_keras_tensor(x):\n                name \u003d model.input_layers[i].name\n                input_tensor \u003d Input(tensor\u003dx,\n                                     name\u003d\u0027input_wrapper_for_\u0027 + name)\n                _input_tensors.append(input_tensor)\n                # Cache newly created input layer.\n                original_input_layer \u003d x._keras_history[0]\n                newly_created_input_layer \u003d input_tensor._keras_history[0]\n                layer_map[original_input_layer] \u003d newly_created_input_layer\n            else:\n                _input_tensors.append(x)\n        input_tensors \u003d _input_tensors\n\n    for x, y in zip(model.inputs, input_tensors):\n        tensor_map[x] \u003d (y, None)  # tensor, mask\n\n    # Iterated over every node in the reference model, in depth order.\n    depth_keys \u003d list(model.nodes_by_depth.keys())\n    depth_keys.sort(reverse\u003dTrue)\n    for depth in depth_keys:\n        nodes \u003d model.nodes_by_depth[depth]\n        for node in nodes:\n            # Recover the corresponding layer.\n            layer \u003d node.outbound_layer\n\n            # Get or create layer.\n            if layer not in layer_map:\n                # Clone layer.\n                new_layer \u003d layer.__class__.from_config(layer.get_config())\n                layer_map[layer] \u003d new_layer\n                layer \u003d new_layer\n            else:\n                # Reuse previously cloned layer.\n                layer \u003d layer_map[layer]\n                # Don\u0027t call InputLayer multiple times.\n                if isinstance(layer, topology.InputLayer):\n                    continue\n\n            # Gather inputs to call the new layer.\n            reference_input_tensors \u003d node.input_tensors\n            reference_output_tensors \u003d node.output_tensors\n\n            # If all previous input tensors are available in tensor_map,\n            # then call node.inbound_layer on them.\n            computed_data \u003d []  # List of tuples (input, mask).\n            for x in reference_input_tensors:\n                if x in tensor_map:\n                    computed_data.append(tensor_map[x])\n\n            if len(computed_data) \u003d\u003d len(reference_input_tensors):\n                # Call layer.\n                if node.arguments:\n                    kwargs \u003d node.arguments\n                else:\n                    kwargs \u003d {}\n                if len(computed_data) \u003d\u003d 1:\n                    computed_tensor, computed_mask \u003d computed_data[0]\n                    if has_arg(layer.call, \u0027mask\u0027):\n                        if \u0027mask\u0027 not in kwargs:\n                            kwargs[\u0027mask\u0027] \u003d computed_mask\n                    output_tensors \u003d topology._to_list(\n                        layer(computed_tensor, **kwargs))\n                    output_masks \u003d topology._to_list(\n                        layer.compute_mask(computed_tensor,\n                                           computed_mask))\n                    computed_tensors \u003d [computed_tensor]\n                    computed_masks \u003d [computed_mask]\n                else:\n                    computed_tensors \u003d [x[0] for x in computed_data]\n                    computed_masks \u003d [x[1] for x in computed_data]\n                    if has_arg(layer.call, \u0027mask\u0027):\n                        if \u0027mask\u0027 not in kwargs:\n                            kwargs[\u0027mask\u0027] \u003d computed_masks\n                    output_tensors \u003d topology._to_list(\n                        layer(computed_tensors, **kwargs))\n                    output_masks \u003d topology._to_list(\n                        layer.compute_mask(computed_tensors,\n                                           computed_masks))\n                # Update tensor_map.\n                for x, y, mask in zip(reference_output_tensors,\n                                      output_tensors,\n                                      output_masks):\n                    tensor_map[x] \u003d (y, mask)\n\n    # Check that we did compute the model outputs,\n    # then instantiate a new model from inputs and outputs.\n    output_tensors \u003d []\n    for x in model.outputs:\n        assert x in tensor_map, \u0027Could not compute output \u0027 + str(x)\n        tensor, _ \u003d tensor_map[x]\n        output_tensors.append(tensor)\n    return Model(input_tensors, output_tensors, name\u003dmodel.name)\n\n",
      "path": "keras/models.py",
      "functionStartLine": 1304,
      "functionName": "_clone_functional_model",
      "functionAnnotation": ""
    }
  }
}