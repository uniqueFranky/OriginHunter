{
  "origin": "codeshovel",
  "repositoryName": "scikit-learn",
  "repositoryPath": "/Users/franky/Documents/Homework/毕业设计/testcase/scikit-learn/.git",
  "startCommitName": "9e5819aa413ce907134ee5704abba43ad8a61827",
  "sourceFileName": "_search.py",
  "functionName": "__getitem__",
  "functionId": "ParameterGrid____getitem_____self__ind",
  "sourceFilePath": "sklearn/model_selection/_search.py",
  "functionAnnotation": "",
  "functionStartLine": 140,
  "functionEndLine": 181,
  "numCommitsSeen": 108,
  "timeTaken": 6795,
  "changeHistory": [
    "3f8743f47b61a269e8bfff2322cb544170976574"
  ],
  "changeHistoryShort": {
    "3f8743f47b61a269e8bfff2322cb544170976574": "Yintroduced"
  },
  "changeHistoryDetails": {
    "3f8743f47b61a269e8bfff2322cb544170976574": {
      "type": "Yintroduced",
      "commitMessage": "Main Commits - Major\n--------------------\n\n* ENH Reogranize classes/fn from grid_search into search.py\n* ENH Reogranize classes/fn from cross_validation into split.py\n* ENH Reogranize cls/fn from cross_validation/learning_curve into validate.py\n\n* MAINT Merge _check_cv into check_cv inside the model_selection module\n* MAINT Update all the imports to point to the model_selection module\n* FIX use iter_cv to iterate throught the new style/old style cv objs\n* TST Add tests for the new model_selection members\n* ENH Wrap the old-style cv obj/iterables instead of using iter_cv\n\n* ENH Use scipy\u0027s binomial coefficient function comb for calucation of nCk\n* ENH Few enhancements to the split module\n* ENH Improve check_cv input validation and docstring\n* MAINT _get_test_folds(X, y, labels) --\u003e _get_test_folds(labels)\n* TST if 1d arrays for X introduce any errors\n* ENH use 1d X arrays for all tests;\n* ENH X_10 --\u003e X (global var)\n\nMinor\n-----\n\n* ENH _PartitionIterator --\u003e _BaseCrossValidator;\n* ENH CVIterator --\u003e CVIterableWrapper\n* TST Import the old SKF locally\n* FIX/TST Clean up the split module\u0027s tests.\n* DOC Improve documentation of the cv parameter\n* COSMIT consistently hyphenate cross-validation/cross-validator\n* TST Calculate n_samples from X\n* COSMIT Use separate lines for each import.\n* COSMIT cross_validation_generator --\u003e cross_validator\n\nCommits merged manually\n-----------------------\n\n* FIX Document the random_state attribute in RandomSearchCV\n* MAINT Use check_cv instead of _check_cv\n* ENH refactor OVO decision function, use it in SVC for sklearn-like\n  decision_function shape\n* FIX avoid memory cost when sampling from large parameter grids\n\nENH Major to Minor incremental enhancements to the model_selection\n\nSquashed commit messages - (For reference)\n\nMajor\n-----\n\n* ENH p --\u003e n_labels\n* FIX *ShuffleSplit: all float/invalid type errors at init and int error at split\n* FIX make PredefinedSplit accept test_folds in constructor; Cleanup docstrings\n* ENH+TST KFold: make rng to be generated at every split call for reproducibility\n* FIX/MAINT KFold: make shuffle a public attr\n* FIX Make CVIterableWrapper private.\n* FIX reuse len_cv instead of recalculating it\n* FIX Prevent adding *SearchCV estimators from the old grid_search module\n* re-FIX In all_estimators: the sorting to use only the 1st item (name)\n    To avoid collision between the old and the new GridSearch classes.\n* FIX test_validate.py: Use 2D X (1D X is being detected as a single sample)\n* MAINT validate.py --\u003e validation.py\n* MAINT make the submodules private\n* MAINT Support old cv/gs/lc until 0.19\n* FIX/MAINT n_splits --\u003e get_n_splits\n* FIX/TST test_logistic.py/test_ovr_multinomial_iris:\n    pass predefined folds as an iterable\n* MAINT expose BaseCrossValidator\n* Update the model_selection module with changes from master\n  - From #5161\n  -  - MAINT remove redundant p variable\n  -  - Add check for sparse prediction in cross_val_predict\n  - From #5201 - DOC improve random_state param doc\n  - From #5190 - LabelKFold and test\n  - From #4583 - LabelShuffleSplit and tests\n  - From #5300 - shuffle the `labels` not the `indxs` in LabelKFold + tests\n  - From #5378 - Make the GridSearchCV docs more accurate.\n  - From #5458 - Remove shuffle from LabelKFold\n  - From #5466(#4270) - Gaussian Process by Jan Metzen\n  - From #4826 - Move custom error / warnings into sklearn.exception\n\nMinor\n-----\n\n* ENH Make the KFold shuffling test stronger\n* FIX/DOC Use the higher level model_selection module as ref\n* DOC in check_cv \"y : array-like, optional\"\n* DOC a supervised learning problem --\u003e supervised learning problems\n* DOC cross-validators --\u003e cross-validation strategies\n* DOC Correct Olivier Grisel\u0027s name ;)\n* MINOR/FIX cv_indices --\u003e kfold\n* FIX/DOC Align the \u0027See also\u0027 section of the new KFold, LeaveOneOut\n* TST/FIX imports on separate lines\n* FIX use __class__ instead of classmethod\n* TST/FIX import directly from model_selection\n* COSMIT Relocate the random_state documentation\n* COSMIT remove pass\n* MAINT Remove deprecation warnings from old tests\n* FIX correct import at test_split\n* FIX/MAINT Move P_sparse, X, y defns to top; rm unused W_sparse, X_sparse\n* FIX random state to avoid doctest failure\n* TST n_splits and split wrapping of _CVIterableWrapper\n* FIX/MAINT Use multilabel indicator matrix directly\n* TST/DOC clarify why we conflate classes 0 and 1\n* DOC add comment that this was taken from BaseEstimator\n* FIX use of labels is not needed in stratified k fold\n* Fix cross_validation reference\n* Fix the labels param doc\n\nFIX/DOC/MAINT Addressing the review comments by Arnaud and Andy\n\nCOSMIT Sort the members alphabetically\nCOSMIT len_cv --\u003e n_splits\nCOSMIT Merge 2 if; FIX Use kwargs\nDOC Add my name to the authors :D\nDOC make labels parameter consistent\nFIX Remove hack for boolean indices; + COSMIT idx --\u003e indices; DOC Add Returns\nCOSMIT preds --\u003e predictions\nDOC Add Returns and neatly arrange X, y, labels\nFIX idx(s)/ind(s)--\u003e indice(s)\nCOSMIT Merge if and else to elif\nCOSMIT n --\u003e n_samples\nCOSMIT Use bincount only once\nCOSMIT cls --\u003e class_i / class_i (ith class indices) --\u003e\nperm_indices_class_i\n\nFIX/ENH/TST Addressing the final reviews\n\nCOSMIT c --\u003e count\nFIX/TST make check_cv raise ValueError for string cv value\nTST nested cv (gs inside cross_val_score) works for diff cvs\nFIX/ENH Raise ValueError when labels is None for label based cvs;\nTST if labels is being passed correctly to the cv and that the\nValueError is being propagated to the cross_val_score/predict and grid\nsearch\nFIX pass labels to cross_val_score\nFIX use make_classification\nDOC Add Returns; COSMIT Remove scaffolding\nTST add a test to check the _build_repr helper\nREVERT the old GS/RS should also be tested by the common tests.\nENH Add a tuple of all/label based CVS\nFIX raise VE even at get_n_splits if labels is None\nFIX Fabian\u0027s comments\nPEP8\n",
      "commitDate": "2015/10/23 下午11:28",
      "commitName": "3f8743f47b61a269e8bfff2322cb544170976574",
      "commitAuthor": "Raghav R V",
      "diff": "@@ -0,0 +1,41 @@\n+    def __getitem__(self, ind):\n+        \"\"\"Get the parameters that would be ``ind``th in iteration\n+\n+        Parameters\n+        ----------\n+        ind : int\n+            The iteration index\n+\n+        Returns\n+        -------\n+        params : dict of string to any\n+            Equal to list(self)[ind]\n+        \"\"\"\n+        # This is used to make discrete sampling without replacement memory\n+        # efficient.\n+        for sub_grid in self.param_grid:\n+            # XXX: could memoize information used here\n+            if not sub_grid:\n+                if ind \u003d\u003d 0:\n+                    return {}\n+                else:\n+                    ind -\u003d 1\n+                    continue\n+\n+            # Reverse so most frequent cycling parameter comes first\n+            keys, values_lists \u003d zip(*sorted(sub_grid.items())[::-1])\n+            sizes \u003d [len(v_list) for v_list in values_lists]\n+            total \u003d np.product(sizes)\n+\n+            if ind \u003e\u003d total:\n+                # Try the next grid\n+                ind -\u003d total\n+            else:\n+                out \u003d {}\n+                for key, v_list, n in zip(keys, values_lists, sizes):\n+                    ind, offset \u003d divmod(ind, n)\n+                    out[key] \u003d v_list[offset]\n+                return out\n+\n+        raise IndexError(\u0027ParameterGrid index out of range\u0027)\n+\n",
      "actualSource": "    def __getitem__(self, ind):\n        \"\"\"Get the parameters that would be ``ind``th in iteration\n\n        Parameters\n        ----------\n        ind : int\n            The iteration index\n\n        Returns\n        -------\n        params : dict of string to any\n            Equal to list(self)[ind]\n        \"\"\"\n        # This is used to make discrete sampling without replacement memory\n        # efficient.\n        for sub_grid in self.param_grid:\n            # XXX: could memoize information used here\n            if not sub_grid:\n                if ind \u003d\u003d 0:\n                    return {}\n                else:\n                    ind -\u003d 1\n                    continue\n\n            # Reverse so most frequent cycling parameter comes first\n            keys, values_lists \u003d zip(*sorted(sub_grid.items())[::-1])\n            sizes \u003d [len(v_list) for v_list in values_lists]\n            total \u003d np.product(sizes)\n\n            if ind \u003e\u003d total:\n                # Try the next grid\n                ind -\u003d total\n            else:\n                out \u003d {}\n                for key, v_list, n in zip(keys, values_lists, sizes):\n                    ind, offset \u003d divmod(ind, n)\n                    out[key] \u003d v_list[offset]\n                return out\n\n        raise IndexError(\u0027ParameterGrid index out of range\u0027)\n\n",
      "path": "sklearn/model_selection/_search.py",
      "functionStartLine": 117,
      "functionName": "__getitem__",
      "functionAnnotation": ""
    }
  }
}